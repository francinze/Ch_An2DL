{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"0ffa1054","cell_type":"markdown","source":"# Kaggle & Colab Imports","metadata":{}},{"id":"6d3e4c0e","cell_type":"code","source":"# KAGGLE IMPORTS\n# Clone repo\n!git clone https://github.com/francinze/Ch_An2DL.git /kaggle/working/ch2\n\n# Install kaggle API\n!pip install -q kaggle\n\n# Configure kaggle.json\n!mkdir -p /root/.config/kaggle\n\n# Copy your kaggle.json there\n!cp /kaggle/working/ch2/kaggle.json /root/.config/kaggle/\n\n# Set correct permissions\n!chmod 600 /root/.config/kaggle/kaggle.json\n\n# Move into the working directory\n%cd /kaggle/working/ch2/\n\n!mkdir data\n!mkdir models\n\n# Download competition files\n!kaggle competitions download -c an2dl2526c2 -p /data\n\n# Unzip dataset\n!unzip -o /data/an2dl2526c2.zip -d /data/","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"93b1cef6","cell_type":"code","source":"'''\n# COLAB IMPORTS\n!git clone https://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@github.com/francinze/Ch_An2DL.git\n! pip install -q kaggle\n! mkdir ~/.kaggle\n! cp Ch_An2DL/kaggle.json ~/.kaggle/\n! chmod 600 ~/.kaggle/kaggle.json\n%cd /content/Ch_An2DL/\n!mkdir data\n!mkdir models\n!kaggle competitions download -c an2dl2526c2 -p /data\n!unzip -o /data/an2dl2526c2.zip -d /data/\n'''","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"687201fe","cell_type":"markdown","source":"#  Import data","metadata":{}},{"id":"8f8eea66","cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport numpy as np","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"341d217a","cell_type":"code","source":"import os\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\n# Detect environment and set appropriate path prefix\nif len(os.listdir('data')) > 0:\n    # Local environment\n    PATH_PREFIX = ''\nelse:\n    # Kaggle or Colab environment\n    PATH_PREFIX = '/'\n\n# ===== SET DATA TYPE: \"IMG\" or \"MASK\" =====\nDATA_TYPE = \"IMG\"  # Use \"IMG\" for images or \"MASK\" for masks\n# ==========================================\n\n# Load image dataset\ntrain_dir = PATH_PREFIX + 'data/train_data/'\ntest_dir = PATH_PREFIX + 'data/test_data/'\ntrain_labels = pd.read_csv(PATH_PREFIX + 'data/train_labels.csv')\n\nprint(f\"Environment detected. Using path prefix: '{PATH_PREFIX}'\")\n\n# Display dataset info\nprint(f\"Total training samples: {len(train_labels)}\")\nprint(f\"\\nClass distribution:\")\nprint(train_labels['label'].value_counts())\n\n# Check image properties\nsample_img = Image.open(os.path.join(train_dir, 'img_0000.png'))\nsample_mask = Image.open(os.path.join(train_dir, 'mask_0000.png'))\nprint(f\"\\nImage shape: {np.array(sample_img).shape}\")\nprint(f\"Mask shape: {np.array(sample_mask).shape}\")\nprint(f\"Image dtype: {np.array(sample_img).dtype}\")\nprint(f\"Mask unique values: {np.unique(np.array(sample_mask))}\")\n\n# Visualize a few samples\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\nfor i in range(3):\n    img_name = train_labels.iloc[i]['sample_index']\n    label = train_labels.iloc[i]['label']\n    \n    img = Image.open(os.path.join(train_dir, img_name))\n    mask = Image.open(os.path.join(train_dir, img_name.replace('img_', 'mask_')))\n    \n    axes[0, i].imshow(img)\n    axes[0, i].set_title(f'{img_name}\\n{label}')\n    axes[0, i].axis('off')\n    \n    axes[1, i].imshow(mask, cmap='gray')\n    axes[1, i].set_title(f'Mask for {img_name}')\n    axes[1, i].axis('off')\n\n\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4af21e5c","cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"id":"63af5838","cell_type":"markdown","source":"## Remove Shrek & Slimes","metadata":{}},{"id":"d8ef36cc","cell_type":"code","source":"# Parse the contaminated indices from the text file\ncontaminated_indices = []\nwith open('shrek_and_slimes.txt', 'r') as f:\n    for line in f:\n        line = line.strip()\n        if line and line.isdigit():\n            contaminated_indices.append(int(line))\n\nprint(f\"Found {len(contaminated_indices)} contaminated samples to remove\")\n\n# Remove corresponding image and mask files\nremoved_count = 0\nfor idx in contaminated_indices:\n    img_name = f'img_{idx:04d}.png'\n    mask_name = f'mask_{idx:04d}.png'\n    \n    img_path = os.path.join(train_dir, img_name)\n    mask_path = os.path.join(train_dir, mask_name)\n    \n    # Remove image if exists\n    if os.path.exists(img_path):\n        os.remove(img_path)\n        removed_count += 1\n    \n    # Remove mask if exists\n    if os.path.exists(mask_path):\n        os.remove(mask_path)\n        removed_count += 1\n\nprint(f\"Removed {removed_count} files from {train_dir}\")\n\n# Update train_labels by removing contaminated indices\ntrain_labels = train_labels[~train_labels['sample_index'].str.extract(r'(\\d+)')[0].astype(int).isin(contaminated_indices)]\nprint(f\"Training labels updated: {len(train_labels)} samples remaining\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"d80f213e","cell_type":"markdown","source":"## Augmentation","metadata":{}},{"id":"3d8b4216","cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Analyze class distribution after removal\nclass_distribution = train_labels['label'].value_counts().sort_index()\nprint(\"\\n\" + \"=\"*60)\nprint(\"Class Distribution After Removal of Contaminated Images\")\nprint(\"=\"*60)\nprint(class_distribution)\nprint(f\"\\nTotal samples: {len(train_labels)}\")\n\n# Calculate statistics\nprint(\"\\n\" + \"=\"*60)\nprint(\"STATISTICS FOR AUGMENTATION\")\nprint(\"=\"*60)\n\n# Class with the most samples (majority)\nmax_class = class_distribution.max()\nmax_class_name = class_distribution.idxmax()\nprint(f\"\\nClass with the most samples (Majority): {max_class_name} ({max_class} samples)\")\n\n# Class with the fewest samples (minority)\nmin_class = class_distribution.min()\nmin_class_name = class_distribution.idxmin()\nprint(f\"Class with the fewest samples (Minority): {min_class_name} ({min_class} samples)\")\n\n# Imbalance ratio\nimbalance_ratio = max_class / min_class\nprint(f\"\\nImbalance ratio (Max/Min): {imbalance_ratio:.2f}x\")\n\n# Augmentation proposal\nprint(\"\\n\" + \"=\"*60)\nprint(\"RECOMMENDED AUGMENTATION STRATEGY\")\nprint(\"=\"*60)\nprint(\"\\nAugmentations to apply (as suggested by the professor):\")\nprint(\"  1. Horizontal Flip (p=0.5)\")\nprint(\"  2. Vertical Flip (p=0.5)\")\nprint(\"  3. Random Translation (0.2, 0.2)\")\nprint(\"  4. Random Zoom/Scale (0.8, 1.2)\")\nprint(\"  [EXCLUDE: Random Rotation - would change dimensions]\\n\")\n\n# STRATEGY: All classes grow until reaching the same target number for ALL\nprint(\"\\n\" + \"=\"*80)\nprint(\"BALANCED STRATEGY: ALL CLASSES GROW TO A FIXED AND EQUAL NUMBER\")\nprint(\"=\"*80)\n\n# ===== MODIFY THE TARGET NUMBER OF SAMPLES HERE =====\ntarget_samples = 1000  # Desired number of samples for EACH class\n# =====================================================\n\nprint(f\"\\nTarget: {target_samples} samples for EACH class\")\n\naugmentation_strategy_balanced = {}\ntotal_to_generate = 0\n\nfor class_name in class_distribution.index:\n    n_samples = class_distribution[class_name]\n    n_needed = target_samples - n_samples\n    n_augmentations = max(0, n_needed)  # We cannot have negative augmentations\n    \n    augmentation_strategy_balanced[class_name] = {\n        'original': n_samples,\n        'target': target_samples,\n        'augment_count': n_augmentations,\n        'ratio_multiplier': n_augmentations / n_samples if n_samples > 0 else 0\n    }\n    \n    total_to_generate += n_augmentations\n\n# Projection of the dataset after augmentation\nprint(\"\\n\" + \"=\"*80)\nprint(\"DATASET AFTER BALANCED AUGMENTATION\")\nprint(\"=\"*80)\nprint(f\"{'Class':<20} {'Original':<15} {'New Augment':<15} {'Augmentations per image':<25} {'Total':<15}\")\nprint(\"-\" * 80)\n\ntotal_original = 0\ntotal_augmented = 0\nfor class_name in class_distribution.index:\n    n_original = class_distribution[class_name]\n    n_aug = augmentation_strategy_balanced[class_name]['augment_count']\n    n_total = n_original + n_aug\n    \n    total_original += n_original\n    total_augmented += n_total\n    \n    print(f\"{class_name:<20} {n_original:<15} {n_aug:<15} {augmentation_strategy_balanced[class_name]['ratio_multiplier']:<25.2f} {n_total:<15}\")\n\nprint(\"-\" * 80)\nprint(f\"{'TOTAL':<20} {total_original:<15} {total_to_generate:<15} {np.mean([augmentation_strategy_balanced[class_name]['ratio_multiplier'] for class_name in class_distribution.index]):<25.2f} {total_augmented:<15}\")\n\n# Visualize the distribution before and after\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Before\nclass_distribution.plot(kind='bar', ax=axes[0], color='steelblue')\naxes[0].set_title('Class Distribution - BEFORE Augmentation', fontsize=12, fontweight='bold')\naxes[0].set_ylabel('Number of samples')\naxes[0].set_xlabel('Class')\naxes[0].axhline(y=target_samples, color='red', linestyle='--', linewidth=2, label=f'Target: {target_samples}')\naxes[0].legend()\naxes[0].grid(axis='y', alpha=0.3)\n\n# After\nafter_augmentation_balanced = {}\nfor class_name in class_distribution.index:\n    after_augmentation_balanced[class_name] = augmentation_strategy_balanced[class_name]['target']\n\nafter_series = pd.Series(after_augmentation_balanced)\nafter_series.plot(kind='bar', ax=axes[1], color='seagreen')\naxes[1].set_title('Class Distribution - AFTER Balanced Augmentation', fontsize=12, fontweight='bold')\naxes[1].set_ylabel('Number of samples')\naxes[1].set_xlabel('Class')\naxes[1].axhline(y=target_samples, color='red', linestyle='--', linewidth=2, label=f'Target: {target_samples}')\naxes[1].set_ylim([0, max_class * 1.1])\naxes[1].legend()\naxes[1].grid(axis='y', alpha=0.3)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f722ec8b","cell_type":"code","source":"# Crea cartella per salvare le immagini augmentate\naugmented_dir = PATH_PREFIX + 'data/train_data_augmented/'\nif not os.path.exists(augmented_dir):\n    os.makedirs(augmented_dir)\n    print(f\"Created directory: {augmented_dir}\")\n\n# Definisci le augmentazioni per ogni classe\naugmentation_transforms = {\n    'flip': transforms.Compose([\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n    ]),\n    'translation': transforms.Compose([\n        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=None),\n    ]),\n    'zoom': transforms.Compose([\n        transforms.RandomAffine(degrees=0, translate=None, scale=(0.8, 1.2)),\n    ]),\n    'combined': transforms.Compose([\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.RandomVerticalFlip(p=0.5),\n        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n    ])\n}\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"INIZIO PROCESS DI AUGMENTATION\")\nprint(\"=\"*80)\n\n# Cicla per ogni classe e genera le augmentazioni\ntotal_augmented = 0\n\nfor class_name in sorted(augmentation_strategy_balanced.keys()):\n    info = augmentation_strategy_balanced[class_name]\n    n_augment = info['augment_count']\n    \n    if n_augment == 0:\n        print(f\"\\n✓ {class_name}: Nessuna augmentation necessaria (già al target)\")\n        continue\n    \n    print(f\"\\n{'-'*80}\")\n    print(f\"Classe: {class_name}\")\n    print(f\"Augmentazioni da generare: {n_augment}\")\n    print(f\"{'-'*80}\")\n    \n    # Ottieni le immagini originali di questa classe\n    class_samples = train_labels[train_labels['label'] == class_name]['sample_index'].tolist()\n    n_original = len(class_samples)\n    \n    # Calcola quante augmentazioni per immagine originale\n    aug_per_img = n_augment / n_original\n    \n    # Per ogni immagine originale\n    aug_count = 0\n    for img_idx, img_name in enumerate(class_samples):\n        # Determine which file to load based on DATA_TYPE\n        if DATA_TYPE == \"MASK\":\n            file_name = img_name.replace('img_', 'mask_')\n        else:  # IMG\n            file_name = img_name\n        \n        img_path = os.path.join(train_dir, file_name)\n        \n        if not os.path.exists(img_path):\n            print(f\"  ⚠ File non trovato: {file_name}\")\n            continue\n        \n        # Carica l'immagine/maschera originale\n        if DATA_TYPE == \"MASK\":\n            img = Image.open(img_path).convert('L')  # Grayscale for masks\n        else:  # IMG\n            img = Image.open(img_path).convert('RGB')\n        img_pil = img.copy()\n        \n        # Genera augmentazioni per questa immagine\n        n_to_generate = int(np.ceil(aug_per_img)) if img_idx < n_augment % n_original else int(np.floor(aug_per_img))\n        \n        for aug_num in range(n_to_generate):\n            if aug_count <= n_augment:\n                base_name = file_name.replace('.png', '')\n\n                # Scegli un tipo di augmentazione in modo ciclico\n                aug_types = list(augmentation_transforms.keys())\n                aug_type = aug_types[aug_count % len(aug_types)]\n                transform = augmentation_transforms[aug_type]\n                img_augmented = transform(img_pil)\n                augmented_img_name = f\"{base_name}_aug_{aug_num}_{aug_type}.png\"\n                \n                # Salva immagine augmentata\n                augmented_img_path = os.path.join(augmented_dir, augmented_img_name)\n                img_augmented.save(augmented_img_path)\n                \n            aug_count += 1\n        \n        # Progress update\n        if (img_idx + 1) % max(1, n_original // 5) == 0 or img_idx == n_original - 1:\n            print(f\"  Elaborati {img_idx + 1}/{n_original} campioni originali ({aug_count} augmentazioni generate)\")\n    \n    total_augmented += aug_count\n    print(f\"  ✓ {class_name}: Completato! {aug_count} augmentazioni generate\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(f\"AUGMENTATION COMPLETATA!\")\nprint(f\"Totale immagini augmentate generate: {total_augmented}\")\nprint(f\"Cartella di salvataggio: {augmented_dir}\")\nprint(\"=\"*80)\n\n# Verifica conteggio file\naugmented_files = os.listdir(augmented_dir)\n\nprint(f\"\\nFile nella cartella augmented: {len(augmented_files)}\")\nprint(f\"Primi 5 file: {augmented_files[:5]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"de093d1e","cell_type":"code","source":"from torch.utils.data import TensorDataset\n\n# Define target image size\nIMG_SIZE = (224, 224)  # Standard size for many CNN architectures\n# Create DataLoaders\nBATCH_SIZE = 32\n\n# Carica le immagini originali + augmentate\nprint(\"\\n\" + \"=\"*80)\nprint(\"CARICAMENTO DATASET EQUILIBRATO (Originali + Augmentate)\")\nprint(\"=\"*80)\n\n# Crea lista delle immagini augmentate\naugmented_files = os.listdir(augmented_dir)\nprint(f\"Immagini augmentate trovate: {len(augmented_files)}\")\n\n# Crea nuovo dataframe con tutte le immagini (originali + augmentate)\ntrain_labels_augmented = train_labels.copy()\n\n# Aggiungi le immagini augmentate\naugmented_rows = []\nfor aug_img_name in augmented_files:\n    # Estrai il nome originale della MASCHERA e converti a IMG\n    if 'mask_' in aug_img_name:\n        base_mask_name = aug_img_name.split('_aug_')[0]  # es: mask_0001\n        base_img_name = base_mask_name.replace('mask_', 'img_') + '.png'  # es: img_0001.png\n    else:\n        base_img_name = aug_img_name.split('_aug_')[0] + '.png'\n    \n    # Trova la classe nel dataframe originale\n    original_row = train_labels[train_labels['sample_index'] == base_img_name]\n    if not original_row.empty:\n        class_label = original_row.iloc[0]['label']\n        augmented_rows.append({'sample_index': aug_img_name, 'label': class_label})\n\naugmented_df = pd.DataFrame(augmented_rows)\ntrain_labels_augmented = pd.concat([train_labels_augmented, augmented_df], ignore_index=True)\n\nprint(f\"\\nDataset originale: {len(train_labels)} campioni\")\nprint(f\"Dataset augmentato: {len(train_labels_augmented)} campioni\")\nprint(f\"\\nDistribuzione nel dataset augmentato:\")\nprint(train_labels_augmented['label'].value_counts().sort_index())\n\n# Carica le immagini in tensori (originali + augmentate)\ndef load_augmented_images_to_tensor(train_dir, augmented_dir, labels_df, img_size=IMG_SIZE):\n    \"\"\"Load original and augmented images into tensors\"\"\"\n    images = []\n    labels = []\n    \n    for idx, row in labels_df.iterrows():\n        img_name = row['sample_index']\n        label = row['label']\n        \n        # Determina da quale cartella caricare\n        if '_aug_' not in img_name:\n            # Immagine originale\n            img_path = os.path.join(train_dir, img_name)\n        else:\n            # Immagine augmentata\n            img_path = os.path.join(augmented_dir, img_name)\n        \n        if not os.path.exists(img_path):\n            print(f\"⚠ Warning: Image not found: {img_path}\")\n            continue\n        \n        img = Image.open(img_path).convert('RGB')\n        img = img.resize(img_size, Image.BILINEAR)\n        img_array = np.array(img)\n        images.append(img_array)\n        labels.append(label)\n    \n    # Convert to tensors\n    images = np.array(images)\n    images_tensor = torch.from_numpy(images).permute(0, 3, 1, 2).float() / 255.0\n    \n    label_map = {'Triple negative': 0, 'Luminal A': 1, 'Luminal B': 2, 'HER2(+)': 3}\n    label_indices = [label_map[label] for label in labels]\n    labels_tensor = torch.tensor(label_indices, dtype=torch.long)\n    \n    return images_tensor, labels_tensor, label_map\n\nprint(\"\\nCaricamento immagini in tensori...\")\nX_train_augmented, y_train_augmented, label_map = load_augmented_images_to_tensor(\n    train_dir, augmented_dir, train_labels_augmented, IMG_SIZE\n)\n\nprint(f\"Tensore immagini shape: {X_train_augmented.shape}\")\nprint(f\"Tensore labels shape: {y_train_augmented.shape}\")\n\n# Split training/validation (stratificato)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train_augmented, y_train_augmented, test_size=0.2, random_state=42, stratify=y_train_augmented\n)\n\nprint(f\"\\nTrain set augmentato: {X_train.shape[0]} campioni\")\nprint(f\"Validation set augmentato: {X_val.shape[0]} campioni\")\n\n# Crea nuovi DataLoaders\ntrain_dataset = TensorDataset(X_train, y_train)\nval_dataset = TensorDataset(X_val, y_val)\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\nprint(f\"\\nDataLoaders augmentati creati:\")\nprint(f\"Train batches: {len(train_loader)}\")\nprint(f\"Val batches: {len(val_loader)}\")\n\nprint(\"\\n✓ Dataset equilibrato pronto per l'addestramento!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"1673d8fa","cell_type":"code","source":"# Load all images and labels into tensors\ndef load_images_to_tensor(data_dir, labels_df=None, is_test=False, img_size=IMG_SIZE):\n    \"\"\"Load all images from directory into a tensor with resizing\"\"\"\n    if not is_test:\n        image_files = labels_df['sample_index'].tolist()\n    else:\n        image_files = sorted([f for f in os.listdir(data_dir) if f.startswith('img_')])\n    \n    images = []\n    for img_name in image_files:\n        img_path = os.path.join(data_dir, img_name)\n        img = Image.open(img_path).convert('RGB')\n        # Resize image to fixed size\n        img = img.resize(img_size, Image.BILINEAR)\n        img_array = np.array(img)\n        images.append(img_array)\n    \n    # Stack into numpy array: (N, H, W, C)\n    images = np.array(images)\n    # Convert to tensor and permute to (N, C, H, W)\n    images_tensor = torch.from_numpy(images).permute(0, 3, 1, 2).float() / 255.0\n    \n    if not is_test:\n        # Create label mapping and convert labels to tensor\n        label_map = {'Triple negative': 0, 'Luminal A': 1, 'Luminal B': 2, 'HER2(+)': 3}\n        labels = [label_map[label] for label in labels_df['label']]\n        labels_tensor = torch.tensor(labels, dtype=torch.long)\n        return images_tensor, labels_tensor, label_map\n    else:\n        return images_tensor, image_files\n\n# Load test data\nprint(\"\\nLoading test images...\")\nX_test, test_filenames = load_images_to_tensor(test_dir, is_test=True)\nprint(f\"Test images shape: {X_test.shape}\")\n\ntest_dataset = TensorDataset(X_test)\n\n# Create DataLoaders\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\nprint(f\"\\nDataLoader created:\")\nprint(f\"Test batches: {len(test_loader)}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"5ad6b729","cell_type":"code","source":"input_shape = X_train.shape[1:]  # (C, H, W)\nnum_classes = len(label_map)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"00880a6d","cell_type":"code","source":"import torch.nn as nn\n\n# Number of training epochs\nLEARNING_RATE = 1e-3\nEPOCHS = 500\nPATIENCE = 50\n\n# Regularisation\nDROPOUT_RATE = 0.2         # Dropout probability\nL1_LAMBDA = 0            # L1 penalty\nL2_LAMBDA = 0            # L2 penalty\n\n# Set up loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\n\n# Print the defined parameters\nprint(\"Epochs:\", EPOCHS)\nprint(\"Batch Size:\", BATCH_SIZE)\nprint(\"Learning Rate:\", LEARNING_RATE)\nprint(\"Dropout Rate:\", DROPOUT_RATE)\nprint(\"L1 Penalty:\", L1_LAMBDA)\nprint(\"L2 Penalty:\", L2_LAMBDA)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b6b3fe4f","cell_type":"markdown","source":"# Download Pretrained Models","metadata":{}},{"id":"383f6983","cell_type":"code","source":"import torchvision.models as models\nfrom torchvision.models import ResNet18_Weights, ResNet50_Weights, EfficientNet_B0_Weights, EfficientNet_B3_Weights, VGG16_Weights\n\n# ===== UNCOMMENT THE MODEL YOU WANT TO USE =====\n\n# ResNet-18 (Smaller, faster)\nmodel_pretrained = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\nMODEL_NAME = \"resnet18\"\n\n# ResNet-50 (Deeper, more powerful)\n# model_pretrained = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n# MODEL_NAME = \"resnet50\"\n\n# EfficientNet-B0 (Efficient, good balance)\n# model_pretrained = models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n# MODEL_NAME = \"efficientnet_b0\"\n\n# EfficientNet-B3 (More powerful EfficientNet)\n# model_pretrained = models.efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1)\n# MODEL_NAME = \"efficientnet_b3\"\n\n# VGG-16 (Classic architecture)\n# model_pretrained = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n# MODEL_NAME = \"vgg16\"\n\n# ===============================================\n\nprint(f\"Loaded pretrained model: {MODEL_NAME}\")\nprint(f\"Model architecture:\\n{model_pretrained}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a112fac8","cell_type":"markdown","source":"## Transfer Learning Setup","metadata":{}},{"id":"30277733","cell_type":"code","source":"import torch.nn as nn\n\n# Get number of classes\ninput_shape = X_train.shape[1:]  # (C, H, W)\nnum_classes = len(label_map)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(f\"Input shape: {input_shape}\")\nprint(f\"Number of classes: {num_classes}\")\nprint(f\"Device: {device}\")\n\n# ===== STEP 1: Freeze all layers in the feature extractor =====\nfor param in model_pretrained.parameters():\n    param.requires_grad = False\n\nprint(\"\\n✓ All feature extractor weights frozen\")\n\n# ===== STEP 2: Replace the classifier head =====\n# Different models have different classifier layer names\nif MODEL_NAME.startswith('resnet'):\n    # ResNet has 'fc' as final layer\n    num_features = model_pretrained.fc.in_features\n    model_pretrained.fc = nn.Sequential(\n        nn.Dropout(DROPOUT_RATE),\n        nn.Linear(num_features, 256),\n        nn.ReLU(),\n        nn.Dropout(DROPOUT_RATE),\n        nn.Linear(256, num_classes)\n    )\n    print(f\"✓ Replaced ResNet classifier: {num_features} -> 256 -> {num_classes}\")\n    \nelif MODEL_NAME.startswith('efficientnet'):\n    # EfficientNet has 'classifier' as final layer\n    num_features = model_pretrained.classifier[1].in_features\n    model_pretrained.classifier = nn.Sequential(\n        nn.Dropout(DROPOUT_RATE),\n        nn.Linear(num_features, 256),\n        nn.ReLU(),\n        nn.Dropout(DROPOUT_RATE),\n        nn.Linear(256, num_classes)\n    )\n    print(f\"✓ Replaced EfficientNet classifier: {num_features} -> 256 -> {num_classes}\")\n    \nelif MODEL_NAME.startswith('vgg'):\n    # VGG has 'classifier' as a sequential module\n    num_features = model_pretrained.classifier[0].in_features\n    model_pretrained.classifier = nn.Sequential(\n        nn.Dropout(DROPOUT_RATE),\n        nn.Linear(num_features, 512),\n        nn.ReLU(),\n        nn.Dropout(DROPOUT_RATE),\n        nn.Linear(512, 256),\n        nn.ReLU(),\n        nn.Dropout(DROPOUT_RATE),\n        nn.Linear(256, num_classes)\n    )\n    print(f\"✓ Replaced VGG classifier: {num_features} -> 512 -> 256 -> {num_classes}\")\n\n# Move model to device\nmodel_pretrained = model_pretrained.to(device)\n\nprint(f\"\\n✓ Model ready for transfer learning on {device}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8dfb0fa5","cell_type":"code","source":"from torchsummary import summary\n\n# Display model architecture summary\nprint(\"\\n\" + \"=\"*80)\nprint(\"MODEL SUMMARY\")\nprint(\"=\"*80)\nsummary(model_pretrained, input_size=input_shape)\n\n# Count trainable vs frozen parameters\ntotal_params = sum(p.numel() for p in model_pretrained.parameters())\ntrainable_params = sum(p.numel() for p in model_pretrained.parameters() if p.requires_grad)\nfrozen_params = total_params - trainable_params\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"PARAMETER STATISTICS\")\nprint(\"=\"*80)\nprint(f\"Total parameters: {total_params:,}\")\nprint(f\"Trainable parameters (classifier only): {trainable_params:,}\")\nprint(f\"Frozen parameters (feature extractor): {frozen_params:,}\")\nprint(f\"Percentage trainable: {100 * trainable_params / total_params:.2f}%\")\nprint(\"=\"*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"074d3174","cell_type":"code","source":"# Define optimizer - ONLY train classifier parameters (feature extractor is frozen)\n# Filter to get only parameters that require gradients (classifier layers)\ntrainable_params = filter(lambda p: p.requires_grad, model_pretrained.parameters())\noptimizer = torch.optim.AdamW(trainable_params, lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n\n# Enable mixed precision training for GPU acceleration\nscaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n\nprint(f\"✓ Optimizer configured to train only classifier layers\")\nprint(f\"  Learning rate: {LEARNING_RATE}\")\nprint(f\"  Weight decay (L2): {L2_LAMBDA}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0d9f5f56","cell_type":"markdown","source":"# Training","metadata":{}},{"id":"d65a4724","cell_type":"code","source":"# Initialize best model tracking variables\nbest_model = None\nbest_performance = float('-inf')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ce7e4dd6","cell_type":"code","source":"def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n    \"\"\"\n    Perform one complete training epoch through the entire training dataset.\n\n    Args:\n        model (nn.Module): The neural network model to train\n        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n        l1_lambda (float): Lambda for L1 regularization\n        l2_lambda (float): Lambda for L2 regularization\n\n    Returns:\n        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n    \"\"\"\n    model.train()  # Set model to training mode\n\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n\n    # Iterate through training batches\n    for batch_idx, (inputs, targets) in enumerate(train_loader):\n        # Move data to device (GPU/CPU)\n        inputs, targets = inputs.to(device), targets.to(device)\n\n        # Clear gradients from previous step\n        optimizer.zero_grad(set_to_none=True)\n\n        # Forward pass with mixed precision (if CUDA available)\n        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n            logits = model(inputs)\n            loss = criterion(logits, targets)\n\n            # Add L1 and L2 regularization\n            l1_norm = sum(p.abs().sum() for p in model.parameters())\n            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n            loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n\n\n        # Backward pass with gradient scaling\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        # Accumulate metrics\n        running_loss += loss.item() * inputs.size(0)\n        predictions = logits.argmax(dim=1)\n        all_predictions.append(predictions.cpu().numpy())\n        all_targets.append(targets.cpu().numpy())\n\n    # Calculate epoch metrics\n    epoch_loss = running_loss / len(train_loader.dataset)\n    epoch_f1 = f1_score(\n        np.concatenate(all_targets),\n        np.concatenate(all_predictions),\n        average='weighted'\n    )\n\n    return epoch_loss, epoch_f1","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"20b99110","cell_type":"code","source":"def validate_one_epoch(model, val_loader, criterion, device):\n    \"\"\"\n    Perform one complete validation epoch through the entire validation dataset.\n\n    Args:\n        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n        criterion (nn.Module): Loss function used to calculate validation loss\n        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n\n    Returns:\n        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n\n    Note:\n        This function automatically sets the model to evaluation mode and disables\n        gradient computation for efficiency during validation.\n    \"\"\"\n    model.eval()  # Set model to evaluation mode\n\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n\n    # Disable gradient computation for validation\n    with torch.no_grad():\n        for inputs, targets in val_loader:\n            # Move data to device\n            inputs, targets = inputs.to(device), targets.to(device)\n\n            # Forward pass with mixed precision (if CUDA available)\n            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n                logits = model(inputs)\n                loss = criterion(logits, targets)\n\n            # Accumulate metrics\n            running_loss += loss.item() * inputs.size(0)\n            predictions = logits.argmax(dim=1)\n            all_predictions.append(predictions.cpu().numpy())\n            all_targets.append(targets.cpu().numpy())\n\n    # Calculate epoch metrics\n    epoch_loss = running_loss / len(val_loader.dataset)\n    epoch_accuracy = f1_score(\n        np.concatenate(all_targets),\n        np.concatenate(all_predictions),\n        average='weighted'\n    )\n\n    return epoch_loss, epoch_accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"05834891","cell_type":"code","source":"def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n        restore_best_weights=True, writer=None, verbose=10, experiment_name=\"\"):\n    \"\"\"\n    Train the neural network model on the training data and validate on the validation data.\n\n    Args:\n        model (nn.Module): The neural network model to train\n        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n        epochs (int): Number of training epochs\n        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n        l1_lambda (float): L1 regularization coefficient (default: 0)\n        l2_lambda (float): L2 regularization coefficient (default: 0)\n        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n        verbose (int, optional): Frequency of printing training progress (default: 10)\n        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n\n    Returns:\n        tuple: (model, training_history) - Trained model and metrics history\n    \"\"\"\n\n    # Initialize metrics tracking\n    training_history = {\n        'train_loss': [], 'val_loss': [],\n        'train_f1': [], 'val_f1': []\n    }\n\n    # Configure early stopping if patience is set\n    if patience > 0:\n        patience_counter = 0\n        best_metric = float('-inf') if mode == 'max' else float('inf')\n        best_epoch = 0\n\n    print(f\"Training {epochs} epochs...\")\n\n    # Main training loop: iterate through epochs\n    for epoch in range(1, epochs + 1):\n\n        # Forward pass through training data, compute gradients, update weights\n        train_loss, train_f1 = train_one_epoch(\n            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n        )\n\n        # Evaluate model on validation data without updating weights\n        val_loss, val_f1 = validate_one_epoch(\n            model, val_loader, criterion, device\n        )\n\n        # Store metrics for plotting and analysis\n        training_history['train_loss'].append(train_loss)\n        training_history['val_loss'].append(val_loss)\n        training_history['train_f1'].append(train_f1)\n        training_history['val_f1'].append(val_f1)\n\n        # Print progress every N epochs or on first epoch\n        if verbose > 0:\n            if epoch % verbose == 0 or epoch == 1:\n                print(f\"Epoch {epoch:3d}/{epochs} | \"\n                    f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n                    f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n\n        # Early stopping logic: monitor metric and save best model\n        if patience > 0:\n            current_metric = training_history[evaluation_metric][-1]\n            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n\n            if is_improvement:\n                best_metric = current_metric\n                best_epoch = epoch\n                torch.save(model.state_dict(),\"models/\"+experiment_name+'_model.pt')\n                patience_counter = 0\n            else:\n                patience_counter += 1\n                if patience_counter >= patience:\n                    print(f\"Early stopping triggered after {epoch} epochs.\")\n                    break\n\n    # Restore best model weights if early stopping was used\n    if restore_best_weights and patience > 0:\n        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n\n    # Save final model if no early stopping\n    if patience == 0:\n        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n\n    # Close TensorBoard writer\n    if writer is not None:\n        writer.close()\n\n    return model, training_history","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"50b0c487","cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\n# Set experiment name for this run\nEXPERIMENT_NAME = f\"pretrained_{MODEL_NAME}_augmented\"\n\n# Train with augmented (balanced) dataset\nprint(\"\\n\" + \"=\"*80)\nprint(f\"TRAINING WITH PRETRAINED {MODEL_NAME.upper()} - TRANSFER LEARNING\")\nprint(\"=\"*80)\nprint(f\"Train loader: {len(train_loader)} batches\")\nprint(f\"Val loader: {len(val_loader)} batches\")\nprint(f\"Strategy: Frozen feature extractor + Trainable classifier\")\nprint(\"=\"*80 + \"\\n\")\n\n# Train model and track training history using AUGMENTED dataset\nmodel_pretrained, history = fit(\n    model=model_pretrained,\n    train_loader=train_loader,  # ← USE AUGMENTED LOADER\n    val_loader=val_loader,      # ← USE AUGMENTED LOADER\n    epochs=EPOCHS,\n    criterion=criterion,\n    optimizer=optimizer,\n    scaler=scaler,\n    device=device,\n    verbose=1,\n    experiment_name=EXPERIMENT_NAME,\n    patience=PATIENCE\n)\n\n# Update best model if current performance is superior\nif history['val_f1'][-1] > best_performance:\n    best_model = model_pretrained    \n    best_performance = history['val_f1'][-1]\n    print(f\"\\n✓ New best model saved with F1 Score: {best_performance:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ea326ad9","cell_type":"markdown","source":"# Inference","metadata":{}},{"id":"9229c1f4","cell_type":"code","source":"# Collect predictions\ntest_preds = []\nbest_model.eval()  # Set model to evaluation mode\n\nwith torch.no_grad():  # Disable gradient computation for inference\n    for batch in test_loader:\n        xb = batch[0].to(device)  # Extract tensor from tuple and move to device\n\n        # Forward pass: get model predictions\n        logits = best_model(xb)\n        preds = logits.argmax(dim=1).cpu().numpy()\n\n        # Store batch results\n        test_preds.append(preds)\n\n# Combine all batches into single array\ntest_preds = np.concatenate(test_preds)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fbe5e407","cell_type":"code","source":"# Get validation predictions\nval_preds = []\nval_targets = []\nbest_model.eval()\n\nwith torch.no_grad():\n    for inputs, targets in val_loader:\n        inputs = inputs.to(device)\n        logits = best_model(inputs)\n        preds = logits.argmax(dim=1).cpu().numpy()\n        \n        val_preds.append(preds)\n        val_targets.append(targets.numpy())\n\nval_preds = np.concatenate(val_preds)\nval_targets = np.concatenate(val_targets)\n\n# Calculate overall validation set metrics\nval_acc = accuracy_score(val_targets, val_preds)\nval_prec = precision_score(val_targets, val_preds, average='weighted')\nval_rec = recall_score(val_targets, val_preds, average='weighted')\nval_f1 = f1_score(val_targets, val_preds, average='weighted')\n\nprint(f\"Accuracy over the validation set: {val_acc:.4f}\")\nprint(f\"Precision over the validation set: {val_prec:.4f}\")\nprint(f\"Recall over the validation set: {val_rec:.4f}\")\nprint(f\"F1 score over the validation set: {val_f1:.4f}\")\n\n# Generate confusion matrix\ncm = confusion_matrix(val_targets, val_preds)\nlabels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n\n# Visualize confusion matrix\nplt.figure(figsize=(8, 7))\nsns.heatmap(cm, annot=labels, fmt='', cmap='Blues')\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix — Validation Set')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"90c0b71c","cell_type":"code","source":"# @title Plot History\nimport matplotlib.pyplot as plt\n\n# Create a figure with two side-by-side subplots (two columns)\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n\n# Plot of training and validation loss on the first axis\nax1.plot(history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\nax1.plot(history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\nax1.set_title('Loss')\nax1.legend()\nax1.grid(alpha=0.3)\n\n# Plot of training and validation accuracy on the second axis\nax2.plot(history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\nax2.plot(history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\nax2.set_title('F1 Score')\nax2.legend()\nax2.grid(alpha=0.3)\n\n# Adjust the layout and display the plot\nplt.tight_layout()\nplt.subplots_adjust(right=0.85)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"443b3d5d","cell_type":"code","source":"# Create reverse label mapping\nreverse_label_map = {v: k for k, v in label_map.items()}\n\n# Create submission dataframe\nsubmission_df = pd.DataFrame({\n    'sample_index': test_filenames,\n    'label': [reverse_label_map[pred] for pred in test_preds]\n})\n\n# Create descriptive filename with all hyperparameters\nfilename_parts = [\n    f\"submission_{EXPERIMENT_NAME}\",\n    f\"data_{DATA_TYPE}\",\n    f\"bs_{BATCH_SIZE}\",\n    f\"lr_{LEARNING_RATE}\",\n    f\"drop_{DROPOUT_RATE}\",\n    f\"l1_{L1_LAMBDA}\",\n    f\"l2_{L2_LAMBDA}\",\n    f\"epochs_{EPOCHS}\",\n    f\"patience_{PATIENCE}\",\n    f\"imgsize_{IMG_SIZE[0]}x{IMG_SIZE[1]}\",\n    f\"f1_{val_f1:.4f}\"\n]\nsubmission_filename = \"_\".join(filename_parts) + \".csv\"\n\n# Save to CSV\nsubmission_df.to_csv(submission_filename, index=False)\nprint(f\"Submission file created: {submission_filename}\")\nprint(f\"Total predictions: {len(submission_df)}\")\nprint(\"\\nFirst few predictions:\")\nprint(submission_df.head(10))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}