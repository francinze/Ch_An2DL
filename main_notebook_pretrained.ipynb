{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ffa1054",
   "metadata": {},
   "source": [
    "# Kaggle & Colab Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e4c0e",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# KAGGLE IMPORTS\n",
    "# Clone repo\n",
    "!git clone https://github.com/francinze/Ch_An2DL.git /kaggle/working/ch2\n",
    "\n",
    "# Install kaggle API\n",
    "!pip install -q kaggle\n",
    "\n",
    "# Configure kaggle.json\n",
    "!mkdir -p /root/.config/kaggle\n",
    "\n",
    "# Copy your kaggle.json there\n",
    "!cp /kaggle/working/ch2/kaggle.json /root/.config/kaggle/\n",
    "\n",
    "# Set correct permissions\n",
    "!chmod 600 /root/.config/kaggle/kaggle.json\n",
    "\n",
    "# Move into the working directory\n",
    "%cd /kaggle/working/ch2/\n",
    "\n",
    "!mkdir data\n",
    "!mkdir models\n",
    "\n",
    "# Download competition files\n",
    "!kaggle competitions download -c an2dl2526c2v2 -p /data\n",
    "\n",
    "# Unzip dataset\n",
    "!unzip -o /data/an2dl2526c2v2.zip -d /data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b1cef6",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# COLAB IMPORTS\n",
    "%%capture\n",
    "!git clone https://github.com/francinze/Ch_An2DL.git\n",
    "! pip install -q kaggle\n",
    "! mkdir ~/.kaggle\n",
    "! cp Ch_An2DL/kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "%cd /content/Ch_An2DL/\n",
    "!mkdir data\n",
    "!mkdir models\n",
    "!kaggle competitions download -c an2dl2526c2v2 -p /data\n",
    "!unzip -o /data/an2dl2526c2v2.zip -d /data/\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687201fe",
   "metadata": {},
   "source": [
    "#  Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8eea66",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a556544",
   "metadata": {},
   "source": [
    "## Organize Data by Type (Masks vs Images)\n",
    "\n",
    "This cell organizes the data into separate directories:\n",
    "- `data/train_img/` - All training images (img_XXXX.png)\n",
    "- `data/train_mask/` - All training masks (mask_XXXX.png)\n",
    "- `data/test_img/` - All test images (img_XXXX.png)\n",
    "- `data/test_mask/` - All test masks (mask_XXXX.png)\n",
    "\n",
    "This structure ensures that:\n",
    "1. The `DATA_TYPE` variable can cleanly switch between using images or masks\n",
    "2. Augmented data follows the same naming convention (train_data_augmented_img/ or train_data_augmented_mask/)\n",
    "3. No confusion between different file types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c277fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ORGANIZING DATA INTO SEPARATE DIRECTORIES BY TYPE\n",
      "================================================================================\n",
      "\n",
      "Organizing training data...\n",
      "  Images: 1163 files copied to data/train_img/\n",
      "  Masks: 1163 files copied to data/train_mask/\n",
      "\n",
      "Organizing test data...\n",
      "  Images: 1163 files copied to data/train_img/\n",
      "  Masks: 1163 files copied to data/train_mask/\n",
      "\n",
      "Organizing test data...\n",
      "  Images: 954 files copied to data/test_img/\n",
      "  Masks: 954 files copied to data/test_mask/\n",
      "\n",
      "================================================================================\n",
      "DATA ORGANIZATION SUMMARY\n",
      "================================================================================\n",
      "Train images: 1163 files in data/train_img/\n",
      "Train masks: 1163 files in data/train_mask/\n",
      "Test images: 954 files in data/test_img/\n",
      "Test masks: 954 files in data/test_mask/\n",
      "================================================================================\n",
      "✓ Data organization complete!\n",
      "  - Original files remain in train_data/ and test_data/\n",
      "  - Organized copies are in train_img/, train_mask/, test_img/, test_mask/\n",
      "  Images: 954 files copied to data/test_img/\n",
      "  Masks: 954 files copied to data/test_mask/\n",
      "\n",
      "================================================================================\n",
      "DATA ORGANIZATION SUMMARY\n",
      "================================================================================\n",
      "Train images: 1163 files in data/train_img/\n",
      "Train masks: 1163 files in data/train_mask/\n",
      "Test images: 954 files in data/test_img/\n",
      "Test masks: 954 files in data/test_mask/\n",
      "================================================================================\n",
      "✓ Data organization complete!\n",
      "  - Original files remain in train_data/ and test_data/\n",
      "  - Organized copies are in train_img/, train_mask/, test_img/, test_mask/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Detect environment and set appropriate path prefix\n",
    "if 'data' not in os.listdir():\n",
    "    # Kaggle or Colab environment\n",
    "    PATH_PREFIX = '/'\n",
    "else:\n",
    "    # Local environment\n",
    "    PATH_PREFIX = ''\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ORGANIZING DATA INTO SEPARATE DIRECTORIES BY TYPE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define source directories\n",
    "train_data_dir = PATH_PREFIX + 'data/train_data/'\n",
    "test_data_dir = PATH_PREFIX + 'data/test_data/'\n",
    "\n",
    "# Define target directories for organized data\n",
    "train_img_dir = PATH_PREFIX + 'data/train_img/'\n",
    "train_mask_dir = PATH_PREFIX + 'data/train_mask/'\n",
    "test_img_dir = PATH_PREFIX + 'data/test_img/'\n",
    "test_mask_dir = PATH_PREFIX + 'data/test_mask/'\n",
    "\n",
    "# Create target directories if they don't exist\n",
    "for directory in [train_img_dir, train_mask_dir, test_img_dir, test_mask_dir]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Function to organize files by type\n",
    "def organize_data_by_type(source_dir, img_dir, mask_dir):\n",
    "    \"\"\"\n",
    "    Move image and mask files from source directory to separate directories.\n",
    "    Only moves files if they don't already exist in the target directory.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(source_dir):\n",
    "        print(f\"⚠ Warning: Source directory not found: {source_dir}\")\n",
    "        return 0, 0\n",
    "    \n",
    "    files = os.listdir(source_dir)\n",
    "    img_count = 0\n",
    "    mask_count = 0\n",
    "    \n",
    "    for filename in files:\n",
    "        source_path = os.path.join(source_dir, filename)\n",
    "        \n",
    "        # Skip if not a file\n",
    "        if not os.path.isfile(source_path):\n",
    "            continue\n",
    "        \n",
    "        # Determine target directory based on filename prefix\n",
    "        if filename.startswith('img_'):\n",
    "            target_path = os.path.join(img_dir, filename)\n",
    "            if not os.path.exists(target_path):\n",
    "                shutil.copy2(source_path, target_path)\n",
    "                img_count += 1\n",
    "        elif filename.startswith('mask_'):\n",
    "            target_path = os.path.join(mask_dir, filename)\n",
    "            if not os.path.exists(target_path):\n",
    "                shutil.copy2(source_path, target_path)\n",
    "                mask_count += 1\n",
    "    \n",
    "    return img_count, mask_count\n",
    "\n",
    "# Organize training data\n",
    "print(\"\\nOrganizing training data...\")\n",
    "train_img_moved, train_mask_moved = organize_data_by_type(\n",
    "    train_data_dir, train_img_dir, train_mask_dir\n",
    ")\n",
    "print(f\"  Images: {train_img_moved} files copied to {train_img_dir}\")\n",
    "print(f\"  Masks: {train_mask_moved} files copied to {train_mask_dir}\")\n",
    "\n",
    "# Organize test data\n",
    "print(\"\\nOrganizing test data...\")\n",
    "test_img_moved, test_mask_moved = organize_data_by_type(\n",
    "    test_data_dir, test_img_dir, test_mask_dir\n",
    ")\n",
    "print(f\"  Images: {test_img_moved} files copied to {test_img_dir}\")\n",
    "print(f\"  Masks: {test_mask_moved} files copied to {test_mask_dir}\")\n",
    "\n",
    "# Verify organization\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA ORGANIZATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train images: {len(os.listdir(train_img_dir)) if os.path.exists(train_img_dir) else 0} files in {train_img_dir}\")\n",
    "print(f\"Train masks: {len(os.listdir(train_mask_dir)) if os.path.exists(train_mask_dir) else 0} files in {train_mask_dir}\")\n",
    "print(f\"Test images: {len(os.listdir(test_img_dir)) if os.path.exists(test_img_dir) else 0} files in {test_img_dir}\")\n",
    "print(f\"Test masks: {len(os.listdir(test_mask_dir)) if os.path.exists(test_mask_dir) else 0} files in {test_mask_dir}\")\n",
    "print(\"=\"*80)\n",
    "print(\"✓ Data organization complete!\")\n",
    "print(\"  - Original files remain in train_data/ and test_data/\")\n",
    "print(\"  - Organized copies are in train_img/, train_mask/, test_img/, test_mask/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d217a",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ===== SET DATA TYPE: \"IMG\" or \"MASK\" =====\n",
    "DATA_TYPE = \"MASK\"  # Use \"IMG\" for images or \"MASK\" for masks\n",
    "# ==========================================\n",
    "\n",
    "# Set directories based on DATA_TYPE\n",
    "if DATA_TYPE == \"MASK\":\n",
    "    train_dir = PATH_PREFIX + 'data/train_mask/'\n",
    "    test_dir = PATH_PREFIX + 'data/test_mask/'\n",
    "else:  # IMG\n",
    "    train_dir = PATH_PREFIX + 'data/train_img/'\n",
    "    test_dir = PATH_PREFIX + 'data/test_img/'\n",
    "\n",
    "train_labels = pd.read_csv(PATH_PREFIX + 'data/train_labels.csv')\n",
    "\n",
    "print(f\"Environment detected. Using path prefix: '{PATH_PREFIX}'\")\n",
    "print(f\"Using DATA_TYPE: {DATA_TYPE}\")\n",
    "print(f\"Train directory: {train_dir}\")\n",
    "print(f\"Test directory: {test_dir}\")\n",
    "\n",
    "# Display dataset info\n",
    "print(f\"\\nTotal training samples: {len(train_labels)}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(train_labels['label'].value_counts())\n",
    "\n",
    "# Check image properties (load from appropriate directory based on DATA_TYPE)\n",
    "if DATA_TYPE == \"MASK\":\n",
    "    sample_file = Image.open(os.path.join(train_dir, 'mask_0000.png'))\n",
    "    print(f\"\\nMask shape: {np.array(sample_file).shape}\")\n",
    "    print(f\"Mask dtype: {np.array(sample_file).dtype}\")\n",
    "    print(f\"Mask unique values: {np.unique(np.array(sample_file))}\")\n",
    "else:\n",
    "    sample_file = Image.open(os.path.join(train_dir, 'img_0000.png'))\n",
    "    print(f\"\\nImage shape: {np.array(sample_file).shape}\")\n",
    "    print(f\"Image dtype: {np.array(sample_file).dtype}\")\n",
    "\n",
    "# Visualize a few samples (always show both img and mask for reference)\n",
    "train_img_dir_viz = PATH_PREFIX + 'data/train_img/'\n",
    "train_mask_dir_viz = PATH_PREFIX + 'data/train_mask/'\n",
    "# Visualize a few samples (always show both img and mask for reference)\n",
    "train_img_dir_viz = PATH_PREFIX + 'data/train_img/'\n",
    "train_mask_dir_viz = PATH_PREFIX + 'data/train_mask/'\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "for i in range(3):\n",
    "    img_name = train_labels.iloc[i]['sample_index']\n",
    "    label = train_labels.iloc[i]['label']\n",
    "    \n",
    "    img = Image.open(os.path.join(train_img_dir_viz, img_name))\n",
    "    mask = Image.open(os.path.join(train_mask_dir_viz, img_name.replace('img_', 'mask_')))\n",
    "    \n",
    "    axes[0, i].imshow(img)\n",
    "    axes[0, i].set_title(f'{img_name}\\n{label}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(mask, cmap='gray')\n",
    "    axes[1, i].set_title(f'Mask for {img_name}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af21e5c",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af5838",
   "metadata": {},
   "source": [
    "## Remove Shrek & Slimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef36cc",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Parse the contaminated indices from the text file\n",
    "contaminated_indices = []\n",
    "with open('shrek_and_slimes.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line and line.isdigit():\n",
    "            contaminated_indices.append(int(line))\n",
    "\n",
    "print(f\"Found {len(contaminated_indices)} contaminated samples to remove\")\n",
    "\n",
    "# Define directories to clean (both img and mask directories)\n",
    "train_img_dir_clean = PATH_PREFIX + 'data/train_img/'\n",
    "train_mask_dir_clean = PATH_PREFIX + 'data/train_mask/'\n",
    "\n",
    "# Remove corresponding image and mask files from both directories\n",
    "removed_count = 0\n",
    "for idx in contaminated_indices:\n",
    "    img_name = f'img_{idx:04d}.png'\n",
    "    mask_name = f'mask_{idx:04d}.png'\n",
    "    \n",
    "    # Remove from train_img directory\n",
    "    img_path = os.path.join(train_img_dir_clean, img_name)\n",
    "    if os.path.exists(img_path):\n",
    "        os.remove(img_path)\n",
    "        removed_count += 1\n",
    "    \n",
    "    # Remove from train_mask directory\n",
    "    mask_path = os.path.join(train_mask_dir_clean, mask_name)\n",
    "    if os.path.exists(mask_path):\n",
    "        os.remove(mask_path)\n",
    "        removed_count += 1\n",
    "\n",
    "print(f\"Removed {removed_count} files from organized directories\")\n",
    "\n",
    "# Update train_labels by removing contaminated indices\n",
    "train_labels = train_labels[~train_labels['sample_index'].str.extract(r'(\\d+)')[0].astype(int).isin(contaminated_indices)]\n",
    "print(f\"Training labels updated: {len(train_labels)} samples remaining\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f213e",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8b4216",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Analyze class distribution after removal\n",
    "class_distribution = train_labels['label'].value_counts().sort_index()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Class Distribution After Removal of Contaminated Images\")\n",
    "print(\"=\"*60)\n",
    "print(class_distribution)\n",
    "print(f\"\\nTotal samples: {len(train_labels)}\")\n",
    "\n",
    "# Calculate statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICS FOR AUGMENTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Class with the most samples (majority)\n",
    "max_class = class_distribution.max()\n",
    "max_class_name = class_distribution.idxmax()\n",
    "print(f\"\\nClass with the most samples (Majority): {max_class_name} ({max_class} samples)\")\n",
    "\n",
    "# Class with the fewest samples (minority)\n",
    "min_class = class_distribution.min()\n",
    "min_class_name = class_distribution.idxmin()\n",
    "print(f\"Class with the fewest samples (Minority): {min_class_name} ({min_class} samples)\")\n",
    "\n",
    "# Imbalance ratio\n",
    "imbalance_ratio = max_class / min_class\n",
    "print(f\"\\nImbalance ratio (Max/Min): {imbalance_ratio:.2f}x\")\n",
    "\n",
    "# Augmentation proposal\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RECOMMENDED AUGMENTATION STRATEGY\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nAugmentations to apply (as suggested by the professor):\")\n",
    "print(\"  1. Horizontal Flip (p=0.5)\")\n",
    "print(\"  2. Vertical Flip (p=0.5)\")\n",
    "print(\"  3. Random Translation (0.2, 0.2)\")\n",
    "print(\"  4. Random Zoom/Scale (0.8, 1.2)\")\n",
    "print(\"  [EXCLUDE: Random Rotation - would change dimensions]\\n\")\n",
    "\n",
    "# STRATEGY: All classes grow until reaching the same target number for ALL\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BALANCED STRATEGY: ALL CLASSES GROW TO A FIXED AND EQUAL NUMBER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ===== MODIFY THE TARGET NUMBER OF SAMPLES HERE =====\n",
    "target_samples = 1000  # Desired number of samples for EACH class\n",
    "# =====================================================\n",
    "\n",
    "print(f\"\\nTarget: {target_samples} samples for EACH class\")\n",
    "\n",
    "augmentation_strategy_balanced = {}\n",
    "total_to_generate = 0\n",
    "\n",
    "for class_name in class_distribution.index:\n",
    "    n_samples = class_distribution[class_name]\n",
    "    n_needed = target_samples - n_samples\n",
    "    n_augmentations = max(0, n_needed)  # We cannot have negative augmentations\n",
    "    \n",
    "    augmentation_strategy_balanced[class_name] = {\n",
    "        'original': n_samples,\n",
    "        'target': target_samples,\n",
    "        'augment_count': n_augmentations,\n",
    "        'ratio_multiplier': n_augmentations / n_samples if n_samples > 0 else 0\n",
    "    }\n",
    "    \n",
    "    total_to_generate += n_augmentations\n",
    "\n",
    "# Projection of the dataset after augmentation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATASET AFTER BALANCED AUGMENTATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Class':<20} {'Original':<15} {'New Augment':<15} {'Augmentations per image':<25} {'Total':<15}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "total_original = 0\n",
    "total_augmented = 0\n",
    "for class_name in class_distribution.index:\n",
    "    n_original = class_distribution[class_name]\n",
    "    n_aug = augmentation_strategy_balanced[class_name]['augment_count']\n",
    "    n_total = n_original + n_aug\n",
    "    \n",
    "    total_original += n_original\n",
    "    total_augmented += n_total\n",
    "    \n",
    "    print(f\"{class_name:<20} {n_original:<15} {n_aug:<15} {augmentation_strategy_balanced[class_name]['ratio_multiplier']:<25.2f} {n_total:<15}\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'TOTAL':<20} {total_original:<15} {total_to_generate:<15} {np.mean([augmentation_strategy_balanced[class_name]['ratio_multiplier'] for class_name in class_distribution.index]):<25.2f} {total_augmented:<15}\")\n",
    "\n",
    "# Visualize the distribution before and after\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Before\n",
    "class_distribution.plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Class Distribution - BEFORE Augmentation', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Number of samples')\n",
    "axes[0].set_xlabel('Class')\n",
    "axes[0].axhline(y=target_samples, color='red', linestyle='--', linewidth=2, label=f'Target: {target_samples}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# After\n",
    "after_augmentation_balanced = {}\n",
    "for class_name in class_distribution.index:\n",
    "    after_augmentation_balanced[class_name] = augmentation_strategy_balanced[class_name]['target']\n",
    "\n",
    "after_series = pd.Series(after_augmentation_balanced)\n",
    "after_series.plot(kind='bar', ax=axes[1], color='seagreen')\n",
    "axes[1].set_title('Class Distribution - AFTER Balanced Augmentation', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Number of samples')\n",
    "axes[1].set_xlabel('Class')\n",
    "axes[1].axhline(y=target_samples, color='red', linestyle='--', linewidth=2, label=f'Target: {target_samples}')\n",
    "axes[1].set_ylim([0, max_class * 1.1])\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f722ec8b",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create folder for augmented data if it doesn't exist\n",
    "# Use DATA_TYPE-specific directory to keep IMG and MASK augmentations separate\n",
    "augmented_dir = PATH_PREFIX + f'data/train_data_augmented_{DATA_TYPE.lower()}/'\n",
    "if not os.path.exists(augmented_dir):\n",
    "    os.makedirs(augmented_dir)\n",
    "    print(f\"Created directory: {augmented_dir}\")\n",
    "else:\n",
    "    existing_files = len(os.listdir(augmented_dir))\n",
    "    print(f\"Directory already exists: {augmented_dir}\")\n",
    "    print(f\"Found {existing_files} existing augmented files for DATA_TYPE={DATA_TYPE}\")\n",
    "\n",
    "# Define augmentations for each class\n",
    "augmentation_transforms = {\n",
    "    'flip': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "    ]),\n",
    "    'translation': transforms.Compose([\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=None),\n",
    "    ]),\n",
    "    'zoom': transforms.Compose([\n",
    "        transforms.RandomAffine(degrees=0, translate=None, scale=(0.8, 1.2)),\n",
    "    ]),\n",
    "    'combined': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STARTING AUGMENTATION PROCESS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Loop through each class and generate augmentations\n",
    "total_augmented = 0\n",
    "\n",
    "for class_name in sorted(augmentation_strategy_balanced.keys()):\n",
    "    info = augmentation_strategy_balanced[class_name]\n",
    "    n_augment = info['augment_count']\n",
    "    \n",
    "    if n_augment == 0:\n",
    "        print(f\"\\n{class_name}: No augmentation needed (already at target)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'-'*80}\")\n",
    "    print(f\"Class: {class_name}\")\n",
    "    print(f\"Augmentations to generate: {n_augment}\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    \n",
    "    # Get original images of this class\n",
    "    class_samples = train_labels[train_labels['label'] == class_name]['sample_index'].tolist()\n",
    "    n_original = len(class_samples)\n",
    "    \n",
    "    # Calculate how many augmentations per original image\n",
    "    aug_per_img = n_augment / n_original\n",
    "    \n",
    "    # For each original image\n",
    "    aug_count = 0\n",
    "    for img_idx, img_name in enumerate(class_samples):\n",
    "        # Determine which file to load based on DATA_TYPE\n",
    "        if DATA_TYPE == \"MASK\":\n",
    "            file_name = img_name.replace('img_', 'mask_')\n",
    "        else:  # IMG\n",
    "            file_name = img_name\n",
    "        \n",
    "        img_path = os.path.join(train_dir, file_name)\n",
    "        \n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"  File not found: {file_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Load the original image/mask\n",
    "        if DATA_TYPE == \"MASK\":\n",
    "            img = Image.open(img_path).convert('L')  # Grayscale for masks\n",
    "        else:  # IMG\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "        img_pil = img.copy()\n",
    "        \n",
    "        # Generate augmentations for this image\n",
    "        n_to_generate = int(np.ceil(aug_per_img)) if img_idx < n_augment % n_original else int(np.floor(aug_per_img))\n",
    "        \n",
    "        for aug_num in range(n_to_generate):\n",
    "            if aug_count <= n_augment:\n",
    "                base_name = file_name.replace('.png', '')\n",
    "\n",
    "                # Choose an augmentation type cyclically\n",
    "                aug_types = list(augmentation_transforms.keys())\n",
    "                aug_type = aug_types[aug_count % len(aug_types)]\n",
    "                transform = augmentation_transforms[aug_type]\n",
    "                img_augmented = transform(img_pil)\n",
    "                augmented_img_name = f\"{base_name}_aug_{aug_num}_{aug_type}.png\"\n",
    "                \n",
    "                # Save augmented image\n",
    "                augmented_img_path = os.path.join(augmented_dir, augmented_img_name)\n",
    "                img_augmented.save(augmented_img_path)\n",
    "                \n",
    "            aug_count += 1\n",
    "        \n",
    "        # Progress update\n",
    "        if (img_idx + 1) % max(1, n_original // 5) == 0 or img_idx == n_original - 1:\n",
    "            print(f\"  Processed {img_idx + 1}/{n_original} original samples ({aug_count} augmentations generated)\")\n",
    "    \n",
    "    total_augmented += aug_count\n",
    "    print(f\"  {class_name}: Completed! {aug_count} augmentations generated\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"AUGMENTATION COMPLETED!\")\n",
    "print(f\"Total augmented images generated: {total_augmented}\")\n",
    "print(f\"Save directory: {augmented_dir}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "\n",
    "# Verify file countprint(f\"First 5 files: {augmented_files[:5]}\")\n",
    "\n",
    "augmented_files = os.listdir(augmented_dir)\n",
    "print(f\"\\nFiles in augmented folder: {len(augmented_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de093d1e",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Define target image size\n",
    "IMG_SIZE = (224, 224)  # Standard size for many CNN architectures\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# ===== GPU OPTIMIZATION SETTINGS =====\n",
    "# Optimal num_workers: 4 * num_GPUs for T4 x2\n",
    "# Auto-detect environment and set appropriate values\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    NUM_WORKERS = min(8, 4 * torch.cuda.device_count())  # 4 workers per GPU\n",
    "    PIN_MEMORY = True  # Faster CPU-to-GPU transfer\n",
    "    PERSISTENT_WORKERS = True if NUM_WORKERS > 0 else False\n",
    "else:\n",
    "    # CPU-only environment\n",
    "    NUM_WORKERS = 0  # Avoid multiprocessing overhead on CPU\n",
    "    PIN_MEMORY = False\n",
    "    PERSISTENT_WORKERS = False\n",
    "# ======================================\n",
    "\n",
    "# Load original + augmented images into tensors\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LOADING BALANCED DATASET (Original + Augmented)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Current DATA_TYPE: {DATA_TYPE}\")\n",
    "print(f\"Augmented directory: {augmented_dir}\")\n",
    "\n",
    "# Check if augmented directory exists and validate files\n",
    "if not os.path.exists(augmented_dir):\n",
    "    print(f\"\\nWARNING: Augmented directory does not exist!\")\n",
    "    print(f\"Expected: {augmented_dir}\")\n",
    "    print(f\"No augmented data will be loaded. Only original images will be used.\")\n",
    "    augmented_files = []\n",
    "else:\n",
    "    # Create list of augmented images\n",
    "    augmented_files = os.listdir(augmented_dir)\n",
    "    print(f\"Augmented images found: {len(augmented_files)}\")\n",
    "    \n",
    "    # Validate that augmented files match DATA_TYPE\n",
    "    if len(augmented_files) > 0:\n",
    "        sample_file = augmented_files[0]\n",
    "        expected_prefix = 'mask_' if DATA_TYPE == \"MASK\" else 'img_'\n",
    "        if not sample_file.startswith(expected_prefix):\n",
    "            print(f\"\\nERROR: Augmented files don't match DATA_TYPE={DATA_TYPE}!\")\n",
    "            print(f\"Found files starting with '{sample_file.split('_')[0]}_' but expected '{expected_prefix}'\")\n",
    "            print(f\"To fix: Either regenerate augmentations or change DATA_TYPE setting.\")\n",
    "            raise ValueError(f\"Augmented data mismatch: files don't match DATA_TYPE={DATA_TYPE}\")\n",
    "        else:\n",
    "            print(f\"Validation passed: Augmented files match DATA_TYPE={DATA_TYPE}\")\n",
    "\n",
    "# Create new dataframe with all images (original + augmented)\n",
    "train_labels_augmented = train_labels.copy()\n",
    "\n",
    "# Add augmented images\n",
    "augmented_rows = []\n",
    "for aug_img_name in augmented_files:\n",
    "    # Extract original file name (works for both img_ and mask_ prefixes)\n",
    "    # Format: {prefix}_{number}_aug_{aug_num}_{aug_type}.png\n",
    "    base_name = aug_img_name.split('_aug_')[0] + '.png'\n",
    "    \n",
    "    # Find the class in the original dataframe\n",
    "    # train_labels uses img_ prefix, so convert if needed\n",
    "    if DATA_TYPE == \"MASK\":\n",
    "        # Augmented file is mask_XXXX, but train_labels has img_XXXX\n",
    "        search_name = base_name.replace('mask_', 'img_')\n",
    "    else:\n",
    "        search_name = base_name\n",
    "    \n",
    "    original_row = train_labels[train_labels['sample_index'] == search_name]\n",
    "    if not original_row.empty:\n",
    "        class_label = original_row.iloc[0]['label']\n",
    "        augmented_rows.append({'sample_index': aug_img_name, 'label': class_label})\n",
    "\n",
    "augmented_df = pd.DataFrame(augmented_rows)\n",
    "train_labels_augmented = pd.concat([train_labels_augmented, augmented_df], ignore_index=True)\n",
    "\n",
    "print(f\"\\nOriginal dataset: {len(train_labels)} samples\")\n",
    "print(f\"Augmented dataset: {len(train_labels_augmented)} samples\")\n",
    "print(f\"\\nDistribution in augmented dataset:\")\n",
    "print(train_labels_augmented['label'].value_counts().sort_index())\n",
    "\n",
    "# Load images into tensors (original + augmented)\n",
    "def load_augmented_images_to_tensor(train_dir, augmented_dir, labels_df, img_size=IMG_SIZE, data_type=\"MASK\"):\n",
    "    \"\"\"Load original and augmented images into tensors\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx, row in labels_df.iterrows():\n",
    "        img_name = row['sample_index']\n",
    "        label = row['label']\n",
    "        \n",
    "        # Determine which folder to load from\n",
    "        if '_aug_' not in img_name:\n",
    "            # Original image - convert filename if needed for masks\n",
    "            if data_type == \"MASK\":\n",
    "                file_name = img_name.replace('img_', 'mask_')\n",
    "            else:\n",
    "                file_name = img_name\n",
    "            img_path = os.path.join(train_dir, file_name)\n",
    "        else:\n",
    "            # Augmented image - already has correct prefix\n",
    "            img_path = os.path.join(augmented_dir, img_name)\n",
    "        \n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"⚠ Warning: Image not found: {img_path}\")\n",
    "            continue\n",
    "        try:\n",
    "            if data_type == \"MASK\":\n",
    "                # Load as grayscale and convert to 3-channel\n",
    "                img = Image.open(img_path).convert('L')\n",
    "                img = img.resize(img_size, Image.BILINEAR)\n",
    "                img_array = np.array(img)\n",
    "                img_array = np.stack([img_array, img_array, img_array], axis=-1)\n",
    "            else:\n",
    "                # Load as RGB\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img = img.resize(img_size, Image.BILINEAR)\n",
    "                img_array = np.array(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to load image {img_path}: {e}\")\n",
    "            continue\n",
    "        images.append(img_array)\n",
    "        labels.append(label)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    images = np.array(images)\n",
    "    images_tensor = torch.from_numpy(images).permute(0, 3, 1, 2).float() / 255.0\n",
    "    \n",
    "    label_map = {'Triple negative': 0, 'Luminal A': 1, 'Luminal B': 2, 'HER2(+)': 3}\n",
    "    label_indices = [label_map[label] for label in labels]\n",
    "    labels_tensor = torch.tensor(label_indices, dtype=torch.long)\n",
    "    \n",
    "    return images_tensor, labels_tensor, label_map\n",
    "\n",
    "print(\"\\nLoading images into tensors...\")\n",
    "X_train_augmented, y_train_augmented, label_map = load_augmented_images_to_tensor(\n",
    "    train_dir, augmented_dir, train_labels_augmented, IMG_SIZE, DATA_TYPE\n",
    ")\n",
    "\n",
    "print(f\"Images tensor shape: {X_train_augmented.shape}\")\n",
    "print(f\"Labels tensor shape: {y_train_augmented.shape}\")\n",
    "\n",
    "# Split training/validation (stratified)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_augmented, y_train_augmented, test_size=0.2, random_state=42, stratify=y_train_augmented\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set augmented: {X_train.shape[0]} samples\")\n",
    "print(f\"Validation set augmented: {X_val.shape[0]} samples\")\n",
    "\n",
    "# Create new DataLoaders with GPU optimizations\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "\n",
    "# DataLoader configuration (conditional persistent_workers)\n",
    "train_loader_kwargs = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': True,\n",
    "    'num_workers': NUM_WORKERS,\n",
    "    'pin_memory': PIN_MEMORY\n",
    "}\n",
    "val_loader_kwargs = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': False,\n",
    "    'num_workers': NUM_WORKERS,\n",
    "    'pin_memory': PIN_MEMORY\n",
    "}\n",
    "# Only add persistent_workers if num_workers > 0 (not supported otherwise)\n",
    "if NUM_WORKERS > 0:\n",
    "    train_loader_kwargs['persistent_workers'] = PERSISTENT_WORKERS\n",
    "    val_loader_kwargs['persistent_workers'] = PERSISTENT_WORKERS\n",
    "\n",
    "train_loader = DataLoader(train_dataset, **train_loader_kwargs)\n",
    "val_loader = DataLoader(val_dataset, **val_loader_kwargs)\n",
    "\n",
    "print(f\"Optimization: {NUM_WORKERS} workers, pin_memory={PIN_MEMORY}, persistent_workers={PERSISTENT_WORKERS}\")\n",
    "\n",
    "print(f\"\\nCreated DataLoaders:\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Train batches: {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1673d8fa",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load all images and labels into tensors\n",
    "def load_images_to_tensor(data_dir, img_size=IMG_SIZE):\n",
    "    \"\"\"Load all images from directory into a tensor with resizing\"\"\"\n",
    "    # Determine which files to load based on DATA_TYPE\n",
    "    if DATA_TYPE == \"MASK\":\n",
    "        image_files = sorted([f for f in os.listdir(data_dir) if f.startswith('mask_')])\n",
    "    else:  # IMG\n",
    "        image_files = sorted([f for f in os.listdir(data_dir) if f.startswith('img_')])\n",
    "    \n",
    "    images = []\n",
    "    for img_name in image_files:\n",
    "        img_path = os.path.join(data_dir, img_name)\n",
    "        \n",
    "        # Load image with appropriate mode based on DATA_TYPE\n",
    "        if DATA_TYPE == \"MASK\":\n",
    "            img = Image.open(img_path).convert('L')  # Grayscale for masks\n",
    "            # Convert grayscale to 3-channel for compatibility with model\n",
    "            img_array = np.array(img.resize(img_size, Image.BILINEAR))\n",
    "            img_array = np.stack([img_array, img_array, img_array], axis=-1)\n",
    "        else:  # IMG\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img = img.resize(img_size, Image.BILINEAR)\n",
    "            img_array = np.array(img)\n",
    "        \n",
    "        images.append(img_array)\n",
    "    \n",
    "    # Stack into numpy array: (N, H, W, C)\n",
    "    images = np.array(images)\n",
    "    # Convert to tensor and permute to (N, C, H, W)\n",
    "    images_tensor = torch.from_numpy(images).permute(0, 3, 1, 2).float() / 255.0\n",
    "    \n",
    "    return images_tensor, image_files\n",
    "\n",
    "# Load test data\n",
    "print(f\"\\nLoading test data using DATA_TYPE: {DATA_TYPE}\")\n",
    "X_test, test_filenames = load_images_to_tensor(test_dir)\n",
    "print(f\"Test images shape: {X_test.shape}\")\n",
    "\n",
    "test_dataset = TensorDataset(X_test)\n",
    "\n",
    "# Create DataLoader with GPU optimizations\n",
    "test_loader_kwargs = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': False,\n",
    "    'num_workers': NUM_WORKERS,\n",
    "    'pin_memory': PIN_MEMORY\n",
    "}\n",
    "if NUM_WORKERS > 0:\n",
    "    test_loader_kwargs['persistent_workers'] = PERSISTENT_WORKERS\n",
    "\n",
    "test_loader = DataLoader(test_dataset, **test_loader_kwargs)\n",
    "\n",
    "print(f\"\\nDataLoader created:\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "print(f\"Optimization: {NUM_WORKERS} workers, pin_memory={PIN_MEMORY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6b729",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]  # (C, H, W)\n",
    "num_classes = len(label_map)\n",
    "\n",
    "# ===== MULTI-GPU SETUP =====\n",
    "# Check for multiple GPUs and set up DataParallel\n",
    "if torch.cuda.is_available():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    device = torch.device('cuda:0')\n",
    "    print(f\"Found {num_gpus} GPU(s) available:\")\n",
    "    for i in range(num_gpus):\n",
    "        print(f\" GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    if num_gpus > 1:\n",
    "        print(f\"Multi-GPU training enabled: Will use {num_gpus} GPUs with DataParallel\")\n",
    "    else:\n",
    "        print(f\"Single GPU training\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    num_gpus = 0\n",
    "    print(\"No GPU available, using CPU\")\n",
    "# ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00880a6d",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Number of training epochs\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 500\n",
    "PATIENCE = 50\n",
    "\n",
    "# Regularisation\n",
    "DROPOUT_RATE = 0.2         # Dropout probability\n",
    "L1_LAMBDA = 0            # L1 penalty\n",
    "L2_LAMBDA = 0            # L2 penalty\n",
    "\n",
    "# Set up loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Print the defined parameters\n",
    "print(\"Epochs:\", EPOCHS)\n",
    "print(\"Batch Size:\", BATCH_SIZE)\n",
    "print(\"Learning Rate:\", LEARNING_RATE)\n",
    "print(\"Dropout Rate:\", DROPOUT_RATE)\n",
    "print(\"L1 Penalty:\", L1_LAMBDA)\n",
    "print(\"L2 Penalty:\", L2_LAMBDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b3fe4f",
   "metadata": {},
   "source": [
    "# Download Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f6983",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torchvision.models import ResNet18_Weights, ResNet50_Weights, EfficientNet_B0_Weights, EfficientNet_B3_Weights, VGG16_Weights\n",
    "\n",
    "# ===== UNCOMMENT THE MODEL YOU WANT TO USE =====\n",
    "\n",
    "# ResNet-18 (Smaller, faster)\n",
    "model_pretrained = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "MODEL_NAME = \"resnet18\"\n",
    "\n",
    "# ResNet-50 (Deeper, more powerful)\n",
    "# model_pretrained = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "# MODEL_NAME = \"resnet50\"\n",
    "\n",
    "# EfficientNet-B0 (Efficient, good balance)\n",
    "# model_pretrained = models.efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "# MODEL_NAME = \"efficientnet_b0\"\n",
    "\n",
    "# EfficientNet-B3 (More powerful EfficientNet)\n",
    "# model_pretrained = models.efficientnet_b3(weights=EfficientNet_B3_Weights.IMAGENET1K_V1)\n",
    "# MODEL_NAME = \"efficientnet_b3\"\n",
    "\n",
    "# VGG-16 (Classic architecture)\n",
    "# model_pretrained = models.vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "# MODEL_NAME = \"vgg16\"\n",
    "\n",
    "# ===============================================\n",
    "\n",
    "print(f\"Loaded pretrained model: {MODEL_NAME}\")\n",
    "print(f\"Model architecture:\\n{model_pretrained}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a112fac8",
   "metadata": {},
   "source": [
    "## Transfer Learning Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30277733",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# ===== STEP 1: Freeze all layers in the feature extractor =====\n",
    "for param in model_pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"\\nAll feature extractor weights frozen\")\n",
    "\n",
    "# ===== STEP 2: Replace the classifier head =====\n",
    "# Different models have different classifier layer names\n",
    "if MODEL_NAME.startswith('resnet'):\n",
    "    # ResNet has 'fc' as final layer\n",
    "    num_features = model_pretrained.fc.in_features\n",
    "    model_pretrained.fc = nn.Sequential(\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    print(f\"Replaced ResNet classifier: {num_features} -> 256 -> {num_classes}\")\n",
    "    \n",
    "elif MODEL_NAME.startswith('efficientnet'):\n",
    "    # EfficientNet has 'classifier' as final layer\n",
    "    num_features = model_pretrained.classifier[1].in_features\n",
    "    model_pretrained.classifier = nn.Sequential(\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    print(f\"Replaced EfficientNet classifier: {num_features} -> 256 -> {num_classes}\")\n",
    "    \n",
    "elif MODEL_NAME.startswith('vgg'):\n",
    "    # VGG has 'classifier' as a sequential module\n",
    "    num_features = model_pretrained.classifier[0].in_features\n",
    "    model_pretrained.classifier = nn.Sequential(\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    print(f\"Replaced VGG classifier: {num_features} -> 512 -> 256 -> {num_classes}\")\n",
    "\n",
    "# Move model to device FIRST\n",
    "model_pretrained = model_pretrained.to(device)\n",
    "\n",
    "# Then wrap with DataParallel if multiple GPUs are available\n",
    "if num_gpus > 1:\n",
    "    model_pretrained = nn.DataParallel(model_pretrained)\n",
    "    print(f\"Model wrapped with DataParallel for {num_gpus} GPUs\")\n",
    "\n",
    "print(f\"\\nModel ready for transfer learning on {device} ({num_gpus} GPU(s))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfb0fa5",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Display model architecture summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "summary(model_pretrained, input_size=input_shape)\n",
    "\n",
    "# Count trainable vs frozen parameters\n",
    "total_params = sum(p.numel() for p in model_pretrained.parameters())\n",
    "trainable_params = sum(p.numel() for p in model_pretrained.parameters() if p.requires_grad)\n",
    "frozen_params = total_params - trainable_params\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PARAMETER STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters (classifier only): {trainable_params:,}\")\n",
    "print(f\"Frozen parameters (feature extractor): {frozen_params:,}\")\n",
    "print(f\"Percentage trainable: {100 * trainable_params / total_params:.2f}%\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d3174",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define optimizer - ONLY train classifier parameters (feature extractor is frozen)\n",
    "# Filter to get only parameters that require gradients (classifier layers)\n",
    "trainable_params = filter(lambda p: p.requires_grad, model_pretrained.parameters())\n",
    "optimizer = torch.optim.AdamW(trainable_params, lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n",
    "\n",
    "# Enable mixed precision training for GPU acceleration\n",
    "scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "\n",
    "print(f\"✓ Optimizer configured to train only classifier layers\")\n",
    "print(f\"  Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"  Weight decay (L2): {L2_LAMBDA}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9552438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Memory and Utilization Monitoring\n",
    "if torch.cuda.is_available():\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GPU STATUS BEFORE TRAINING\")\n",
    "    print(\"=\"*80)\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"\\nGPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"  Memory Allocated: {torch.cuda.memory_allocated(i) / 1024**3:.2f} GB\")\n",
    "        print(f\"  Memory Reserved: {torch.cuda.memory_reserved(i) / 1024**3:.2f} GB\")\n",
    "        print(f\"  Max Memory Allocated: {torch.cuda.max_memory_allocated(i) / 1024**3:.2f} GB\")\n",
    "    print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f5f56",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a4724",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize best model tracking variables\n",
    "best_model = None\n",
    "best_performance = float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e4dd6",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n",
    "    \"\"\"\n",
    "    Perform one complete training epoch through the entire training dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to train\n",
    "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
    "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
    "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "        l1_lambda (float): Lambda for L1 regularization\n",
    "        l2_lambda (float): Lambda for L2 regularization\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Iterate through training batches\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        # Move data to device (GPU/CPU)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Clear gradients from previous step\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Forward pass with mixed precision (if CUDA available)\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, targets)\n",
    "\n",
    "            # Add L1 and L2 regularization\n",
    "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n",
    "            loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n",
    "\n",
    "\n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        all_predictions.append(predictions.cpu().numpy())\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_f1 = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='weighted'\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b99110",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Perform one complete validation epoch through the entire validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n",
    "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
    "        criterion (nn.Module): Loss function used to calculate validation loss\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n",
    "\n",
    "    Note:\n",
    "        This function automatically sets the model to evaluation mode and disables\n",
    "        gradient computation for efficiency during validation.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Disable gradient computation for validation\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            # Move data to device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass with mixed precision (if CUDA available)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model(inputs)\n",
    "                loss = criterion(logits, targets)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_accuracy = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='weighted'\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05834891",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n",
    "        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
    "        restore_best_weights=True, writer=None, verbose=10, experiment_name=\"\"):\n",
    "    \"\"\"\n",
    "    Train the neural network model on the training data and validate on the validation data.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to train\n",
    "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
    "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
    "        epochs (int): Number of training epochs\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
    "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
    "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "        l1_lambda (float): L1 regularization coefficient (default: 0)\n",
    "        l2_lambda (float): L2 regularization coefficient (default: 0)\n",
    "        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n",
    "        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n",
    "        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n",
    "        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n",
    "        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n",
    "        verbose (int, optional): Frequency of printing training progress (default: 10)\n",
    "        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, training_history) - Trained model and metrics history\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize metrics tracking\n",
    "    training_history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_f1': [], 'val_f1': []\n",
    "    }\n",
    "\n",
    "    # Configure early stopping if patience is set\n",
    "    if patience > 0:\n",
    "        patience_counter = 0\n",
    "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
    "        best_epoch = 0\n",
    "\n",
    "    print(f\"Training {epochs} epochs...\")\n",
    "\n",
    "    # Main training loop: iterate through epochs\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        # Forward pass through training data, compute gradients, update weights\n",
    "        train_loss, train_f1 = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n",
    "        )\n",
    "\n",
    "        # Evaluate model on validation data without updating weights\n",
    "        val_loss, val_f1 = validate_one_epoch(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        # Store metrics for plotting and analysis\n",
    "        training_history['train_loss'].append(train_loss)\n",
    "        training_history['val_loss'].append(val_loss)\n",
    "        training_history['train_f1'].append(train_f1)\n",
    "        training_history['val_f1'].append(val_f1)\n",
    "\n",
    "        # Print progress every N epochs or on first epoch\n",
    "        if verbose > 0:\n",
    "            if epoch % verbose == 0 or epoch == 1:\n",
    "                print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
    "                    f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n",
    "                    f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n",
    "\n",
    "        # Early stopping logic: monitor metric and save best model\n",
    "        if patience > 0:\n",
    "            current_metric = training_history[evaluation_metric][-1]\n",
    "            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
    "\n",
    "            if is_improvement:\n",
    "                best_metric = current_metric\n",
    "                best_epoch = epoch\n",
    "                torch.save(model.state_dict(),\"models/\"+experiment_name+'_model.pt')\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping triggered after {epoch} epochs.\")\n",
    "                    break\n",
    "\n",
    "    # Restore best model weights if early stopping was used\n",
    "    if restore_best_weights and patience > 0:\n",
    "        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n",
    "        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n",
    "\n",
    "    # Save final model if no early stopping\n",
    "    if patience == 0:\n",
    "        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
    "\n",
    "    # Close TensorBoard writer\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "\n",
    "    return model, training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1777cc86",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0c487",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Set experiment name for this run\n",
    "EXPERIMENT_NAME = f\"pretrained_{MODEL_NAME}_augmented\"\n",
    "\n",
    "# Train with augmented (balanced) dataset\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"TRAINING WITH PRETRAINED {MODEL_NAME.upper()} - TRANSFER LEARNING\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train loader: {len(train_loader)} batches\")\n",
    "print(f\"Val loader: {len(val_loader)} batches\")\n",
    "print(f\"Strategy: Frozen feature extractor + Trainable classifier\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Train model and track training history using AUGMENTED dataset\n",
    "model_pretrained, history = fit(\n",
    "    model=model_pretrained,\n",
    "    train_loader=train_loader,  # ← USE AUGMENTED LOADER\n",
    "    val_loader=val_loader,      # ← USE AUGMENTED LOADER\n",
    "    epochs=EPOCHS,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scaler=scaler,\n",
    "    device=device,\n",
    "    verbose=1,\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    patience=PATIENCE\n",
    ")\n",
    "\n",
    "# Update best model if current performance is superior\n",
    "if history['val_f1'][-1] > best_performance:\n",
    "    best_model = model_pretrained    \n",
    "    best_performance = history['val_f1'][-1]\n",
    "    print(f\"\\n✓ New best model saved with F1 Score: {best_performance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71698433",
   "metadata": {},
   "source": [
    "# Identify High-Loss Samples (Data Quality Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35608f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_per_sample_loss(model, dataset, criterion, device):\n",
    "    \"\"\"\n",
    "    Calculate loss for each individual sample in the dataset.\n",
    "    \n",
    "    Returns:\n",
    "        losses: numpy array of per-sample losses\n",
    "        predictions: numpy array of predicted labels\n",
    "        targets: numpy array of true labels\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    losses = []\n",
    "    predictions = []\n",
    "    targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(dataset)):\n",
    "            inputs, target = dataset[i]\n",
    "            inputs = inputs.unsqueeze(0).to(device)  # Add batch dimension\n",
    "            target_tensor = torch.tensor([target]).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model(inputs)\n",
    "                loss = criterion(logits, target_tensor)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            predictions.append(logits.argmax(dim=1).cpu().item())\n",
    "            targets.append(target)\n",
    "    \n",
    "    return np.array(losses), np.array(predictions), np.array(targets)\n",
    "\n",
    "print(\"Calculating per-sample losses on training set...\")\n",
    "train_losses, train_preds, train_targets = calculate_per_sample_loss(\n",
    "    model_pretrained, train_dataset, criterion, device\n",
    ")\n",
    "\n",
    "print(f\"\\nLoss statistics:\")\n",
    "print(f\"Mean loss: {train_losses.mean():.4f}\")\n",
    "print(f\"Median loss: {np.median(train_losses):.4f}\")\n",
    "print(f\"Max loss: {train_losses.max():.4f}\")\n",
    "print(f\"Min loss: {train_losses.min():.4f}\")\n",
    "print(f\"Std loss: {train_losses.std():.4f}\")\n",
    "\n",
    "# Identify high-loss samples\n",
    "top_k = 50  # Number of worst samples to examine\n",
    "worst_indices = np.argsort(train_losses)[-top_k:][::-1]  # Highest losses first\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"TOP {top_k} HIGHEST LOSS SAMPLES (Potential Data Quality Issues)\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"{'Index':<10} {'Loss':<12} {'True Label':<20} {'Predicted':<20} {'Correct':<10}\")\n",
    "print('-' * 80)\n",
    "\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "problematic_samples = []\n",
    "\n",
    "for rank, idx in enumerate(worst_indices, 1):\n",
    "    loss = train_losses[idx]\n",
    "    true_label = reverse_label_map[train_targets[idx]]\n",
    "    pred_label = reverse_label_map[train_preds[idx]]\n",
    "    is_correct = train_targets[idx] == train_preds[idx]\n",
    "    \n",
    "    problematic_samples.append({\n",
    "        'dataset_index': idx,\n",
    "        'loss': loss,\n",
    "        'true_label': true_label,\n",
    "        'predicted_label': pred_label,\n",
    "        'correct': is_correct\n",
    "    })\n",
    "    \n",
    "    if rank <= 20:  # Print top 20\n",
    "        print(f\"{idx:<10} {loss:<12.4f} {true_label:<20} {pred_label:<20} {str(is_correct):<10}\")\n",
    "\n",
    "print('=' * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9056c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the worst samples\n",
    "fig, axes = plt.subplots(5, 5, figsize=(20, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "print(f\"\\nVisualizing top 25 highest-loss samples...\")\n",
    "\n",
    "for i in range(min(25, len(worst_indices))):\n",
    "    idx = worst_indices[i]\n",
    "    loss = train_losses[idx]\n",
    "    true_label = reverse_label_map[train_targets[idx]]\n",
    "    pred_label = reverse_label_map[train_preds[idx]]\n",
    "    \n",
    "    # Get the image tensor\n",
    "    img_tensor, _ = train_dataset[idx]\n",
    "    \n",
    "    # Convert tensor to displayable image (C, H, W) -> (H, W, C)\n",
    "    img = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "    \n",
    "    # Display image\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(\n",
    "        f\"Rank {i+1}: Loss={loss:.3f}\\n\"\n",
    "        f\"True: {true_label}\\n\"\n",
    "        f\"Pred: {pred_label}\",\n",
    "        fontsize=9,\n",
    "        color='red' if true_label != pred_label else 'green'\n",
    "    )\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Top 25 Highest Loss Training Samples', fontsize=16, y=1.001)\n",
    "plt.show()\n",
    "\n",
    "# Plot loss distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Histogram of losses\n",
    "axes[0].hist(train_losses, bins=100, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "axes[0].axvline(train_losses.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {train_losses.mean():.3f}')\n",
    "axes[0].axvline(np.median(train_losses), color='green', linestyle='--', linewidth=2, label=f'Median: {np.median(train_losses):.3f}')\n",
    "axes[0].set_xlabel('Loss')\n",
    "axes[0].set_ylabel('Number of Samples')\n",
    "axes[0].set_title('Distribution of Per-Sample Losses')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Sorted losses\n",
    "sorted_losses = np.sort(train_losses)\n",
    "axes[1].plot(sorted_losses, color='steelblue', linewidth=2)\n",
    "axes[1].axhline(train_losses.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {train_losses.mean():.3f}')\n",
    "axes[1].set_xlabel('Sample Rank (sorted)')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Sorted Per-Sample Losses')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69598fe0",
   "metadata": {},
   "source": [
    "## Remove High-Loss Samples (Data Cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80ec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold for removing high-loss samples\n",
    "# Option 1: Remove top N samples with highest loss\n",
    "REMOVE_TOP_N = 100  # Adjust this value based on visual inspection\n",
    "\n",
    "# Option 2: Remove samples above a certain loss percentile\n",
    "LOSS_PERCENTILE_THRESHOLD = 95  # Remove top 5% highest losses\n",
    "\n",
    "# Choose method (uncomment one)\n",
    "METHOD = \"top_n\"  # Remove top N samples\n",
    "# METHOD = \"percentile\"  # Remove by percentile\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"REMOVING HIGH-LOSS SAMPLES\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "if METHOD == \"top_n\":\n",
    "    # First, we need to get the actual worst indices (not limited by top_k)\n",
    "    # Re-calculate worst_indices for removal (up to REMOVE_TOP_N)\n",
    "    all_worst_indices = np.argsort(train_losses)[::-1]  # All samples sorted by loss (highest first)\n",
    "    n_to_remove = min(REMOVE_TOP_N, len(train_losses))  # Don't try to remove more than available\n",
    "    samples_to_remove = all_worst_indices[:n_to_remove]\n",
    "    threshold_loss = train_losses[samples_to_remove[-1]]\n",
    "    print(f\"Method: Remove top {n_to_remove} samples\")\n",
    "    print(f\"Loss threshold: {threshold_loss:.4f}\")\n",
    "else:\n",
    "    # Remove samples above percentile threshold\n",
    "    threshold_loss = np.percentile(train_losses, LOSS_PERCENTILE_THRESHOLD)\n",
    "    samples_to_remove = np.where(train_losses > threshold_loss)[0]\n",
    "    print(f\"Method: Remove samples above {LOSS_PERCENTILE_THRESHOLD}th percentile\")\n",
    "    print(f\"Loss threshold: {threshold_loss:.4f}\")\n",
    "\n",
    "print(f\"Samples to remove: {len(samples_to_remove)}\")\n",
    "print(f\"Original training set size: {len(train_dataset)}\")\n",
    "print(f\"New training set size: {len(train_dataset) - len(samples_to_remove)}\")\n",
    "\n",
    "# Create mask for samples to keep\n",
    "keep_mask = np.ones(len(train_dataset), dtype=bool)\n",
    "keep_mask[samples_to_remove] = False\n",
    "\n",
    "# Filter the datasets\n",
    "X_train_cleaned = X_train[keep_mask]\n",
    "y_train_cleaned = y_train[keep_mask]\n",
    "\n",
    "print(f\"\\nCleaned dataset shapes:\")\n",
    "print(f\"X_train: {X_train_cleaned.shape}\")\n",
    "print(f\"y_train: {y_train_cleaned.shape}\")\n",
    "\n",
    "# Check class distribution after cleaning\n",
    "print(f\"\\nClass distribution after cleaning:\")\n",
    "unique, counts = np.unique(y_train_cleaned.cpu().numpy(), return_counts=True)\n",
    "for label_idx, count in zip(unique, counts):\n",
    "    label_name = reverse_label_map[label_idx]\n",
    "    print(f\"  {label_name}: {count} samples\")\n",
    "\n",
    "# Create new cleaned DataLoader\n",
    "train_dataset_cleaned = TensorDataset(X_train_cleaned, y_train_cleaned)\n",
    "\n",
    "train_loader_kwargs = {\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'shuffle': True,\n",
    "    'num_workers': NUM_WORKERS,\n",
    "    'pin_memory': PIN_MEMORY\n",
    "}\n",
    "if NUM_WORKERS > 0:\n",
    "    train_loader_kwargs['persistent_workers'] = PERSISTENT_WORKERS\n",
    "\n",
    "train_loader_cleaned = DataLoader(train_dataset_cleaned, **train_loader_kwargs)\n",
    "\n",
    "print(f\"\\nNew DataLoader created:\")\n",
    "print(f\"Train batches: {len(train_loader_cleaned)}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc769f9",
   "metadata": {},
   "source": [
    "## Retrain with Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f105385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize model with fresh weights\n",
    "import torch.nn as nn\n",
    "\n",
    "# ===== STEP 1: Freeze all layers in the feature extractor =====\n",
    "for param in model_pretrained.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print(\"\\nAll feature extractor weights frozen\")\n",
    "\n",
    "# ===== STEP 2: Replace the classifier head =====\n",
    "# Different models have different classifier layer names\n",
    "if MODEL_NAME.startswith('resnet'):\n",
    "    # ResNet has 'fc' as final layer\n",
    "    num_features = model_pretrained.fc.in_features\n",
    "    model_pretrained.fc = nn.Sequential(\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    print(f\"Replaced ResNet classifier: {num_features} -> 256 -> {num_classes}\")\n",
    "    \n",
    "elif MODEL_NAME.startswith('efficientnet'):\n",
    "    # EfficientNet has 'classifier' as final layer\n",
    "    num_features = model_pretrained.classifier[1].in_features\n",
    "    model_pretrained.classifier = nn.Sequential(\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(num_features, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    print(f\"Replaced EfficientNet classifier: {num_features} -> 256 -> {num_classes}\")\n",
    "    \n",
    "elif MODEL_NAME.startswith('vgg'):\n",
    "    # VGG has 'classifier' as a sequential module\n",
    "    num_features = model_pretrained.classifier[0].in_features\n",
    "    model_pretrained.classifier = nn.Sequential(\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(num_features, 512),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(DROPOUT_RATE),\n",
    "        nn.Linear(256, num_classes)\n",
    "    )\n",
    "    print(f\"Replaced VGG classifier: {num_features} -> 512 -> 256 -> {num_classes}\")\n",
    "\n",
    "# Move model to device FIRST\n",
    "model_pretrained = model_pretrained.to(device)\n",
    "\n",
    "# Then wrap with DataParallel if multiple GPUs are available\n",
    "if num_gpus > 1:\n",
    "    model_pretrained = nn.DataParallel(model_pretrained)\n",
    "    print(f\"Model wrapped with DataParallel for {num_gpus} GPUs\")\n",
    "\n",
    "print(f\"\\nModel ready for transfer learning on {device} ({num_gpus} GPU(s))\")\n",
    "\n",
    "# Reinitialize optimizer and scaler\n",
    "optimizer_cleaned = torch.optim.AdamW(model_pretrained.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n",
    "scaler_cleaned = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "\n",
    "# Set experiment name for cleaned model\n",
    "EXPERIMENT_NAME_CLEANED = f\"{EXPERIMENT_NAME}_cleaned\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING WITH CLEANED DATASET (High-loss samples removed)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train loader: {len(train_loader_cleaned)} batches\")\n",
    "print(f\"Val loader: {len(val_loader)} batches (unchanged)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Train model with cleaned data\n",
    "cnn_model_cleaned, history_cleaned = fit(\n",
    "    model=cnn_model_cleaned,\n",
    "    train_loader=train_loader_cleaned,  # ← CLEANED LOADER\n",
    "    val_loader=val_loader,              # Validation set unchanged\n",
    "    epochs=EPOCHS,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer_cleaned,\n",
    "    scaler=scaler_cleaned,\n",
    "    device=device,\n",
    "    verbose=1,\n",
    "    experiment_name=EXPERIMENT_NAME_CLEANED,\n",
    "    patience=PATIENCE\n",
    ")\n",
    "\n",
    "# Update best model if current performance is superior\n",
    "if history_cleaned['val_f1'][-1] > best_performance:\n",
    "    best_model = cnn_model_cleaned\n",
    "    best_performance = history_cleaned['val_f1'][-1]\n",
    "    print(f\"\\n New best model saved with F1 Score: {best_performance:.4f}\")\n",
    "    print(f\" Improvement from data cleaning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf5615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare original vs cleaned training\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Loss comparison\n",
    "axes[0, 0].plot(history['train_loss'], label='Original - Train', alpha=0.6, linestyle='--', color='#1f77b4')\n",
    "axes[0, 0].plot(history['val_loss'], label='Original - Val', alpha=0.8, color='#1f77b4')\n",
    "axes[0, 0].plot(history_cleaned['train_loss'], label='Cleaned - Train', alpha=0.6, linestyle='--', color='#ff7f0e')\n",
    "axes[0, 0].plot(history_cleaned['val_loss'], label='Cleaned - Val', alpha=0.8, color='#ff7f0e')\n",
    "axes[0, 0].set_title('Loss Comparison: Original vs Cleaned Data')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# F1 Score comparison\n",
    "axes[0, 1].plot(history['train_f1'], label='Original - Train', alpha=0.6, linestyle='--', color='#1f77b4')\n",
    "axes[0, 1].plot(history['val_f1'], label='Original - Val', alpha=0.8, color='#1f77b4')\n",
    "axes[0, 1].plot(history_cleaned['train_f1'], label='Cleaned - Train', alpha=0.6, linestyle='--', color='#ff7f0e')\n",
    "axes[0, 1].plot(history_cleaned['val_f1'], label='Cleaned - Val', alpha=0.8, color='#ff7f0e')\n",
    "axes[0, 1].set_title('F1 Score Comparison: Original vs Cleaned Data')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('F1 Score')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Training loss only (zoomed)\n",
    "axes[1, 0].plot(history['train_loss'], label='Original', alpha=0.8, color='#1f77b4')\n",
    "axes[1, 0].plot(history_cleaned['train_loss'], label='Cleaned', alpha=0.8, color='#ff7f0e')\n",
    "axes[1, 0].set_title('Training Loss: Original vs Cleaned Data')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Training Loss')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Validation F1 only (zoomed)\n",
    "axes[1, 1].plot(history['val_f1'], label='Original', alpha=0.8, color='#1f77b4', marker='o')\n",
    "axes[1, 1].plot(history_cleaned['val_f1'], label='Cleaned', alpha=0.8, color='#ff7f0e', marker='s')\n",
    "axes[1, 1].set_title('Validation F1 Score: Original vs Cleaned Data')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Validation F1 Score')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nOriginal Dataset:\")\n",
    "print(f\"  Best Val F1: {max(history['val_f1']):.4f}\")\n",
    "print(f\"  Final Val F1: {history['val_f1'][-1]:.4f}\")\n",
    "print(f\"  Final Train Loss: {history['train_loss'][-1]:.4f}\")\n",
    "print(f\"  Final Val Loss: {history['val_loss'][-1]:.4f}\")\n",
    "\n",
    "print(f\"\\nCleaned Dataset (removed {len(samples_to_remove)} high-loss samples):\")\n",
    "print(f\"  Best Val F1: {max(history_cleaned['val_f1']):.4f}\")\n",
    "print(f\"  Final Val F1: {history_cleaned['val_f1'][-1]:.4f}\")\n",
    "print(f\"  Final Train Loss: {history_cleaned['train_loss'][-1]:.4f}\")\n",
    "print(f\"  Final Val Loss: {history_cleaned['val_loss'][-1]:.4f}\")\n",
    "\n",
    "improvement = max(history_cleaned['val_f1']) - max(history['val_f1'])\n",
    "print(f\"\\nImprovement: {improvement:+.4f} ({improvement*100:+.2f}%)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0addc8c",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5e407",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get validation predictions\n",
    "val_preds = []\n",
    "val_targets = []\n",
    "best_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        logits = best_model(inputs)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        \n",
    "        val_preds.append(preds)\n",
    "        val_targets.append(targets.numpy())\n",
    "\n",
    "val_preds = np.concatenate(val_preds)\n",
    "val_targets = np.concatenate(val_targets)\n",
    "\n",
    "# Calculate overall validation set metrics\n",
    "val_acc = accuracy_score(val_targets, val_preds)\n",
    "val_prec = precision_score(val_targets, val_preds, average='weighted')\n",
    "val_rec = recall_score(val_targets, val_preds, average='weighted')\n",
    "val_f1 = f1_score(val_targets, val_preds, average='weighted')\n",
    "\n",
    "print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n",
    "print(f\"Precision over the validation set: {val_prec:.4f}\")\n",
    "print(f\"Recall over the validation set: {val_rec:.4f}\")\n",
    "print(f\"F1 score over the validation set: {val_f1:.4f}\")\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(val_targets, val_preds)\n",
    "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix — Validation Set')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c0b71c",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a figure with two side-by-side subplots (two columns)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n",
    "\n",
    "# Plot of training and validation loss on the first axis\n",
    "ax1.plot(history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
    "ax1.plot(history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot of training and validation accuracy on the second axis\n",
    "ax2.plot(history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
    "ax2.plot(history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n",
    "ax2.set_title('F1 Score')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# Adjust the layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea326ad9",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229c1f4",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Collect predictions\n",
    "test_preds = []\n",
    "best_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for batch in test_loader:\n",
    "        xb = batch[0].to(device)  # Extract tensor from tuple and move to device\n",
    "\n",
    "        # Forward pass: get model predictions\n",
    "        logits = best_model(xb)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        # Store batch results\n",
    "        test_preds.append(preds)\n",
    "\n",
    "# Combine all batches into single array\n",
    "test_preds = np.concatenate(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b3d5d",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create reverse label mapping\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "test_filenames = [fn.replace('mask', 'img') for fn in test_filenames]\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'sample_index': test_filenames,\n",
    "    'label': [reverse_label_map[pred] for pred in test_preds]\n",
    "})\n",
    "\n",
    "# Create descriptive filename with all hyperparameters\n",
    "filename_parts = [\n",
    "    f\"submission_{EXPERIMENT_NAME}\",\n",
    "    f\"data_{DATA_TYPE}\",\n",
    "    f\"bs_{BATCH_SIZE}\",\n",
    "    f\"lr_{LEARNING_RATE}\",\n",
    "    f\"drop_{DROPOUT_RATE}\",\n",
    "    f\"l1_{L1_LAMBDA}\",\n",
    "    f\"l2_{L2_LAMBDA}\",\n",
    "    f\"epochs_{EPOCHS}\",\n",
    "    f\"patience_{PATIENCE}\",\n",
    "    f\"imgsize_{IMG_SIZE[0]}x{IMG_SIZE[1]}\",\n",
    "    f\"f1_{val_f1:.4f}\"\n",
    "]\n",
    "submission_filename = \"_\".join(filename_parts) + \".csv\"\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv(submission_filename, index=False)\n",
    "print(f\"Submission file created: {submission_filename}\")\n",
    "print(f\"Total predictions: {len(submission_df)}\")\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(submission_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
