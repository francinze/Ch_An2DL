{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"712fa9f4","cell_type":"markdown","source":"# **Notebook Setup**","metadata":{}},{"id":"94125c90-4472-4f68-8828-98108d5186bf","cell_type":"code","source":"# KAGGLE IMPORTS\n# Clone repo\n!git clone https://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@github.com/francinze/Ch1_An2DL.git /kaggle/working/ch1\n\n# Install kaggle API\n!pip install -q kaggle\n\n# Configure kaggle.json\n!mkdir -p /root/.config/kaggle\n\n# Copy your kaggle.json there\n!cp /kaggle/working/ch1/kaggle.json /root/.config/kaggle/\n\n# Set correct permissions\n!chmod 600 /root/.config/kaggle/kaggle.json\n\n# Download competition files\n!kaggle competitions download -c an2dl2526c1 -p /kaggle/working/ch1\n\n# Unzip dataset\n!unzip -o /kaggle/working/ch1/an2dl2526c1.zip -d /kaggle/working/ch1/\n\n# Move into the working directory\n%cd /kaggle/working/ch1/","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:17:07.220926Z","iopub.execute_input":"2025-11-17T10:17:07.221164Z","iopub.status.idle":"2025-11-17T10:17:23.391039Z","shell.execute_reply.started":"2025-11-17T10:17:07.221142Z","shell.execute_reply":"2025-11-17T10:17:23.389938Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Cloning into '/kaggle/working/ch1'...\nremote: Enumerating objects: 379, done.\u001b[K\nremote: Counting objects: 100% (70/70), done.\u001b[K\nremote: Compressing objects: 100% (59/59), done.\u001b[K\nremote: Total 379 (delta 38), reused 25 (delta 11), pack-reused 309 (from 1)\u001b[K\nReceiving objects: 100% (379/379), 7.26 MiB | 20.77 MiB/s, done.\nResolving deltas: 100% (220/220), done.\nDownloading an2dl2526c1.zip to /kaggle/working/ch1\n  0%|                                               | 0.00/82.0M [00:00<?, ?B/s]\n100%|██████████████████████████████████████| 82.0M/82.0M [00:00<00:00, 1.08GB/s]\nArchive:  /kaggle/working/ch1/an2dl2526c1.zip\n  inflating: /kaggle/working/ch1/pirate_pain_test.csv  \n  inflating: /kaggle/working/ch1/pirate_pain_train.csv  \n  inflating: /kaggle/working/ch1/pirate_pain_train_labels.csv  \n  inflating: /kaggle/working/ch1/sample_submission.csv  \n/kaggle/working/ch1\n","output_type":"stream"}],"execution_count":1},{"id":"83ad8eb4","cell_type":"code","source":"# COLAB IMPORTS\n!git clone https://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@github.com/francinze/Ch1_An2DL.git\n! pip install -q kaggle\n! mkdir ~/.kaggle\n! cp Ch1_An2DL/kaggle.json ~/.kaggle/\n! chmod 600 ~/.kaggle/kaggle.json\n!kaggle competitions download -c an2dl2526c1\n!unzip an2dl2526c1.zip -d Ch1_An2DL/\n%cd /content/Ch1_An2DL/","metadata":{"execution":{"iopub.execute_input":"2025-11-16T14:53:55.880743Z","iopub.status.busy":"2025-11-16T14:53:55.880495Z","iopub.status.idle":"2025-11-16T14:54:00.254277Z","shell.execute_reply":"2025-11-16T14:54:00.253313Z","shell.execute_reply.started":"2025-11-16T14:53:55.880724Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"50eb6750","cell_type":"code","source":"SEED = 42\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.benchmark = True\nelse:\n    device = torch.device(\"cpu\")\n\nprint(f\"Using device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:17:26.766447Z","iopub.execute_input":"2025-11-17T10:17:26.767372Z","iopub.status.idle":"2025-11-17T10:17:33.286903Z","shell.execute_reply.started":"2025-11-17T10:17:26.767324Z","shell.execute_reply":"2025-11-17T10:17:33.285465Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"}],"execution_count":2},{"id":"0e971aa8","cell_type":"markdown","source":"# **Data Loading**","metadata":{}},{"id":"da882a75","cell_type":"code","source":"df = pd.read_csv(\"pirate_pain_train.csv\")\ndf_test = pd.read_csv(\"pirate_pain_test.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:20:00.883393Z","iopub.execute_input":"2025-11-17T10:20:00.884149Z","iopub.status.idle":"2025-11-17T10:20:03.734694Z","shell.execute_reply.started":"2025-11-17T10:20:00.884120Z","shell.execute_reply":"2025-11-17T10:20:03.733592Z"},"trusted":true},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n0             0     0              2              0              2   \n1             0     1              2              2              2   \n2             0     2              2              0              2   \n3             0     3              2              2              2   \n4             0     4              2              2              2   \n\n   pain_survey_4 n_legs n_hands n_eyes  joint_00  ...      joint_21  \\\n0              1    two     two    two  1.094705  ...  3.499558e-06   \n1              2    two     two    two  1.135183  ...  3.976952e-07   \n2              2    two     two    two  1.080745  ...  1.533820e-07   \n3              2    two     two    two  0.938017  ...  1.006865e-05   \n4              2    two     two    two  1.090185  ...  4.437266e-06   \n\n       joint_22  joint_23      joint_24  joint_25  joint_26  joint_27  \\\n0  1.945042e-06  0.000004  1.153299e-05  0.000004  0.017592  0.013508   \n1  6.765107e-07  0.000006  4.643774e-08  0.000000  0.013352  0.000000   \n2  1.698525e-07  0.000001  2.424536e-06  0.000003  0.016225  0.008110   \n3  5.511079e-07  0.000002  5.432416e-08  0.000000  0.011832  0.007450   \n4  1.735459e-07  0.000002  5.825366e-08  0.000007  0.005360  0.002532   \n\n   joint_28  joint_29  joint_30  \n0  0.026798  0.027815       0.5  \n1  0.013377  0.013716       0.5  \n2  0.024097  0.023105       0.5  \n3  0.028613  0.024648       0.5  \n4  0.033026  0.025328       0.5  \n\n[5 rows x 40 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_index</th>\n      <th>time</th>\n      <th>pain_survey_1</th>\n      <th>pain_survey_2</th>\n      <th>pain_survey_3</th>\n      <th>pain_survey_4</th>\n      <th>n_legs</th>\n      <th>n_hands</th>\n      <th>n_eyes</th>\n      <th>joint_00</th>\n      <th>...</th>\n      <th>joint_21</th>\n      <th>joint_22</th>\n      <th>joint_23</th>\n      <th>joint_24</th>\n      <th>joint_25</th>\n      <th>joint_26</th>\n      <th>joint_27</th>\n      <th>joint_28</th>\n      <th>joint_29</th>\n      <th>joint_30</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>two</td>\n      <td>two</td>\n      <td>two</td>\n      <td>1.094705</td>\n      <td>...</td>\n      <td>3.499558e-06</td>\n      <td>1.945042e-06</td>\n      <td>0.000004</td>\n      <td>1.153299e-05</td>\n      <td>0.000004</td>\n      <td>0.017592</td>\n      <td>0.013508</td>\n      <td>0.026798</td>\n      <td>0.027815</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>two</td>\n      <td>two</td>\n      <td>two</td>\n      <td>1.135183</td>\n      <td>...</td>\n      <td>3.976952e-07</td>\n      <td>6.765107e-07</td>\n      <td>0.000006</td>\n      <td>4.643774e-08</td>\n      <td>0.000000</td>\n      <td>0.013352</td>\n      <td>0.000000</td>\n      <td>0.013377</td>\n      <td>0.013716</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>two</td>\n      <td>two</td>\n      <td>two</td>\n      <td>1.080745</td>\n      <td>...</td>\n      <td>1.533820e-07</td>\n      <td>1.698525e-07</td>\n      <td>0.000001</td>\n      <td>2.424536e-06</td>\n      <td>0.000003</td>\n      <td>0.016225</td>\n      <td>0.008110</td>\n      <td>0.024097</td>\n      <td>0.023105</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>two</td>\n      <td>two</td>\n      <td>two</td>\n      <td>0.938017</td>\n      <td>...</td>\n      <td>1.006865e-05</td>\n      <td>5.511079e-07</td>\n      <td>0.000002</td>\n      <td>5.432416e-08</td>\n      <td>0.000000</td>\n      <td>0.011832</td>\n      <td>0.007450</td>\n      <td>0.028613</td>\n      <td>0.024648</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>two</td>\n      <td>two</td>\n      <td>two</td>\n      <td>1.090185</td>\n      <td>...</td>\n      <td>4.437266e-06</td>\n      <td>1.735459e-07</td>\n      <td>0.000002</td>\n      <td>5.825366e-08</td>\n      <td>0.000007</td>\n      <td>0.005360</td>\n      <td>0.002532</td>\n      <td>0.033026</td>\n      <td>0.025328</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"id":"9cafa0bf","cell_type":"code","source":"target = pd.read_csv(\"pirate_pain_train_labels.csv\")\ntarget.head()","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:20:10.382939Z","iopub.execute_input":"2025-11-17T10:20:10.383638Z","iopub.status.idle":"2025-11-17T10:20:10.400788Z","shell.execute_reply.started":"2025-11-17T10:20:10.383584Z","shell.execute_reply":"2025-11-17T10:20:10.399351Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   sample_index     label\n0             0   no_pain\n1             1   no_pain\n2             2  low_pain\n3             3   no_pain\n4             4   no_pain","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_index</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>no_pain</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>no_pain</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>low_pain</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>no_pain</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>no_pain</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"id":"cef8b1ed","cell_type":"code","source":"pain_survey_cols = ['pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4']\njoint_cols = [f'joint_{str(i).zfill(2)}' for i in range(1, 31)]\nbody_cols = ['n_legs', 'n_eyes', 'n_hands']","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:20:11.695612Z","iopub.execute_input":"2025-11-17T10:20:11.695925Z","iopub.status.idle":"2025-11-17T10:20:11.704108Z","shell.execute_reply.started":"2025-11-17T10:20:11.695901Z","shell.execute_reply":"2025-11-17T10:20:11.702389Z"},"trusted":true},"outputs":[],"execution_count":6},{"id":"6beca32d","cell_type":"markdown","source":"# **Data Exploration**","metadata":{}},{"id":"96b087cc","cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:04.935013Z","iopub.status.busy":"2025-11-16T15:07:04.934575Z","iopub.status.idle":"2025-11-16T15:07:05.004436Z","shell.execute_reply":"2025-11-16T15:07:05.003689Z","shell.execute_reply.started":"2025-11-16T15:07:04.934993Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"65afb952","cell_type":"markdown","source":"## **Body columns**\nInvestigate the body columns in the dataset. Use pandas to load the dataset and display the first few rows to understand its structure.\n\nWe will see how correlated these columns are between themselves, and with respect to the target variable.","metadata":{}},{"id":"5d128375","cell_type":"code","source":"# Create encoded versions for correlation analysis\nfor col in body_cols:\n    df[f'{col}_encoded'] = (df[col] == 'two').astype(int)\n    df_test[f'{col}_encoded'] = (df_test[col] == 'two').astype(int)\n\n# Calculate correlation matrix\ncorrelation_features = [f'{col}_encoded' for col in body_cols]\ncorr_matrix = df[correlation_features].corr()\n\n# Visualize\nplt.figure(figsize=(8, 6))\nsns.heatmap(corr_matrix, annot=True, fmt='.4f', cmap='coolwarm', \n            square=True, vmin=0, vmax=1, cbar_kws={'label': 'Correlation'})\nplt.title('Correlation Matrix: n_legs, n_hands, n_eyes', fontsize=14, fontweight='bold')\nplt.xticks(range(3), body_cols, rotation=45)\nplt.yticks(range(3), body_cols, rotation=0)\nplt.tight_layout()\nplt.show()\n\n# Print correlation values\nprint(\"Correlation Matrix:\")\nprint(\"=\" * 50)\ncorr_matrix.index = body_cols\ncorr_matrix.columns = body_cols\nprint(corr_matrix)","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:06.163509Z","iopub.status.busy":"2025-11-16T15:07:06.162497Z","iopub.status.idle":"2025-11-16T15:07:06.586234Z","shell.execute_reply":"2025-11-16T15:07:06.585435Z","shell.execute_reply.started":"2025-11-16T15:07:06.163472Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"765082ab","cell_type":"markdown","source":"### Result: Perfect correlation (1.0) detected!\nThese three features are 100% identical. It means that there is a perfect correspondence between their values.","metadata":{}},{"id":"fd921fca","cell_type":"code","source":"# Verify that all three features always have the same value\nprint(\"Verifying redundancy...\")\nprint(\"=\" * 60)\n\n# Show unique combinations\nprint(\"Unique combinations in the data:\")\nprint(\"=\" * 60)\nunique_combos = df[body_cols].drop_duplicates()\nfor idx, row in unique_combos.iterrows():\n    count = ((df['n_legs'] == row['n_legs']) & \n             (df['n_hands'] == row['n_hands']) & \n             (df['n_eyes'] == row['n_eyes'])).sum()\n    print(f\"  {row['n_legs']:15s} | {row['n_hands']:15s} | {row['n_eyes']:15s} → {count:,} samples\")\n\nprint(\"\\nConclusion: Only 2 combinations exist (all natural OR all prosthetic) → Safe to consolidate into a single binary feature!\")","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:13.704259Z","iopub.status.busy":"2025-11-16T15:07:13.703513Z","iopub.status.idle":"2025-11-16T15:07:13.776330Z","shell.execute_reply":"2025-11-16T15:07:13.775637Z","shell.execute_reply.started":"2025-11-16T15:07:13.704232Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"33d298de","cell_type":"markdown","source":"## **Pain Surveys**\nInstead we see here the pain survey columns, and we investigate their values and correlations.","metadata":{}},{"id":"783ccacb","cell_type":"code","source":"fig, axes = plt.subplots(2, 2, figsize=(12, 8))\naxes = axes.flatten()\n\nfor i, col in enumerate(pain_survey_cols):\n    ax = axes[i]\n\n    # percentages\n    train_pct = df[col].value_counts(normalize=True).mul(100)\n    test_pct = df_test[col].value_counts(normalize=True).mul(100)\n\n    # ensure same levels and sorted order\n    levels = sorted(set(train_pct.index).union(set(test_pct.index)))\n    train_pct = train_pct.reindex(levels, fill_value=0)\n    test_pct = test_pct.reindex(levels, fill_value=0)\n\n    # prepare long dataframe for seaborn\n    plot_df = pd.DataFrame({\n        'Pain Level': levels,\n        'Train': train_pct.values,\n        'Test': test_pct.values\n    }).melt(id_vars='Pain Level', var_name='Dataset', value_name='percentage')\n\n    sns.barplot(x='Pain Level', y='percentage', hue='Dataset', data=plot_df, ax=ax, palette='viridis')\n    ax.set_title(f'{col} - Train vs Test')\n    ax.set_xlabel('Pain Level')\n    ax.set_ylabel('Percentage (%)')\n    ax.set_ylim(0, 100)\n\n    # keep legend only on the first subplot\n    try:\n        if i == 0:\n            ax.legend(title='Dataset')\n        else:\n            ax.get_legend().remove()\n    except Exception:\n        pass\n\nfig.suptitle('Percentage Distribution of Pain Surveys: Train vs Test', fontsize=16)\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:15.343522Z","iopub.status.busy":"2025-11-16T15:07:15.343246Z","iopub.status.idle":"2025-11-16T15:07:16.043409Z","shell.execute_reply":"2025-11-16T15:07:16.042768Z","shell.execute_reply.started":"2025-11-16T15:07:15.343503Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"d191fa25","cell_type":"markdown","source":"No significant difference in distribution for the surveys, both between the train and test sets, and between the different survey types.","metadata":{}},{"id":"937d5a06","cell_type":"code","source":"# 1. Calculate the Pearson correlation matrix for the pain_survey_cols in df\ncorr_matrix_train = df[pain_survey_cols].corr(method='pearson')\n\n# 2. Calculate the Pearson correlation matrix for the pain_survey_cols in df_test\ncorr_matrix_test = df_test[pain_survey_cols].corr(method='pearson')\n\n# 3. Create a figure with two subplots for heatmaps\nfig, axes = plt.subplots(1, 2, figsize=(16, 7))\nfig.suptitle('Inter-correlation of Pain Survey Columns (Train vs. Test)', fontsize=18)\n\n# Heatmap for Training Data\nsns.heatmap(corr_matrix_train, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, ax=axes[0])\naxes[0].set_title('Pain Survey Correlation Matrix - Train Data', fontsize=14)\naxes[0].tick_params(axis='x', rotation=45)\naxes[0].tick_params(axis='y', rotation=0)\n\n# Heatmap for Testing Data\nsns.heatmap(corr_matrix_test, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, ax=axes[1])\naxes[1].set_title('Pain Survey Correlation Matrix - Test Data', fontsize=14)\naxes[1].tick_params(axis='x', rotation=45)\naxes[1].tick_params(axis='y', rotation=0)\n\n# Adjust the layout to prevent overlapping titles and display the plot\nplt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust rect to make space for suptitle\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:17.391945Z","iopub.status.busy":"2025-11-16T15:07:17.391231Z","iopub.status.idle":"2025-11-16T15:07:17.969724Z","shell.execute_reply":"2025-11-16T15:07:17.969047Z","shell.execute_reply.started":"2025-11-16T15:07:17.391893Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"ad6367bb","cell_type":"markdown","source":"The surveys do not appear to be correlated with each other. Maximal correlation is about 0.06 between \"pain_survey_1\" and \"pain_survey_3\", which is very low and can be considered negligible.","metadata":{}},{"id":"719d4b07","cell_type":"code","source":"from scipy.stats import f_oneway\n\ndf_merged = pd.merge(df, target, on='sample_index', how='left')\n\nprint(\"Performing ANOVA for each pain_survey column against 'label' in df_merged:\")\nfor pain_col in pain_survey_cols:\n    print(f\"\\n--- ANOVA for {pain_col} vs. label ---\")\n    # Get unique labels\n    labels = df_merged['label'].unique()\n\n    # Prepare data for ANOVA: a list of arrays, each array containing pain_col values for a specific label\n    data_for_anova = [df_merged[pain_col][df_merged['label'] == label].values for label in labels]\n\n    # Perform ANOVA test\n    f_statistic, p_value = f_oneway(*data_for_anova)\n\n    print(f\"F-statistic: {f_statistic:.4f}\")\n    print(f\"P-value: {p_value:.4f}\")\n\n    # Interpret the p-value\n    alpha = 0.05\n    if p_value < alpha:\n        print(f\"Conclusion: Since p-value ({p_value:.4f}) < alpha ({alpha}), we reject the null hypothesis. There is a statistically significant difference in {pain_col} means across different pain labels.\")\n    else:\n        print(f\"Conclusion: Since p-value ({p_value:.4f}) >= alpha ({alpha}), we fail to reject the null hypothesis. There is no statistically significant difference in {pain_col} means across different pain labels.\")","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:19.219129Z","iopub.status.busy":"2025-11-16T15:07:19.218475Z","iopub.status.idle":"2025-11-16T15:07:19.382378Z","shell.execute_reply":"2025-11-16T15:07:19.381554Z","shell.execute_reply.started":"2025-11-16T15:07:19.219097Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"dfc65465","cell_type":"markdown","source":"ANOVA tests also confirm that all 4 survey columns have minimal p-values, they are all statistically significant towards the target variable.","metadata":{}},{"id":"e8fd8d21","cell_type":"markdown","source":"## Mapping pain target variable to numerical classes","metadata":{}},{"id":"e38ecd8d","cell_type":"code","source":"unique_labels = df_merged['label'].unique()\nprint(f\"Unique pain labels: {unique_labels}\")\npain_label_mapping = {\n    'no_pain': 0,\n    'low_pain': 1,\n    'high_pain': 2\n}\ndf_merged['pain_level'] = df_merged['label'].map(pain_label_mapping)\ndf_merged.head()","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:21.910441Z","iopub.status.busy":"2025-11-16T15:07:21.910165Z","iopub.status.idle":"2025-11-16T15:07:21.938402Z","shell.execute_reply":"2025-11-16T15:07:21.937783Z","shell.execute_reply.started":"2025-11-16T15:07:21.910421Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"529e9f61","cell_type":"markdown","source":"## **Joint Columns**\nThen we analyze the joint columns in the dataset, and their correlations.","metadata":{}},{"id":"a17b498e","cell_type":"code","source":"from scipy.stats import f_oneway\n\nanova_results = {}\n\nfor col in joint_cols:\n    # Group data by pain level\n    group0 = df_merged[df_merged['pain_level'] == 0][col]\n    group1 = df_merged[df_merged['pain_level'] == 1][col]\n    group2 = df_merged[df_merged['pain_level'] == 2][col]\n\n    # Perform ANOVA test\n    # Ensure all groups have data to avoid errors\n    if len(group0) > 1 and len(group1) > 1 and len(group2) > 1:\n        f_statistic, p_value = f_oneway(group0, group1, group2)\n        anova_results[col] = p_value\n    else:\n        anova_results[col] = float('nan') # Assign NaN if a group is too small for ANOVA\n\n# Sort results by p-value for easier interpretation\nsorted_anova_results = sorted(anova_results.items(), key=lambda x: x[1])\n\nprint(\"ANOVA p-values for joint columns (sorted by significance):\")\nfor col, p_val in sorted_anova_results:\n    print(f\"  {col}: {p_val:.4f}\")","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:23.478193Z","iopub.status.busy":"2025-11-16T15:07:23.477576Z","iopub.status.idle":"2025-11-16T15:07:23.996217Z","shell.execute_reply":"2025-11-16T15:07:23.995445Z","shell.execute_reply.started":"2025-11-16T15:07:23.478167Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"e3bd5e15","cell_type":"code","source":"joint_data_train = df[joint_cols]\ncorrelation_matrix_train = joint_data_train.corr()\nplt.figure(figsize=(15, 12))\nsns.heatmap(correlation_matrix_train, annot=False, cmap='coolwarm', fmt=\".2f\")\nplt.title('Correlation Matrix of Joint Columns in df')\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:26.116306Z","iopub.status.busy":"2025-11-16T15:07:26.116033Z","iopub.status.idle":"2025-11-16T15:07:26.888564Z","shell.execute_reply":"2025-11-16T15:07:26.887867Z","shell.execute_reply.started":"2025-11-16T15:07:26.116289Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"628961a0","cell_type":"markdown","source":"The correlation matrix shows that several joint columns are highly correlated with each other. For example, \"joint_10\" and \"joint_11\" have a correlation of >0.9, indicating a strong linear relationship between these two features.","metadata":{}},{"id":"59c39488","cell_type":"code","source":"joint_data_test = df_test[joint_cols]\ncorrelation_matrix_test = joint_data_test.corr()\nplt.figure(figsize=(15, 12))\nsns.heatmap(correlation_matrix_test, annot=False, cmap='coolwarm', fmt=\".2f\")\nplt.title('Correlation Matrix of Joint Columns in df_test')\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:29.847364Z","iopub.status.busy":"2025-11-16T15:07:29.847010Z","iopub.status.idle":"2025-11-16T15:07:31.001760Z","shell.execute_reply":"2025-11-16T15:07:31.000941Z","shell.execute_reply.started":"2025-11-16T15:07:29.847343Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"aa983224","cell_type":"markdown","source":"Again, no significant difference between train and test sets. The same correlation we saw in the train set is also present in the test set.","metadata":{}},{"id":"fc83d69c","cell_type":"code","source":"print(\"Statistical Descriptions for Joint Columns in df:\")\ndisplay(df[joint_cols].describe())\nprint(\"Statistical Descriptions for Joint Columns in df_test:\")\ndisplay(df_test[joint_cols].describe())","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:31.591527Z","iopub.status.busy":"2025-11-16T15:07:31.590900Z","iopub.status.idle":"2025-11-16T15:07:32.076214Z","shell.execute_reply":"2025-11-16T15:07:32.075565Z","shell.execute_reply.started":"2025-11-16T15:07:31.591501Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"690f8fe8","cell_type":"code","source":"# Set style for attractive visualizations\nsns.set_style(\"whitegrid\")\nplt.rcParams['figure.facecolor'] = 'white'\n\n# Calculate outliers using IQR method for each joint column\noutlier_stats = []\nfor col in joint_cols:\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    \n    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n    outlier_count = len(outliers)\n    outlier_pct = (outlier_count / len(df)) * 100\n    \n    outlier_stats.append({\n        'joint': col,\n        'count': outlier_count,\n        'percentage': outlier_pct,\n        'lower_bound': lower_bound,\n        'upper_bound': upper_bound\n    })\n\noutlier_df = pd.DataFrame(outlier_stats)\n\n# Create comprehensive visualization\nfig = plt.figure(figsize=(20, 12))\ngs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n\n# 1. Bar chart of outlier percentages\nax1 = fig.add_subplot(gs[0, :])\ncolors = plt.cm.RdYlGn_r(outlier_df['percentage'] / outlier_df['percentage'].max())\nbars = ax1.bar(range(len(outlier_df)), outlier_df['percentage'], color=colors, edgecolor='black', linewidth=0.5)\nax1.set_xlabel('Joint Column', fontsize=12, fontweight='bold')\nax1.set_ylabel('Outlier Percentage (%)', fontsize=12, fontweight='bold')\nax1.set_title('Percentage of Outliers per Joint Column (IQR Method)', fontsize=14, fontweight='bold')\nax1.set_xticks(range(len(outlier_df)))\nax1.set_xticklabels(outlier_df['joint'], rotation=45, ha='right')\nax1.grid(axis='y', alpha=0.3)\n\n# Add percentage labels on bars\nfor i, (bar, pct) in enumerate(zip(bars, outlier_df['percentage'])):\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height,\n             f'{pct:.1f}%', ha='center', va='bottom', fontsize=7)\n\n# 2. Box plots for top 15 joints with most outliers\nax2 = fig.add_subplot(gs[1, :])\ntop_outliers = outlier_df.nlargest(15, 'percentage')['joint'].tolist()\nbox_data = [df[col].values for col in top_outliers]\n\nbp = ax2.boxplot(box_data, labels=top_outliers, patch_artist=True, \n                  flierprops=dict(marker='o', markerfacecolor='red', markersize=2, alpha=0.3))\n\nfor patch, col in zip(bp['boxes'], top_outliers):\n    patch.set_facecolor(plt.cm.viridis(top_outliers.index(col) / len(top_outliers)))\n\nax2.set_xlabel('Joint Column', fontsize=12, fontweight='bold')\nax2.set_ylabel('Value', fontsize=12, fontweight='bold')\nax2.set_title('Box Plot: Top 15 Joints with Most Outliers', fontsize=14, fontweight='bold')\nax2.tick_params(axis='x', rotation=45)\nax2.grid(axis='y', alpha=0.3)\n\n# 3. Heatmap of outlier counts\nax3 = fig.add_subplot(gs[2, 0])\noutlier_matrix = outlier_df['percentage'].values.reshape(5, 6)  # 30 joints in 5x6 grid\nim = ax3.imshow(outlier_matrix, cmap='YlOrRd', aspect='auto')\nax3.set_xticks(range(6))\nax3.set_yticks(range(5))\nax3.set_xticklabels([f'Col {i+1}' for i in range(6)])\nax3.set_yticklabels([f'Row {i+1}' for i in range(5)])\nax3.set_title('Outlier Heatmap (% by Position)', fontsize=13, fontweight='bold')\n\n# Add values to heatmap\nfor i in range(5):\n    for j in range(6):\n        idx = i * 6 + j\n        if idx < len(outlier_df):\n            text = ax3.text(j, i, f'{outlier_matrix[i, j]:.1f}%',\n                           ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n\nplt.colorbar(im, ax=ax3, label='Outlier %')\n\n# 4. Summary statistics table\nax4 = fig.add_subplot(gs[2, 1])\nax4.axis('off')\n\nsummary_text = f\"\"\"\n╔══════════════════════════════════════════════╗\n║          OUTLIER SUMMARY STATISTICS          ║\n╠══════════════════════════════════════════════╣\n║  Total Joints Analyzed:        {len(outlier_df):>12}  ║\n║  Total Data Points:            {len(df):>12,}  ║\n║                                              ║\n║  Avg Outliers per Joint:       {outlier_df['percentage'].mean():>11.2f}%  ║\n║  Max Outliers (joint):         {outlier_df['percentage'].max():>11.2f}%  ║\n║  Min Outliers (joint):         {outlier_df['percentage'].min():>11.2f}%  ║\n║                                              ║\n║  Joint with Most Outliers:                   ║\n║    {outlier_df.loc[outlier_df['percentage'].idxmax(), 'joint']:>12} ({outlier_df['percentage'].max():.2f}%)   ║\n║                                              ║\n║  Joint with Least Outliers:                  ║\n║    {outlier_df.loc[outlier_df['percentage'].idxmin(), 'joint']:>12} ({outlier_df['percentage'].min():.2f}%)   ║\n╚══════════════════════════════════════════════╝\n\"\"\"\n\nax4.text(0.5, 0.5, summary_text, \n         fontsize=10, \n         family='monospace',\n         ha='center', \n         va='center',\n         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n\nplt.suptitle('Joint Columns Outlier Analysis', fontsize=16, fontweight='bold', y=0.995)\nplt.show()\n\n# Print detailed statistics\nprint(\"\\n\" + \"=\" * 80)\nprint(\"DETAILED OUTLIER STATISTICS\")\nprint(\"=\" * 80)\nprint(outlier_df.sort_values('percentage', ascending=False).to_string(index=False))\nprint(\"\\n\" + \"=\" * 80)","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:33.532888Z","iopub.status.busy":"2025-11-16T15:07:33.532616Z","iopub.status.idle":"2025-11-16T15:07:35.095800Z","shell.execute_reply":"2025-11-16T15:07:35.094862Z","shell.execute_reply.started":"2025-11-16T15:07:33.532866Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"c613c21a","cell_type":"code","source":"# Analyze each joint column for extreme anomalies\nanomaly_report = []\n\nfor col in joint_cols:\n    data = df[col]\n    \n    # Calculate percentiles to understand typical range\n    p01 = data.quantile(0.01)\n    p50 = data.quantile(0.50)  # median\n    p99 = data.quantile(0.99)\n    \n    # Calculate mean and std of the bulk of the data (1st-99th percentile)\n    bulk_data = data[(data >= p01) & (data <= p99)]\n    bulk_mean = bulk_data.mean()\n    bulk_std = bulk_data.std()\n    \n    # Find values that are way outside the typical range\n    # Using 10 standard deviations as threshold for extreme anomalies\n    threshold = 10\n    extreme_low = bulk_mean - threshold * bulk_std\n    extreme_high = bulk_mean + threshold * bulk_std\n    \n    anomalies = data[(data < extreme_low) | (data > extreme_high)]\n    \n    # Also check for magnitude differences (e.g., 0.8 among 1e-05 values)\n    # If median is very small, check for values that are orders of magnitude larger\n    if p50 < 0.01:  # Column has very small values\n        magnitude_threshold = p50 * 100  # Values 100x larger than median\n        magnitude_anomalies = data[data > magnitude_threshold]\n    else:\n        magnitude_anomalies = pd.Series(dtype=float)\n    \n    anomaly_report.append({\n        'joint': col,\n        'median': p50,\n        'p01': p01,\n        'p99': p99,\n        'bulk_mean': bulk_mean,\n        'bulk_std': bulk_std,\n        'extreme_anomalies': len(anomalies),\n        'magnitude_anomalies': len(magnitude_anomalies),\n        'total_anomalies': len(set(anomalies.index) | set(magnitude_anomalies.index)),\n        'anomaly_pct': (len(set(anomalies.index) | set(magnitude_anomalies.index)) / len(data)) * 100,\n        'min_val': data.min(),\n        'max_val': data.max()\n    })\n\nanomaly_df = pd.DataFrame(anomaly_report)\n\n# Display joints with significant anomalies\nprint(\"=\"*100)\nprint(\"EXTREME ANOMALY DETECTION IN JOINT COLUMNS\")\nprint(\"=\"*100)\nprint(\"\\nJoints with extreme out-of-range values (sorted by anomaly percentage):\")\nprint(\"-\"*100)\n\nsignificant_anomalies = anomaly_df[anomaly_df['total_anomalies'] > 0].sort_values('anomaly_pct', ascending=False)\n\nfor _, row in significant_anomalies.iterrows():\n    print(f\"\\n{row['joint']}:\")\n    print(f\"  Median: {row['median']:.6e}  |  Range: [{row['min_val']:.6e}, {row['max_val']:.6e}]\")\n    print(f\"  Bulk mean±std: {row['bulk_mean']:.6e} ± {row['bulk_std']:.6e}\")\n    print(f\"  Extreme anomalies: {row['extreme_anomalies']:,} ({row['anomaly_pct']:.2f}%)\")\n    print(f\"  Magnitude anomalies: {row['magnitude_anomalies']:,}\")\n    \n    # Show example anomalous values\n    col = row['joint']\n    data = df[col]\n    bulk_mean = row['bulk_mean']\n    bulk_std = row['bulk_std']\n    extreme_vals = data[(data < bulk_mean - 10*bulk_std) | (data > bulk_mean + 10*bulk_std)]\n    \n    if len(extreme_vals) > 0:\n        print(f\"  Example anomalous values: {extreme_vals.head(5).values}\")\n\n# Visualize the most anomalous columns\ntop_anomalous = significant_anomalies.head(6)['joint'].tolist()\n\nif len(top_anomalous) > 0:\n    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n    axes = axes.flatten()\n    \n    for i, col in enumerate(top_anomalous):\n        if i >= 6:\n            break\n        ax = axes[i]\n        \n        data = df[col]\n        row = anomaly_df[anomaly_df['joint'] == col].iloc[0]\n        \n        # Create histogram with log scale if needed\n        ax.hist(data, bins=100, alpha=0.7, edgecolor='black', linewidth=0.5)\n        ax.axvline(row['median'], color='red', linestyle='--', linewidth=2, label=f'Median: {row[\"median\"]:.2e}')\n        ax.axvline(row['bulk_mean'], color='green', linestyle='--', linewidth=2, label=f'Mean: {row[\"bulk_mean\"]:.2e}')\n        \n        ax.set_title(f'{col}\\nAnomalies: {row[\"total_anomalies\"]:,} ({row[\"anomaly_pct\"]:.2f}%)', \n                     fontweight='bold', fontsize=11)\n        ax.set_xlabel('Value', fontsize=9)\n        ax.set_ylabel('Frequency', fontsize=9)\n        ax.legend(fontsize=8)\n        ax.grid(alpha=0.3)\n        \n        # Use log scale for y-axis if there's high variance\n        if data.max() / data.median() > 100:\n            ax.set_yscale('log')\n    \n    plt.tight_layout()\n    plt.suptitle('Distribution of Joints with Extreme Anomalies', fontsize=14, fontweight='bold', y=1.00)\n    plt.subplots_adjust(top=0.96)\n    plt.show()\n\nprint(\"\\n\" + \"=\"*100)\nprint(\"SUMMARY\")\nprint(\"=\"*100)\nprint(f\"Joints with no anomalies: {len(anomaly_df[anomaly_df['total_anomalies'] == 0])}\")\nprint(f\"Joints with anomalies: {len(anomaly_df[anomaly_df['total_anomalies'] > 0])}\")\nprint(f\"Most anomalous joint: {anomaly_df.loc[anomaly_df['anomaly_pct'].idxmax(), 'joint']} \"\n      f\"({anomaly_df['anomaly_pct'].max():.2f}% anomalies)\")","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:36.802679Z","iopub.status.busy":"2025-11-16T15:07:36.802386Z","iopub.status.idle":"2025-11-16T15:07:41.308062Z","shell.execute_reply":"2025-11-16T15:07:41.307317Z","shell.execute_reply.started":"2025-11-16T15:07:36.802657Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"4131f7f1","cell_type":"code","source":"fig, axes = plt.subplots(5, 6, figsize=(24, 20))\naxes = axes.flatten()\n\nfor i, col in enumerate(joint_cols):\n    ax = axes[i]\n    \n    # Plot KDE for train and test\n    sns.kdeplot(df[col], label='Train', fill=True, alpha=0.5, ax=ax, color='blue')\n    sns.kdeplot(df_test[col], label='Test', fill=True, alpha=0.5, ax=ax, color='orange')\n    \n    ax.set_title(f'{col}', fontsize=10, fontweight='bold')\n    ax.set_xlabel('')\n    ax.set_ylabel('Density', fontsize=8)\n    \n    # Add legend only to the first subplot\n    if i == 0:\n        ax.legend(loc='upper right', fontsize=8)\n    \n    # Determine x-axis limits based on data range\n    combined_data = pd.concat([df[col], df_test[col]])\n    \n    # Use percentiles to handle outliers\n    p1 = combined_data.quantile(0.01)\n    p99 = combined_data.quantile(0.99)\n    \n    data_min = combined_data.min()\n    data_max = combined_data.max()\n    \n    # Calculate range\n    data_range = p99 - p1\n    \n    if data_range > 0:\n        # Add 10% padding to the percentile range\n        padding = data_range * 0.1\n        lower_lim = max(p1 - padding, data_min)\n        upper_lim = min(p99 + padding, data_max)\n    else:\n        # If all values are the same, create a small range around the value\n        if data_min == 0:\n            lower_lim = -1e-8\n            upper_lim = 1e-8\n        else:\n            abs_val = abs(data_min)\n            lower_lim = data_min - abs_val * 0.1\n            upper_lim = data_min + abs_val * 0.1\n    \n    # Ensure lower limit doesn't go negative if all data is non-negative\n    if data_min >= 0 and lower_lim < 0:\n        lower_lim = 0\n    \n    ax.set_xlim(lower_lim, upper_lim)\n    ax.tick_params(axis='both', labelsize=8)\n    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n\nplt.tight_layout()\nplt.suptitle('Distribution of Joint Columns: Train vs Test', fontsize=16, fontweight='bold', y=1.00)\nplt.subplots_adjust(top=0.98)\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:07:41.309484Z","iopub.status.busy":"2025-11-16T15:07:41.309238Z","iopub.status.idle":"2025-11-16T15:08:27.176611Z","shell.execute_reply":"2025-11-16T15:08:27.175723Z","shell.execute_reply.started":"2025-11-16T15:07:41.309458Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"1e8dd0a0","cell_type":"markdown","source":"## **Time Column**","metadata":{}},{"id":"a28ef079","cell_type":"code","source":"print(\"\\nCreating time-based features from 'time' column\")\n\n# Feature 1: Normalized time (position in sequence: 0.0 to 1.0)\nprint(\"\\n1. Normalized Time (relative position in sequence)\")\ndf['time_normalized'] = df.groupby('sample_index')['time'].transform(\n    lambda x: x / x.max() if x.max() > 0 else 0\n)\ndf_test['time_normalized'] = df_test.groupby('sample_index')['time'].transform(\n    lambda x: x / x.max() if x.max() > 0 else 0\n)\n\n# Analyze sequence lengths to determine cyclical period\ntrain_lengths = df.groupby('sample_index')['time'].max()\ntest_lengths = df_test.groupby('sample_index')['time'].max()\navg_length = train_lengths.mean()\n\nprint(f\"   - Average sequence length: {avg_length:.1f} timesteps\")\nprint(f\"   - Train range: {train_lengths.min():.0f} to {train_lengths.max():.0f}\")\nprint(f\"   - Test range: {test_lengths.min():.0f} to {test_lengths.max():.0f}\")\n\n# Feature 2: Cyclical encoding (captures periodic patterns)\n# Use a period based on average sequence length for meaningful cycles\nperiod = max(50, avg_length / 3)  # Create ~3 cycles per sequence\nprint(f\"\\n2. Cyclical Encoding (period={period:.1f} timesteps)\")\nprint(f\"   - Captures repeating patterns within sequences\")\n\ndf['time_sin'] = np.sin(2 * np.pi * df['time'] / period)\ndf['time_cos'] = np.cos(2 * np.pi * df['time'] / period)\ndf_test['time_sin'] = np.sin(2 * np.pi * df_test['time'] / period)\ndf_test['time_cos'] = np.cos(2 * np.pi * df_test['time'] / period)\n\n# Feature 3: Time position categories (early/mid/late)\nprint(\"\\n3. Time Position Category (early/mid/late in sequence)\")\n\ndef categorize_time_position(group):\n    normalized = group / group.max() if group.max() > 0 else 0\n    return pd.cut(normalized, bins=[0, 0.33, 0.66, 1.0], \n                    labels=[0, 1, 2], include_lowest=True).astype(int)\n\ndf['time_position'] = df.groupby('sample_index')['time'].transform(categorize_time_position)\ndf_test['time_position'] = df_test.groupby('sample_index')['time'].transform(categorize_time_position)\n\nprint(\"   - 0: Early (0-33% of sequence)\")\nprint(\"   - 1: Mid (33-66% of sequence)\")\nprint(\"   - 2: Late (66-100% of sequence)\")\n\n# Show distribution of time position categories\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Distribution of time position categories:\")\nprint(\"=\" * 60)\nprint(\"\\nTraining set:\")\ntrain_dist = df['time_position'].value_counts().sort_index()\nfor value, count in train_dist.items():\n    label = ['Early', 'Mid', 'Late'][value]\n    pct = (count / len(df)) * 100\n    print(f\"  {value} ({label:5s}): {count:6,} samples ({pct:.2f}%)\")\n\nprint(\"\\nTest set:\")\ntest_dist = df_test['time_position'].value_counts().sort_index()\nfor value, count in test_dist.items():\n    label = ['Early', 'Mid', 'Late'][value]\n    pct = (count / len(df_test)) * 100\n    print(f\"  {value} ({label:5s}): {count:6,} samples ({pct:.2f}%)\")\n\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Summary: Created 4 new time features\")\nprint(\" time_normalized: Continuous [0.0, 1.0] - position in sequence\")\nprint(\" time_sin: Continuous [-1.0, 1.0] - cyclical encoding\")\nprint(\" time_cos: Continuous [-1.0, 1.0] - cyclical encoding\")\nprint(\" time_position: Categorical [0, 1, 2] - early/mid/late (for embeddings)\")","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:08:27.179078Z","iopub.status.busy":"2025-11-16T15:08:27.178471Z","iopub.status.idle":"2025-11-16T15:08:29.117180Z","shell.execute_reply":"2025-11-16T15:08:29.116369Z","shell.execute_reply.started":"2025-11-16T15:08:27.179050Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"65f6b584","cell_type":"code","source":"# Visualize time features for a single pirate\npirate_id = 0\npirate_data = df[df['sample_index'] == pirate_id]\n\nfig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n# Plot 1: Normalized time progression\nax1 = axes[0, 0]\nax1.plot(pirate_data['time'], pirate_data['time_normalized'], 'b-', linewidth=2)\nax1.set_xlabel('Time (timestep)', fontsize=12, fontweight='bold')\nax1.set_ylabel('Normalized Time', fontsize=12, fontweight='bold')\nax1.set_title('Time Normalization: Linear Progression', fontsize=13, fontweight='bold')\nax1.grid(True, alpha=0.3)\nax1.set_ylim(0, 1.05)\n\n# Plot 2: Cyclical encoding (sin/cos)\nax2 = axes[0, 1]\nax2.plot(pirate_data['time'], pirate_data['time_sin'], 'r-', linewidth=2, label='sin(time)', alpha=0.7)\nax2.plot(pirate_data['time'], pirate_data['time_cos'], 'b-', linewidth=2, label='cos(time)', alpha=0.7)\nax2.set_xlabel('Time (timestep)', fontsize=12, fontweight='bold')\nax2.set_ylabel('Cyclical Value', fontsize=12, fontweight='bold')\nax2.set_title('Cyclical Encoding: Captures Periodic Patterns', fontsize=13, fontweight='bold')\nax2.legend(loc='upper right', fontsize=11)\nax2.grid(True, alpha=0.3)\nax2.set_ylim(-1.2, 1.2)\n\n# Plot 3: Time position categories\nax3 = axes[1, 0]\ntime_pos_counts = pirate_data['time_position'].value_counts().sort_index()\ncolors = ['#2ecc71', '#f39c12', '#e74c3c']  # Green, Orange, Red\nax3.bar(time_pos_counts.index, time_pos_counts.values, color=colors, edgecolor='black', linewidth=1.5)\nax3.set_xlabel('Time Position Category', fontsize=12, fontweight='bold')\nax3.set_ylabel('Frequency', fontsize=12, fontweight='bold')\nax3.set_title('Time Position: Early/Mid/Late Distribution', fontsize=13, fontweight='bold')\nax3.set_xticks([0, 1, 2])\nax3.set_xticklabels(['Early\\n(0-33%)', 'Mid\\n(33-66%)', 'Late\\n(66-100%)'], fontsize=10)\nax3.grid(True, alpha=0.3, axis='y')\n\n# Plot 4: Cyclical encoding in 2D space (phase diagram)\nax4 = axes[1, 1]\nscatter = ax4.scatter(pirate_data['time_cos'], pirate_data['time_sin'], \n                     c=pirate_data['time'], cmap='viridis', s=50, alpha=0.6, edgecolors='black', linewidth=0.5)\nax4.set_xlabel('cos(time)', fontsize=12, fontweight='bold')\nax4.set_ylabel('sin(time)', fontsize=12, fontweight='bold')\nax4.set_title('Cyclical Encoding: 2D Phase Space', fontsize=13, fontweight='bold')\nax4.grid(True, alpha=0.3)\nax4.set_xlim(-1.2, 1.2)\nax4.set_ylim(-1.2, 1.2)\nax4.axhline(y=0, color='k', linestyle='--', alpha=0.3)\nax4.axvline(x=0, color='k', linestyle='--', alpha=0.3)\ncbar = plt.colorbar(scatter, ax=ax4)\ncbar.set_label('Timestep', fontsize=10)\n\nplt.tight_layout()\nplt.suptitle(f'Time Feature Visualization (Pirate {pirate_id})', fontsize=15, fontweight='bold', y=1.00)\nplt.subplots_adjust(top=0.96)\nplt.show()\n\nprint(f\"\\n{'='*70}\")\nprint(f\"Time feature summary for pirate {pirate_id}:\")\nprint(f\"{'='*70}\")\nprint(f\"Total timesteps: {len(pirate_data)}\")\nprint(f\"Time range: {pirate_data['time'].min():.0f} to {pirate_data['time'].max():.0f}\")\nprint(f\"Normalized range: {pirate_data['time_normalized'].min():.3f} to {pirate_data['time_normalized'].max():.3f}\")\nprint(f\"Time position distribution: {time_pos_counts.to_dict()}\")","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:08:29.118027Z","iopub.status.busy":"2025-11-16T15:08:29.117817Z","iopub.status.idle":"2025-11-16T15:08:30.425546Z","shell.execute_reply":"2025-11-16T15:08:30.424664Z","shell.execute_reply.started":"2025-11-16T15:08:29.118011Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"5d27ea27","cell_type":"code","source":"# Analyze correlation between time features and pain labels\nfrom scipy.stats import f_oneway\n\n# Merge with labels\ndf = pd.merge(df, target, on='sample_index', how='left')\n\n# Map labels to integers\npain_label_mapping = {'no_pain': 0, 'low_pain': 1, 'high_pain': 2}\ndf['pain_level'] = df['label'].map(pain_label_mapping)\n# Perform ANOVA for each time feature\ntime_feature_cols = ['time_normalized', 'time_sin', 'time_cos', 'time_position']\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ANOVA: Time Features vs Pain Labels\")\nprint(\"=\"*70)\nprint(\"\\nTesting if time features differ across pain levels (no_pain, low_pain, high_pain)\")\nprint(\"-\"*70)\n\nfor col in time_feature_cols:\n    group0 = df[df['pain_level'] == 0][col]\n    group1 = df[df['pain_level'] == 1][col]\n    group2 = df[df['pain_level'] == 2][col]\n    \n    if len(group0) > 1 and len(group1) > 1 and len(group2) > 1:\n        f_statistic, p_value = f_oneway(group0, group1, group2)\n        \n        # Interpret significance\n        if p_value < 0.001:\n            significance = \"*** Highly significant\"\n        elif p_value < 0.01:\n            significance = \"** Very significant\"\n        elif p_value < 0.05:\n            significance = \"* Significant\"\n        else:\n            significance = \"Not significant\"\n        \n        print(f\"\\n{col}:\")\n        print(f\"  F-statistic: {f_statistic:.4f}\")\n        print(f\"  P-value: {p_value:.4f}  {significance}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"Interpretation:\")\nprint(\"=\"*70)\nprint(\"p < 0.001: Strong evidence that time feature relates to pain level\")\nprint(\"p < 0.05:  Evidence of relationship (statistically significant)\")\nprint(\"p ≥ 0.05:  No clear relationship detected\")\nprint(\"=\"*70)","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:08:30.427232Z","iopub.status.busy":"2025-11-16T15:08:30.427015Z","iopub.status.idle":"2025-11-16T15:08:30.555875Z","shell.execute_reply":"2025-11-16T15:08:30.555189Z","shell.execute_reply.started":"2025-11-16T15:08:30.427216Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"2488ca67","cell_type":"markdown","source":"# **Data Preprocessing and Feature Engineering**","metadata":{}},{"id":"a1313f76","cell_type":"markdown","source":"## **Drop Redundant Joint Columns**","metadata":{}},{"id":"b906efd8","cell_type":"code","source":"df.drop(columns=['joint_30', 'joint_11', 'time'], inplace=True)\ndf_test.drop(columns=['joint_30', 'joint_11', 'time'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:20:19.802019Z","iopub.execute_input":"2025-11-17T10:20:19.802362Z","iopub.status.idle":"2025-11-17T10:20:19.870404Z","shell.execute_reply.started":"2025-11-17T10:20:19.802338Z","shell.execute_reply":"2025-11-17T10:20:19.869151Z"},"trusted":true},"outputs":[],"execution_count":7},{"id":"f26cfa1c","cell_type":"markdown","source":"## Unify n_legs, n_arms and n_eyes into single feature 'has_prosthetics'","metadata":{}},{"id":"5072ff5b","cell_type":"code","source":"# Create the new feature\ndf['has_prosthetics'] = (df['n_legs'] != 'two').astype(int)\ndf_test['has_prosthetics'] = (df_test['n_legs'] != 'two').astype(int)\n\n# Show distribution\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Distribution of new feature:\")\nprint(\"=\" * 60)\nprint(\"\\nTraining set:\")\ntrain_dist = df['has_prosthetics'].value_counts().sort_index()\nfor value, count in train_dist.items():\n    label = \"Natural\" if value == 0 else \"Prosthetics\"\n    pct = (count / len(df)) * 100\n    print(f\"  {value} ({label:12s}): {count:6,} samples ({pct:.2f}%)\")\n\nprint(\"\\nTest set:\")\ntest_dist = df_test['has_prosthetics'].value_counts().sort_index()\nfor value, count in test_dist.items():\n    label = \"Natural\" if value == 0 else \"Prosthetics\"\n    pct = (count / len(df_test)) * 100\n    print(f\"  {value} ({label:12s}): {count:6,} samples ({pct:.2f}%)\")\n\n\n# Columns to drop\ncols_to_drop = ['n_legs', 'n_hands', 'n_eyes', \n                'n_legs_encoded', 'n_hands_encoded', 'n_eyes_encoded']\n\n# Drop from both train and test\ndf = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\ndf_test = df_test.drop(columns=[col for col in cols_to_drop if col in df_test.columns])\n\nprint(\"\\nFeature created successfully!\")","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:20:22.042607Z","iopub.execute_input":"2025-11-17T10:20:22.042951Z","iopub.status.idle":"2025-11-17T10:20:22.152454Z","shell.execute_reply.started":"2025-11-17T10:20:22.042923Z","shell.execute_reply":"2025-11-17T10:20:22.151353Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n============================================================\nDistribution of new feature:\n============================================================\n\nTraining set:\n  0 (Natural     ): 104,800 samples (99.09%)\n  1 (Prosthetics ):    960 samples (0.91%)\n\nTest set:\n  0 (Natural     ): 209,760 samples (99.02%)\n  1 (Prosthetics ):  2,080 samples (0.98%)\n\nFeature created successfully!\n","output_type":"stream"}],"execution_count":8},{"id":"2a6caae9","cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nprint(\"\\nApplying Min-Max normalization to joint columns...\")\nprint(\"=\" * 60)\n# List of joint columns to normalize\njoint_cols = [\"joint_\" + str(i).zfill(2) for i in range(30)]\njoint_cols.remove(\"joint_11\")  # Removed earlier\n\nfor col in joint_cols:\n    df[col] = df[col].astype(np.float32)\n\n# Initialize the MinMaxScaler\nminmax_scaler = MinMaxScaler()\n\n# Apply Min-Max normalization to the joint columns\ndf[joint_cols] = minmax_scaler.fit_transform(df[joint_cols])\n\n# Use the same scaler on test data\ndf_test[joint_cols] = minmax_scaler.transform(df_test[joint_cols])\n\nprint(f\"Scaler learned from training data - Min: {minmax_scaler.data_min_[:5]}\")\nprint(f\"Scaler learned from training data - Max: {minmax_scaler.data_max_[:5]}\")","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:20:24.287841Z","iopub.execute_input":"2025-11-17T10:20:24.288167Z","iopub.status.idle":"2025-11-17T10:20:24.587310Z","shell.execute_reply.started":"2025-11-17T10:20:24.288144Z","shell.execute_reply":"2025-11-17T10:20:24.586119Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nApplying Min-Max normalization to joint columns...\n============================================================\nScaler learned from training data - Min: [0.         0.         0.00101504 0.00540321 0.        ]\nScaler learned from training data - Max: [1.407968  1.3346131 1.3060458 1.2547286 1.3592042]\n","output_type":"stream"}],"execution_count":9},{"id":"5d719457","cell_type":"code","source":"# Define Weights\nWEIGHTS = []\nfor label in np.unique(target['label']):\n    print(f\"Label: {label}, Count: {len(target[target['label'] == label])}\")\n    WEIGHTS.append(len(target) / len(target[target['label'] == label]))\nWEIGHTS = torch.Tensor(WEIGHTS).to(device)\n\n# Define a mapping of pain indexes to integer labels\nlabel_mapping = {\n    'no_pain': 0,\n    'low_pain': 1,\n    'high_pain': 2\n}\n\n# Map pain indexes to integers\ntarget['label'] = target['label'].map(label_mapping)","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:20:25.971262Z","iopub.execute_input":"2025-11-17T10:20:25.971611Z","iopub.status.idle":"2025-11-17T10:20:26.006335Z","shell.execute_reply.started":"2025-11-17T10:20:25.971587Z","shell.execute_reply":"2025-11-17T10:20:26.005266Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Label: high_pain, Count: 56\nLabel: low_pain, Count: 94\nLabel: no_pain, Count: 511\n","output_type":"stream"}],"execution_count":10},{"id":"ca6c4374","cell_type":"code","source":"import random\n\nprint(\"\\nPerforming train/validation split based on unique users...\")\nprint(\"=\" * 60)\n# Get unique user IDs and shuffle them\nunique_users = df['sample_index'].unique()\nrandom.seed(SEED) # Ensure reproducibility of shuffling\nrandom.shuffle(unique_users)\ninput_shape = df.shape\n\nprint(f\"Input shape: {input_shape}\")\n\n# Determine the number of users for validation\nnum_val_users = int(len(unique_users) * 0.2)\nval_users = unique_users[:num_val_users]\ntrain_users = unique_users[num_val_users:]\nprint(f\"Number of training users: {len(train_users)}\")\nprint(f\"Number of validation users: {len(val_users)}\")\n# Split the DataFrame and target based on user IDs\ntrain_df = df[df['sample_index'].isin(train_users)].reset_index(drop=True)\nval_df = df[df['sample_index'].isin(val_users)].reset_index(drop=True)\ntrain_target = target[target['sample_index'].isin(train_users)].reset_index(drop=True)  \nval_target = target[target['sample_index'].isin(val_users)].reset_index(drop=True)\nprint(f\"Training set shape: {train_df.shape}\")\nprint(f\"Validation set shape: {val_df.shape}\")","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:20:27.340115Z","iopub.execute_input":"2025-11-17T10:20:27.341045Z","iopub.status.idle":"2025-11-17T10:20:27.419457Z","shell.execute_reply.started":"2025-11-17T10:20:27.341002Z","shell.execute_reply":"2025-11-17T10:20:27.418147Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\nPerforming train/validation split based on unique users...\n============================================================\nInput shape: (105760, 35)\nNumber of training users: 529\nNumber of validation users: 132\nTraining set shape: (84640, 35)\nValidation set shape: (21120, 35)\n","output_type":"stream"}],"execution_count":11},{"id":"9ab8563a","cell_type":"code","source":"# Label mapping (robust to string or numeric labels)\nLABEL_MAP = {\"no_pain\": 0, \"low_pain\": 1, \"high_pain\": 2}\n\ndef _detect_joint_cols(df):\n    return sorted([c for c in df.columns if c.startswith(\"joint_\")])\n\ndef _get_data_cols(df):\n    cols = _detect_joint_cols(df)\n    if not cols:\n        raise ValueError(\"No 'joint_*' columns found in df.\")\n    return cols\n\n# Load labels if not already present\nif \"target\" not in globals():\n    try:\n        target = pd.read_csv(\"pirate_pain_train_labels.csv\")\n    except FileNotFoundError:\n        print(\"Warning: 'target' not defined and 'pirate_pain_train_labels.csv' not found.\")\n    else:\n        if \"label\" in target.columns:\n            # Map strings to ints if needed\n            if target[\"label\"].dtype == object:\n                target[\"label\"] = target[\"label\"].map(lambda x: LABEL_MAP.get(x, x))\n\n# --- Window builder ---\ndef build_windows(\n    df: pd.DataFrame,\n    target: pd.DataFrame | None,\n    window: int = 300,\n    stride: int = 75,\n    padding: str = \"zero\",      # 'zero' or 'drop_last'\n    feature: str = \"3d\",        # '3d' (for RNNs) or 'flatten' (for traditional ML)\n    data_cols: list | None = None,\n):\n    \"\"\"\n    Builds sliding windows from df and returns (X, y, groups).\n    \n    Args:\n        df: DataFrame with time series data\n        target: DataFrame with labels\n        window: Window size (number of timesteps)\n        stride: Stride for sliding window\n        padding: 'zero' to pad with zeros, 'drop_last' to drop incomplete windows\n        feature: '3d' returns (samples, timesteps, features) for RNNs,\n                 'flatten' returns (samples, timesteps*features) for traditional ML\n        data_cols: List of columns to use as features\n    \n    Returns:\n        X: numpy array of shape (n_samples, window, n_features) if feature='3d'\n           or (n_samples, window*n_features) if feature='flatten'\n        y: numpy array of labels\n        groups: numpy array of sample indices\n    \"\"\"\n    if data_cols is None:\n        data_cols = _get_data_cols(df)\n    X, y = [], []\n    for sid in df[\"sample_index\"].unique():\n        temp = df[df[\"sample_index\"] == sid][data_cols].values\n        # get label for this id\n        if target is not None:\n            lab_arr = target[target[\"sample_index\"] == sid][\"label\"].values\n            if len(lab_arr) == 0:\n                # if missing label, skip this id\n                continue\n            lab = lab_arr[0]\n            if isinstance(lab, str):\n                lab = LABEL_MAP.get(lab, lab)\n        # padding computation\n        pad = (window - (len(temp) % window)) % window\n        if padding == \"zero\" and pad:\n            temp = np.concatenate([temp, np.zeros((pad, temp.shape[1]), dtype=temp.dtype)], axis=0)\n        L = len(temp)\n        start = 0\n        while start + window <= L:\n            seg = temp[start:start + window]  # shape: (window, n_features)\n            if feature == \"flatten\":\n                feat = seg.reshape(-1)  # shape: (window * n_features,)\n            else:\n                feat = seg  # Keep 3D: (window, n_features)\n            X.append(feat)\n            if target is not None:\n                y.append(lab)\n            start += stride\n    if not X:\n        raise ValueError(\"No windows were created. Check your data and parameters.\")\n    return np.asarray(X), np.asarray(y)","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:20:29.260573Z","iopub.execute_input":"2025-11-17T10:20:29.260949Z","iopub.status.idle":"2025-11-17T10:20:29.274389Z","shell.execute_reply.started":"2025-11-17T10:20:29.260923Z","shell.execute_reply":"2025-11-17T10:20:29.273361Z"},"trusted":true},"outputs":[],"execution_count":12},{"id":"e814f42f","cell_type":"code","source":"# Hyperparameters\nWINDOW_SIZE = 110\nSTRIDE = 22\n\n# Build sequences - returns 3D arrays (samples, timesteps, features)\nX_train, y_train = build_windows(train_df, train_target, WINDOW_SIZE, STRIDE, feature=\"3d\")\nX_val, y_val = build_windows(val_df, val_target, WINDOW_SIZE, STRIDE, feature=\"3d\")\n\nprint(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\nprint(f\"Validation set shape: {X_val.shape}, {y_val.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:20:31.823792Z","iopub.execute_input":"2025-11-17T10:20:31.824128Z","iopub.status.idle":"2025-11-17T10:20:32.604962Z","shell.execute_reply.started":"2025-11-17T10:20:31.824104Z","shell.execute_reply":"2025-11-17T10:20:32.604008Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Training set shape: (3174, 110, 29), (3174,)\nValidation set shape: (792, 110, 29), (792,)\n","output_type":"stream"}],"execution_count":13},{"id":"3ab20f4f","cell_type":"markdown","source":"## Apply Weighted Sampling to Address Class Imbalance","metadata":{}},{"id":"2a43b642","cell_type":"code","source":"from torch.utils.data import WeightedRandomSampler\n\nclass_counts = np.bincount(y_train)\nprint(\"\\n📊 Class distribution in training set:\")\nfor cls, count in enumerate(class_counts):\n    print(f\"  Class {cls}: {count} samples ({count/len(y_train)*100:.1f}%)\")\n\n# Calculate inverse-frequency weights per class\nclass_weights = 1.0 / class_counts\nclass_weights = class_weights / np.sum(class_weights)  # Normalize weights\nprint(\"\\n⚖️  Sample weights (inverse frequency):\")\nfor cls, weight in enumerate(class_weights):\n    print(f\"  Class {cls}: {weight:.4f}\")\n\n# Assign a weight to each sample based on its class (only for valid labels)\nsample_weights = np.zeros(len(y_train))\nsample_weights = class_weights[y_train]\nsample_weights = torch.from_numpy(sample_weights).double()\n\n# Create WeightedRandomSampler (oversamples minority classes)\nsampler = WeightedRandomSampler(\n    weights=sample_weights,\n    num_samples=len(sample_weights),\n    replacement=True\n)","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:20:37.801863Z","iopub.execute_input":"2025-11-17T10:20:37.802174Z","iopub.status.idle":"2025-11-17T10:20:37.813331Z","shell.execute_reply.started":"2025-11-17T10:20:37.802153Z","shell.execute_reply":"2025-11-17T10:20:37.812298Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n📊 Class distribution in training set:\n  Class 0: 2502 samples (78.8%)\n  Class 1: 408 samples (12.9%)\n  Class 2: 264 samples (8.3%)\n\n⚖️  Sample weights (inverse frequency):\n  Class 0: 0.0602\n  Class 1: 0.3692\n  Class 2: 0.5706\n","output_type":"stream"}],"execution_count":14},{"id":"b6ee699b","cell_type":"markdown","source":"## Create DataLoaders","metadata":{}},{"id":"1739946f","cell_type":"code","source":"import os\nfrom torch.utils.data import DataLoader, TensorDataset\n\nBATCH_SIZE = 64\n\ndef make_loader(ds, batch_size, shuffle, drop_last, sampler=None):\n    # Determine optimal number of worker processes for data loading\n    cpu_cores = os.cpu_count() or 2\n    num_workers = max(2, min(4, cpu_cores))\n\n    # Create DataLoader with performance optimizations\n    return DataLoader(\n        ds,\n        batch_size=batch_size,\n        shuffle=shuffle if sampler is None else False,  # shuffle and sampler are mutually exclusive\n        sampler=sampler,\n        drop_last=drop_last,\n        num_workers=num_workers,\n        pin_memory=True,  # Faster GPU transfer\n        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n        prefetch_factor=4,  # Load 4 batches ahead\n    )\n\n# Convert to PyTorch datasets\ntrain_ds = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\nval_ds = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n\n# Create data loaders\ntrain_loader = make_loader(train_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=True, sampler=sampler)\nval_loader = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n\n# Store metadata for model creation\ninput_shape = X_train.shape\nnum_classes = len(np.unique(y_train))\n\nprint(f\"\\n✅ DataLoaders created\")\nprint(f\"   Training batches: {len(train_loader)}\")\nprint(f\"   Validation batches: {len(val_loader)}\")\nprint(f\"   Input shape: {input_shape}\")\nprint(f\"   Number of classes: {num_classes}\")","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:20:42.347909Z","iopub.execute_input":"2025-11-17T10:20:42.348284Z","iopub.status.idle":"2025-11-17T10:20:42.360742Z","shell.execute_reply.started":"2025-11-17T10:20:42.348258Z","shell.execute_reply":"2025-11-17T10:20:42.359395Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n✅ DataLoaders created\n   Training batches: 49\n   Validation batches: 13\n   Input shape: (3174, 110, 29)\n   Number of classes: 3\n","output_type":"stream"}],"execution_count":15},{"id":"974fdb2c","cell_type":"markdown","source":"# **Model Setup**","metadata":{}},{"id":"708021fb","cell_type":"markdown","source":"## **Inner Logic**","metadata":{}},{"id":"b2f1a7ca","cell_type":"code","source":"from sklearn.metrics import f1_score\n\ndef train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n    \"\"\"\n    Perform one complete training epoch through the entire training dataset.\n\n    Args:\n        model (nn.Module): The neural network model to train\n        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n        l1_lambda (float): Lambda for L1 regularization\n        l2_lambda (float): Lambda for L2 regularization\n\n    Returns:\n        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n    \"\"\"\n    model.train()\n\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n\n    # Iterate through training batches\n    for _, (inputs, targets) in enumerate(train_loader):\n        # Move data to device (GPU/CPU)\n        inputs, targets = inputs.to(device), targets.to(device)\n\n        # Clear gradients from previous step\n        optimizer.zero_grad(set_to_none=True)\n\n        # Forward pass with mixed precision (if CUDA available)\n        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n          logits = model(inputs)\n          loss = criterion(logits, targets)\n\n          # --- REGULARIZATION ---\n          if l1_lambda > 0 or l2_lambda > 0:\n              for name, param in model.named_parameters():\n                  # Only regularize weight matrices\n                  if 'weight' in name:\n                      if l1_lambda > 0:\n                          loss += l1_lambda * torch.sum(torch.abs(param))\n                      if l2_lambda > 0:\n                          loss += l2_lambda * torch.sum(torch.pow(param, 2))\n\n\n        # Backward pass with gradient scaling\n        scaler.scale(loss).backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n        scaler.unscale_(optimizer)\n        scaler.step(optimizer)\n        scaler.update()\n\n        # Accumulate metrics\n        running_loss += loss.item() * inputs.size(0)\n        predictions = logits.argmax(dim=1)\n        all_predictions.append(predictions.cpu().numpy())\n        all_targets.append(targets.cpu().numpy())\n\n    # Calculate epoch metrics\n    epoch_loss = running_loss / len(train_loader.dataset)\n    epoch_f1 = f1_score(\n        np.concatenate(all_targets),\n        np.concatenate(all_predictions),\n        average='weighted',\n        zero_division=0\n    )\n\n    return epoch_loss, epoch_f1\n\n\ndef validate_one_epoch(model, val_loader, criterion, device):\n    \"\"\"\n    Perform one complete validation epoch through the entire validation dataset.\n\n    Args:\n        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n        criterion (nn.Module): Loss function used to calculate validation loss\n        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n\n    Returns:\n        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n\n    Note:\n        This function automatically sets the model to evaluation mode and disables\n        gradient computation for efficiency during validation.\n    \"\"\"\n    model.eval()  # Set model to evaluation mode\n\n    running_loss = 0.0\n    all_predictions = []\n    all_targets = []\n\n    # Disable gradient computation for validation\n    with torch.no_grad():\n        for inputs, targets in val_loader:\n            # Move data to device\n            inputs, targets = inputs.to(device), targets.to(device)\n\n            # Forward pass with mixed precision (if CUDA available)\n            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n                logits = model(inputs)\n                loss = criterion(logits, targets)\n\n            # Accumulate metrics\n            running_loss += loss.item() * inputs.size(0)\n            predictions = logits.argmax(dim=1)\n            all_predictions.append(predictions.cpu().numpy())\n            all_targets.append(targets.cpu().numpy())\n\n    # Calculate epoch metrics\n    epoch_loss = running_loss / len(val_loader.dataset)\n    epoch_accuracy = f1_score(\n        np.concatenate(all_targets),\n        np.concatenate(all_predictions),\n        average='weighted',\n        zero_division=0\n    )\n\n    return epoch_loss, epoch_accuracy\n\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output, display\n\ndef fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n        restore_best_weights=True, verbose=10, experiment_name=\"\", plot_live=False):\n    \"\"\"\n    Same as before, but with two live-updating subplots and preserved verbose output.\n    \"\"\"\n\n    training_history = {\n        'train_loss': [], 'val_loss': [],\n        'train_f1': [], 'val_f1': []\n    }\n\n    # Live plot setup\n    if plot_live:\n        plt.ion()\n        fig, (ax_loss, ax_f1) = plt.subplots(1, 2, figsize=(13, 4))\n\n    # Early stopping\n    if patience > 0:\n        patience_counter = 0\n        best_metric = float('-inf') if mode == 'max' else float('inf')\n        best_epoch = 0\n\n    print(f\"Training {epochs} epochs...\")\n\n    # --- Accumulate text output so clear_output doesn't remove it ---\n    logs = \"\"\n\n    for epoch in range(1, epochs + 1):\n\n        train_loss, train_f1 = train_one_epoch(\n            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n        )\n\n        val_loss, val_f1 = validate_one_epoch(\n            model, val_loader, criterion, device\n        )\n\n        training_history['train_loss'].append(train_loss)\n        training_history['val_loss'].append(val_loss)\n        training_history['train_f1'].append(train_f1)\n        training_history['val_f1'].append(val_f1)\n\n        # --- Verbose logging ---\n        if verbose > 0 and (epoch % verbose == 0 or epoch == 1):\n            log_line = (f\"Epoch {epoch:3d}/{epochs} | \"\n                        f\"Train: Loss={train_loss:.4f}, F1={train_f1:.4f} | \"\n                        f\"Val: Loss={val_loss:.4f}, F1={val_f1:.4f}\\n\")\n            logs += log_line\n\n        # --- 🔥 LIVE PLOTTING ---\n        if plot_live:\n            clear_output(wait=True)\n\n            # Plot 1: Loss\n            ax_loss.clear()\n            ax_loss.plot(range(1, len(training_history['train_loss']) + 1),\n                         training_history['train_loss'], linestyle='--', color='orange',\n                         label=\"Train Loss\")\n            ax_loss.plot(range(1, len(training_history['val_loss']) + 1),\n                         training_history['val_loss'], linestyle='-', color='orange',\n                         label=\"Val Loss\")\n            ax_loss.set_title(\"Loss\")\n            ax_loss.set_xlabel(\"Epoch\")\n            ax_loss.legend()\n            ax_loss.grid(True)\n\n            # Plot 2: F1\n            ax_f1.clear()\n            ax_f1.plot(range(1, len(training_history['train_f1']) + 1),\n                       training_history['train_f1'], linestyle='--', color='orange',\n                       label=\"Train F1\")\n            ax_f1.plot(range(1, len(training_history['val_f1']) + 1),\n                       training_history['val_f1'], linestyle='-', color='orange',\n                       label=\"Val F1\")\n            ax_f1.set_title(\"F1 Score\")\n            ax_f1.set_xlabel(\"Epoch\")\n            ax_f1.legend()\n            ax_f1.grid(True)\n\n            display(fig)\n\n            # Reprint accumulated logs so far\n            print(logs)\n\n            plt.pause(0.001)\n        # --------------------------------------------------------------\n\n        # Early stopping\n        if patience > 0:\n            current_metric = training_history[evaluation_metric][-1]\n            improved = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n\n            if improved:\n                best_metric = current_metric\n                best_epoch = epoch\n                torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n                patience_counter = 0\n            else:\n                patience_counter += 1\n                if patience_counter >= patience:\n                    print(f\"\\nEarly stopping triggered after {epoch} epochs.\")\n                    break\n\n    # Restore best weights\n    if restore_best_weights and patience > 0:\n        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n\n    # Save final weights if no ES\n    if patience == 0:\n        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n\n    if plot_live:\n        plt.ioff()\n\n    return model, training_history","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:22:16.300701Z","iopub.execute_input":"2025-11-17T10:22:16.301039Z","iopub.status.idle":"2025-11-17T10:22:16.465016Z","shell.execute_reply.started":"2025-11-17T10:22:16.301012Z","shell.execute_reply":"2025-11-17T10:22:16.463844Z"},"trusted":true},"outputs":[],"execution_count":16},{"id":"87fa938b","cell_type":"markdown","source":"## **Model Definition**","metadata":{}},{"id":"e8d9136a","cell_type":"code","source":"# ============================================================================\n# MODEL SETUP\n# ============================================================================\nimport torch.nn as nn\nfrom model_definitions.cnn_lstm import CNNLSTMClassifier\n\nmodel = CNNLSTMClassifier(\n    input_size=input_shape[-1],\n    num_classes=num_classes,\n    num_filters=[128, 256, 256],\n    kernel_sizes=[9, 13, 5],\n    dropout_rate=0.3,\n    bidirectional=True\n).to(device)\n\n\nprint(f\"\\n🔧 Model: {model.__class__.__name__}\")\nprint(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:22:25.043791Z","iopub.execute_input":"2025-11-17T10:22:25.044107Z","iopub.status.idle":"2025-11-17T10:22:25.100896Z","shell.execute_reply.started":"2025-11-17T10:22:25.044084Z","shell.execute_reply":"2025-11-17T10:22:25.099660Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n🔧 Model: CNNLSTMClassifier\n   Parameters: 809,603\n","output_type":"stream"}],"execution_count":17},{"id":"fa00afd7","cell_type":"markdown","source":"## Loss Function, Optimizer, Gradient Scaler","metadata":{}},{"id":"de0dcf78","cell_type":"code","source":"# Calculate class weights: inverse frequency with normalization\ntrain_class_counts = np.bincount(y_train.astype(int))\nclass_weights_loss = len(y_train) / (len(train_class_counts) * train_class_counts)\nclass_weights_loss = torch.tensor(class_weights_loss, dtype=torch.float32).to(device)\n\nprint(f\"\\n⚖️  Loss weights (amplifies gradients for minority classes):\")\nfor cls, weight in enumerate(class_weights_loss):\n    print(f\"  Class {cls}: {weight:.4f}x\")\n\n# criterion = nn.CrossEntropyLoss(weight=class_weights_loss, label_smoothing=0.1)\n\nclass FocalLoss(nn.Module):\n    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n        \"\"\"\n        Focal Loss for multi-class classification.\n\n        Parameters:\n        - alpha: Tensor of shape [num_classes] containing class weights. \n                 Use None if no weighting is needed (e.g., if using a WeightedRandomSampler).\n        - gamma: focusing parameter. Higher gamma → focus more on hard examples.\n        - reduction: 'mean', 'sum', or 'none'\n        \"\"\"\n        super().__init__()\n        self.alpha = alpha  # should be a tensor or None\n        self.gamma = gamma\n        self.reduction = reduction\n        self.ce = nn.CrossEntropyLoss(reduction='none')\n\n    def forward(self, inputs, targets):\n        \"\"\"\n        inputs: [batch_size, num_classes] logits\n        targets: [batch_size] long tensor of class indices\n        \"\"\"\n        # Compute per-sample cross entropy\n        ce_loss = self.ce(inputs, targets)  # [batch_size]\n\n        # Compute probability of correct class\n        pt = torch.exp(-ce_loss)  # [batch_size]\n\n        # Apply class weights if provided\n        if self.alpha is not None:\n            # Ensure alpha is on the same device as inputs\n            alpha = self.alpha.to(inputs.device)\n            alpha_t = alpha[targets]  # pick weight per sample\n            focal_loss = alpha_t * ((1 - pt) ** self.gamma) * ce_loss\n        else:\n            focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n\n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        else:  # 'none'\n            return focal_loss\n\ncriterion = FocalLoss(alpha=None, gamma=2.0)\n\noptimizer = torch.optim.AdamW(\n    model.parameters(),\n    lr=1e-3,           # Learning rate\n    weight_decay=1e-4  # L2 regularization\n)\n\nscaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))","metadata":{"execution":{"iopub.status.busy":"2025-11-17T10:22:31.975880Z","iopub.execute_input":"2025-11-17T10:22:31.976231Z","iopub.status.idle":"2025-11-17T10:22:35.916325Z","shell.execute_reply.started":"2025-11-17T10:22:31.976187Z","shell.execute_reply":"2025-11-17T10:22:35.915252Z"},"trusted":true},"outputs":[{"name":"stdout","text":"\n⚖️  Loss weights (amplifies gradients for minority classes):\n  Class 0: 0.4229x\n  Class 1: 2.5931x\n  Class 2: 4.0076x\n","output_type":"stream"}],"execution_count":18},{"id":"6cfa3245-c39b-48c0-9ff8-d428dbc2ce39","cell_type":"markdown","source":"## Optuna Search","metadata":{}},{"id":"d101e69d-393c-4238-8c02-aa3cb1b27d9f","cell_type":"code","source":"from sklearn.model_selection import KFold\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"📊 SETTING UP K-FOLD CROSS-VALIDATION\")\nprint(\"=\"*80)\n\nK_FOLDS = 5\n\n# Create K-Fold splits (fixed, will be reused for all Optuna trials)\nkfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\nfold_indices = list(kfold.split(X_train))\n\nprint(f\"   Fold splits created: {len(fold_indices)} folds ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T10:25:07.566902Z","iopub.execute_input":"2025-11-17T10:25:07.568130Z","iopub.status.idle":"2025-11-17T10:25:07.591490Z","shell.execute_reply.started":"2025-11-17T10:25:07.568093Z","shell.execute_reply":"2025-11-17T10:25:07.590458Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\n📊 SETTING UP K-FOLD CROSS-VALIDATION\n================================================================================\n   Fold splits created: 5 folds ready\n","output_type":"stream"}],"execution_count":24},{"id":"0f6953c7-8ada-4719-bb57-7f42d15ed35f","cell_type":"code","source":"def optuna_objective(trial):\n    \"\"\"\n    Optuna objective function.\n    Trains model on K-Fold and returns average validation F1.\n    \"\"\"\n\n    # ========================================================================\n    # SUGGEST HYPERPARAMETERS\n    # ========================================================================\n    hidden_size = trial.suggest_categorical('hidden_size', [64, 128, 256, 512])\n    num_layers = trial.suggest_int('num_layers', 1, 3)\n    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5, step=0.1)\n    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n    l1_lambda = trial.suggest_categorical('l1_lambda', [0, 0.001, 0.01])\n    l2_lambda = trial.suggest_categorical('l2_lambda', [0, 1e-5, 1e-4, 1e-3])\n\n    # ========================================================================\n    # K-FOLD TRAINING\n    # ========================================================================\n    fold_scores = []\n\n    for fold_idx, (train_idx, val_idx) in enumerate(fold_indices):\n        # Split data for this fold\n        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n\n        # Create datasets\n        train_ds = TensorDataset(torch.from_numpy(X_fold_train).float(), torch.from_numpy(y_fold_train).long())\n        val_ds = TensorDataset(torch.from_numpy(X_fold_val).float(), torch.from_numpy(y_fold_val).long())\n\n        # Weighted sampling for class imbalance\n        fold_class_counts = np.bincount(y_fold_train.astype(int))\n        class_weights_sampling = 1.0 / fold_class_counts\n        class_weights_sampling = class_weights_sampling / np.sum(class_weights_sampling)\n        sample_weights = class_weights_sampling[y_fold_train.astype(int)]\n        sample_weights = torch.from_numpy(sample_weights).float()\n\n        sampler = WeightedRandomSampler(\n            weights=sample_weights,\n            num_samples=len(sample_weights),\n            replacement=True\n        )\n\n        # Create data loaders\n        train_loader = make_loader(train_ds, batch_size=batch_size, shuffle=False, drop_last=True, sampler=sampler)\n        val_loader = make_loader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n\n        # Create model\n        model = CNNLSTMClassifier(\n            input_size=input_shape[-1],\n            num_classes=num_classes,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            dropout_rate=dropout_rate\n        ).to(device)\n\n        # Loss & Optimizer\n        fold_class_weights_loss = len(y_fold_train) / (len(fold_class_counts) * fold_class_counts)\n        fold_class_weights_loss = torch.tensor(fold_class_weights_loss, dtype=torch.float32).to(device)\n        criterion = nn.CrossEntropyLoss(weight=fold_class_weights_loss)\n\n        optimizer = torch.optim.AdamW(\n            model.parameters(),\n            lr=learning_rate,\n            weight_decay=l2_lambda\n        )\n\n        scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n\n        # Train\n        _, history = fit(\n            model=model,\n            train_loader=train_loader,\n            val_loader=val_loader,\n            epochs=30,\n            criterion=criterion,\n            optimizer=optimizer,\n            scaler=scaler,\n            device=device,\n            patience=50,\n            l1_lambda=l1_lambda,\n            verbose=0  # Silent during Optuna\n        )\n\n        # Get best F1 for this fold\n        best_f1 = max(history['val_f1'])\n        fold_scores.append(best_f1)\n\n        # Report intermediate value for pruning\n        trial.report(best_f1, fold_idx)\n\n        # Prune if performing poorly\n        if trial.should_prune():\n            raise optuna.TrialPruned()\n\n    # Return average F1 across all folds\n    avg_f1 = np.mean(fold_scores)\n    return avg_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T10:28:26.990131Z","iopub.execute_input":"2025-11-17T10:28:26.990480Z","iopub.status.idle":"2025-11-17T10:28:27.004640Z","shell.execute_reply.started":"2025-11-17T10:28:26.990456Z","shell.execute_reply":"2025-11-17T10:28:27.003476Z"}},"outputs":[],"execution_count":31},{"id":"21867b47-accf-4072-bf73-65eb3bf90191","cell_type":"code","source":"import optuna\nfrom optuna.pruners import MedianPruner\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"🔍 STARTING OPTUNA HYPERPARAMETER OPTIMIZATION\")\nprint(\"=\"*80)\n\n# Optuna configuration\nN_TRIALS = 5\nTIMEOUT = 6 * 3600  # 6 hours\n\n# Create pruner\npruner = MedianPruner(\n    n_startup_trials=5,\n    n_warmup_steps=3,\n    interval_steps=10\n)\n\n# Create study\nstudy = optuna.create_study(\n    direction='maximize',\n    pruner=pruner,\n    study_name='bilstm_kfold_optimization'\n)\n\nprint(f\"\\n⚙  Configuration:\")\nprint(f\"   Trials: {N_TRIALS}\")\nprint(f\"   Timeout: {TIMEOUT/3600:.1f} hours\")\nprint(f\"   K-Folds: {K_FOLDS}\")\nprint(f\"   Epochs per trial: 200 (with patience=30)\")\nprint(f\"   Pruning: Enabled (MedianPruner)\")\n\nprint(f\"\\n🚀 Starting optimization...\")\nprint(f\"   This will take approximately 5-8 hours\")\nprint(\"=\"*80)\n\n# Run optimization\nstudy.optimize(\n    optuna_objective,\n    n_trials=N_TRIALS,\n    timeout=TIMEOUT,\n    show_progress_bar=True\n)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"✅ OPTUNA OPTIMIZATION COMPLETE!\")\nprint(\"=\"*80)\n\n# Best trial\nbest_trial = study.best_trial\nprint(f\"\\n🏆 Best Trial:\")\nprint(f\"   Trial number: {best_trial.number}\")\nprint(f\"   Best F1 score: {best_trial.value:.4f}\")\nprint(f\"\\n🎯 Best Hyperparameters:\")\nfor key, value in best_trial.params.items():\n    print(f\"   {key}: {value}\")\n\n# Save study\nwith open('optuna_study_cnnlstm.pkl', 'wb') as f:\n    pickle.dump(study, f)\nprint(f\"\\n💾 Study saved to 'optuna_study_cnnlstm.pkl'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T10:28:28.689631Z","iopub.execute_input":"2025-11-17T10:28:28.690814Z"}},"outputs":[{"name":"stderr","text":"[I 2025-11-17 10:28:28,696] A new study created in memory with name: bilstm_kfold_optimization\n","output_type":"stream"},{"name":"stdout","text":"\n================================================================================\n🔍 STARTING OPTUNA HYPERPARAMETER OPTIMIZATION\n================================================================================\n\n⚙  Configuration:\n   Trials: 5\n   Timeout: 6.0 hours\n   K-Folds: 1\n   Epochs per trial: 200 (with patience=30)\n   Pruning: Enabled (MedianPruner)\n\n🚀 Starting optimization...\n   This will take approximately 5-8 hours\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6718e6624fa445afa6f9149f53657eed"}},"metadata":{}},{"name":"stdout","text":"Training 30 epochs...\n","output_type":"stream"}],"execution_count":null},{"id":"f782e907","cell_type":"markdown","source":"# **Fit Model**","metadata":{}},{"id":"40fd43a7-edc5-48ca-9abf-eea09f7e6f1e","cell_type":"code","source":"# ============================================================================\n# TRAINING\n# ============================================================================\nprint(f\"\\n{'='*70}\")\nprint(f\"Training {model.__class__.__name__}...\")\nprint(f\"{'='*70}\")\n\n_, history = fit(\n    model=model,\n    train_loader=train_loader,\n    val_loader=val_loader,\n    epochs=500,\n    criterion=criterion,\n    optimizer=optimizer,\n    scaler=scaler,\n    device=device,\n    verbose=5,\n    experiment_name=\"model_training\",\n    patience=20,       # Set > 0 for early stopping\n    l1_lambda=0,      # L1 regularization\n    l2_lambda=0,       # L2 regularization (or use weight_decay in optimizer)\n    plot_live=True\n)","metadata":{"execution":{"iopub.execute_input":"2025-11-16T16:58:59.370037Z","iopub.status.busy":"2025-11-16T16:58:59.369418Z","iopub.status.idle":"2025-11-16T16:59:37.781583Z","shell.execute_reply":"2025-11-16T16:59:37.780839Z","shell.execute_reply.started":"2025-11-16T16:58:59.370015Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"7151d49d-9d9f-496c-b0ac-e464786f63b7","cell_type":"code","source":"# ============================================================================\n# RESULTS\n# ============================================================================\nprint(\"\\n\" + \"=\" * 70)\nprint(\"📊 TRAINING RESULTS:\")\nprint(\"=\" * 70)\nprint(f\"  Initial val F1: {history['val_f1'][0]:.4f}\")\nprint(f\"  Final val F1:   {history['val_f1'][-1]:.4f}\")\nprint(f\"  Best val F1:    {max(history['val_f1']):.4f}\")\nprint(f\"  Improvement:    {max(history['val_f1']) - history['val_f1'][0]:+.4f}\")\n\n# Per-class predictions\nfrom sklearn.metrics import classification_report\nmodel.eval()\nval_preds = []\nval_true = []\nwith torch.no_grad():\n    for inputs, targets in val_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        preds = outputs.argmax(dim=1)\n        val_preds.extend(preds.cpu().numpy())\n        val_true.extend(targets.cpu().numpy())\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"📈 CLASSIFICATION REPORT:\")\nprint(\"=\" * 70)\nprint(classification_report(\n    val_true, val_preds,\n    target_names=['no_pain', 'low_pain', 'high_pain'],\n    digits=4\n))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"ed37f45d","cell_type":"markdown","source":"## **Plot Results**","metadata":{}},{"id":"c9a77c4e","cell_type":"code","source":"# @title Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\n\n# Get predictions for the validation set\nmodel.eval()\nval_predictions = []\nval_targets = []\nwith torch.no_grad():\n    for inputs, targets in val_loader:\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        val_predictions.extend(predicted.cpu().numpy())\n        val_targets.extend(targets.cpu().numpy())\n\n# Calculate the confusion matrix\ncm = confusion_matrix(val_targets, val_predictions)\n\n# Define class labels\nclass_labels = ['no_pain', 'low_pain', 'high_pain']\n\n# Plot the confusion matrix\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.title('Confusion Matrix (Validation Set)')\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:09:45.640506Z","iopub.status.busy":"2025-11-16T15:09:45.640162Z","iopub.status.idle":"2025-11-16T15:09:46.383435Z","shell.execute_reply":"2025-11-16T15:09:46.382590Z","shell.execute_reply.started":"2025-11-16T15:09:45.640477Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"d55ca596","cell_type":"code","source":"# @title Plot History\n\n# Create a figure with two side-by-side subplots (two columns)\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n\n# Plot of training and validation loss on the first axis\nax1.plot(history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\nax1.plot(history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\nax1.set_title('Loss')\nax1.legend()\nax1.grid(alpha=0.3)\n\n# Plot of training and validation accuracy on the second axis\nax2.plot(history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\nax2.plot(history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\nax2.set_title('F1 Score')\nax2.legend()\nax2.grid(alpha=0.3)\n\n# Adjust the layout and display the plot\nplt.tight_layout()\nplt.subplots_adjust(right=0.85)\nplt.show()","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:09:48.521153Z","iopub.status.busy":"2025-11-16T15:09:48.520717Z","iopub.status.idle":"2025-11-16T15:09:49.041579Z","shell.execute_reply":"2025-11-16T15:09:49.040925Z","shell.execute_reply.started":"2025-11-16T15:09:48.521128Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"52380347","cell_type":"markdown","source":"# Inference","metadata":{}},{"id":"773a3709","cell_type":"code","source":"# Create test dataset and loader\ntest_df = build_windows(df_test, None, WINDOW_SIZE, STRIDE, feature=\"3d\")[0]\nX_test = test_df.astype(np.float32)\ntest_loader = make_loader(\n    TensorDataset(torch.from_numpy(X_test).float()), \n    batch_size=32, \n    shuffle=False,\n    drop_last=False\n)\n\n# Generate predictions for all windows\nall_window_preds = []\nmodel.eval()\n\nwith torch.no_grad():\n    for xb in test_loader:\n        xb = xb[0].to(device)\n        outputs = model(xb)\n        _, preds = torch.max(outputs.data, 1)\n        all_window_preds.extend(preds.cpu().numpy())\n\nprint(f\"\\n📊 Generated {len(all_window_preds)} window predictions\")","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:09:52.903340Z","iopub.status.busy":"2025-11-16T15:09:52.902670Z","iopub.status.idle":"2025-11-16T15:09:55.797797Z","shell.execute_reply":"2025-11-16T15:09:55.796984Z","shell.execute_reply.started":"2025-11-16T15:09:52.903314Z"},"trusted":true},"outputs":[],"execution_count":null},{"id":"ab86a3a8","cell_type":"code","source":"# ============================================================================\n# AGGREGATE PREDICTIONS PER PIRATE (sample_index)\n# ============================================================================\n# Calculate how many windows per sample_index\nnum_test_samples = len(df_test['sample_index'].unique())\nwindows_per_sample = len(all_window_preds) // num_test_samples\n\nprint(f\"   Test samples: {num_test_samples}\")\nprint(f\"   Windows per sample: {windows_per_sample}\")\n\n# Aggregate predictions using sum of logits (confidence-weighted voting)\nlabel_mapping = {0: 'no_pain', 1: 'low_pain', 2: 'high_pain'}\nfinal_predictions = []\n\n# Get probability scores for all windows\nall_window_probs = []\nmodel.eval()\n\nwith torch.no_grad():\n    for xb in test_loader:\n        xb = xb[0].to(device)\n        outputs = model(xb)\n        probs = torch.softmax(outputs, dim=1)  # Convert logits to probabilities\n        all_window_probs.extend(probs.cpu().numpy())\n\nall_window_probs = np.array(all_window_probs)\n\n# Aggregate using sum of probabilities\nfor sample_idx in range(num_test_samples):\n    # Get all window predictions for this sample_index\n    start_idx = sample_idx * windows_per_sample\n    end_idx = start_idx + windows_per_sample\n    window_probs = all_window_probs[start_idx:end_idx]\n    \n    # Sum probabilities across all windows for each class\n    class_scores = window_probs.sum(axis=0)  # Shape: (3,) for 3 classes\n    \n    # Winner: class with highest total confidence\n    predicted_class = class_scores.argmax()\n    final_predictions.append(label_mapping[predicted_class])\n\nprint(f\"\\nAggregated to {len(final_predictions)} final predictions (one per pirate)\")\n\n# Create submission CSV\nfrom datetime import datetime\npredictions_df = pd.DataFrame({\n    'sample_index': np.arange(num_test_samples),\n    'label': final_predictions\n})\n\ntimestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\nfilename = f'predictions_{timestamp}.csv'\npredictions_df.to_csv(filename, index=False)\n\nprint(f\"\\nPredictions saved to: {filename}\")\nprint(f\"Total predictions: {len(final_predictions)} (one per pirate)\")\nprint(f\"\\nDistribution:\")\nfor label in ['no_pain', 'low_pain', 'high_pain']:\n    count = final_predictions.count(label)\n    pct = (count / len(final_predictions)) * 100\n    print(f\"   {label:10s}: {count:5d} ({pct:5.2f}%)\")","metadata":{"execution":{"iopub.execute_input":"2025-11-16T15:09:55.799642Z","iopub.status.busy":"2025-11-16T15:09:55.799405Z","iopub.status.idle":"2025-11-16T15:09:56.079086Z","shell.execute_reply":"2025-11-16T15:09:56.078240Z","shell.execute_reply.started":"2025-11-16T15:09:55.799619Z"},"trusted":true},"outputs":[],"execution_count":null}]}