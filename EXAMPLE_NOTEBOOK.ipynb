{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "712fa9f4",
   "metadata": {},
   "source": [
    "# **Notebook Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ad8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLAB IMPORTS\n",
    "!git clone https://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@github.com/francinze/Ch1_An2DL.git\n",
    "! pip install -q kaggle\n",
    "! mkdir ~/.kaggle\n",
    "! cp Ch1_An2DL/kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle competitions download -c an2dl2526c1\n",
    "!unzip an2dl2526c1.zip -d Ch1_An2DL/\n",
    "%cd /content/Ch1_An2DL/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eb6750",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e971aa8",
   "metadata": {},
   "source": [
    "# **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da882a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"pirate_pain_train.csv\")\n",
    "df_test = pd.read_csv(\"pirate_pain_test.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b087cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cafa0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"pirate_pain_train_labels.csv\")\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef8b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pain_survey_cols = ['pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4']\n",
    "joint_cols = [f'joint_{str(i).zfill(2)}' for i in range(1, 31)]\n",
    "body_cols = ['n_legs', 'n_eyes', 'n_hands']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beca32d",
   "metadata": {},
   "source": [
    "# **Data Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65afb952",
   "metadata": {},
   "source": [
    "## **Body columns**\n",
    "Investigate the body columns in the dataset. Use pandas to load the dataset and display the first few rows to understand its structure.\n",
    "\n",
    "We will see how correlated these columns are between themselves, and with respect to the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d128375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create encoded versions for correlation analysis\n",
    "for col in body_cols:\n",
    "    df_train[f'{col}_encoded'] = (df_train[col] == 'two').astype(int)\n",
    "    df_test[f'{col}_encoded'] = (df_test[col] == 'two').astype(int)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_features = [f'{col}_encoded' for col in body_cols]\n",
    "corr_matrix = df_train[correlation_features].corr()\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.4f', cmap='coolwarm', \n",
    "            square=True, vmin=0, vmax=1, cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Correlation Matrix: n_legs, n_hands, n_eyes', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(3), body_cols, rotation=45)\n",
    "plt.yticks(range(3), body_cols, rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print correlation values\n",
    "print(\"Correlation Matrix:\")\n",
    "print(\"=\" * 50)\n",
    "corr_matrix.index = body_cols\n",
    "corr_matrix.columns = body_cols\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765082ab",
   "metadata": {},
   "source": [
    "### Result: Perfect correlation (1.0) detected!\n",
    "These three features are 100% identical. It means that there is a perfect correspondence between their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd921fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that all three features always have the same value\n",
    "print(\"Verifying redundancy...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show unique combinations\n",
    "print(\"Unique combinations in the data:\")\n",
    "print(\"=\" * 60)\n",
    "unique_combos = df_train[body_cols].drop_duplicates()\n",
    "for idx, row in unique_combos.iterrows():\n",
    "    count = ((df_train['n_legs'] == row['n_legs']) & \n",
    "             (df_train['n_hands'] == row['n_hands']) & \n",
    "             (df_train['n_eyes'] == row['n_eyes'])).sum()\n",
    "    print(f\"  {row['n_legs']:15s} | {row['n_hands']:15s} | {row['n_eyes']:15s} → {count:,} samples\")\n",
    "\n",
    "print(\"\\nConclusion: Only 2 combinations exist (all natural OR all prosthetic) → Safe to consolidate into a single binary feature!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d298de",
   "metadata": {},
   "source": [
    "## **Pain Surveys**\n",
    "Instead we see here the pain survey columns, and we investigate their values and correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ccacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(pain_survey_cols):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # percentages\n",
    "    train_pct = df_train[col].value_counts(normalize=True).mul(100)\n",
    "    test_pct = df_test[col].value_counts(normalize=True).mul(100)\n",
    "\n",
    "    # ensure same levels and sorted order\n",
    "    levels = sorted(set(train_pct.index).union(set(test_pct.index)))\n",
    "    train_pct = train_pct.reindex(levels, fill_value=0)\n",
    "    test_pct = test_pct.reindex(levels, fill_value=0)\n",
    "\n",
    "    # prepare long dataframe for seaborn\n",
    "    plot_df = pd.DataFrame({\n",
    "        'Pain Level': levels,\n",
    "        'Train': train_pct.values,\n",
    "        'Test': test_pct.values\n",
    "    }).melt(id_vars='Pain Level', var_name='Dataset', value_name='percentage')\n",
    "\n",
    "    sns.barplot(x='Pain Level', y='percentage', hue='Dataset', data=plot_df, ax=ax, palette='viridis')\n",
    "    ax.set_title(f'{col} - Train vs Test')\n",
    "    ax.set_xlabel('Pain Level')\n",
    "    ax.set_ylabel('Percentage (%)')\n",
    "    ax.set_ylim(0, 100)\n",
    "\n",
    "    # keep legend only on the first subplot\n",
    "    try:\n",
    "        if i == 0:\n",
    "            ax.legend(title='Dataset')\n",
    "        else:\n",
    "            ax.get_legend().remove()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "fig.suptitle('Percentage Distribution of Pain Surveys: Train vs Test', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d191fa25",
   "metadata": {},
   "source": [
    "No significant difference in distribution for the surveys, both between the train and test sets, and between the different survey types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937d5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate the Pearson correlation matrix for the pain_survey_cols in df_train\n",
    "corr_matrix_train = df_train[pain_survey_cols].corr(method='pearson')\n",
    "\n",
    "# 2. Calculate the Pearson correlation matrix for the pain_survey_cols in df_test\n",
    "corr_matrix_test = df_test[pain_survey_cols].corr(method='pearson')\n",
    "\n",
    "# 3. Create a figure with two subplots for heatmaps\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "fig.suptitle('Inter-correlation of Pain Survey Columns (Train vs. Test)', fontsize=18)\n",
    "\n",
    "# Heatmap for Training Data\n",
    "sns.heatmap(corr_matrix_train, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, ax=axes[0])\n",
    "axes[0].set_title('Pain Survey Correlation Matrix - Train Data', fontsize=14)\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].tick_params(axis='y', rotation=0)\n",
    "\n",
    "# Heatmap for Testing Data\n",
    "sns.heatmap(corr_matrix_test, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, ax=axes[1])\n",
    "axes[1].set_title('Pain Survey Correlation Matrix - Test Data', fontsize=14)\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].tick_params(axis='y', rotation=0)\n",
    "\n",
    "# Adjust the layout to prevent overlapping titles and display the plot\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust rect to make space for suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6367bb",
   "metadata": {},
   "source": [
    "The surveys do not appear to be correlated with each other. Maximal correlation is about 0.06 between \"pain_survey_1\" and \"pain_survey_3\", which is very low and can be considered negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719d4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "df_train_merged = pd.merge(df_train, train_labels, on='sample_index', how='left')\n",
    "\n",
    "print(\"Performing ANOVA for each pain_survey column against 'label' in df_train_merged:\")\n",
    "for pain_col in pain_survey_cols:\n",
    "    print(f\"\\n--- ANOVA for {pain_col} vs. label ---\")\n",
    "    # Get unique labels\n",
    "    labels = df_train_merged['label'].unique()\n",
    "\n",
    "    # Prepare data for ANOVA: a list of arrays, each array containing pain_col values for a specific label\n",
    "    data_for_anova = [df_train_merged[pain_col][df_train_merged['label'] == label].values for label in labels]\n",
    "\n",
    "    # Perform ANOVA test\n",
    "    f_statistic, p_value = f_oneway(*data_for_anova)\n",
    "\n",
    "    print(f\"F-statistic: {f_statistic:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "    # Interpret the p-value\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(f\"Conclusion: Since p-value ({p_value:.4f}) < alpha ({alpha}), we reject the null hypothesis. There is a statistically significant difference in {pain_col} means across different pain labels.\")\n",
    "    else:\n",
    "        print(f\"Conclusion: Since p-value ({p_value:.4f}) >= alpha ({alpha}), we fail to reject the null hypothesis. There is no statistically significant difference in {pain_col} means across different pain labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc65465",
   "metadata": {},
   "source": [
    "ANOVA tests also confirm that all 4 survey columns have minimal p-values, they are all statistically significant towards the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd8d21",
   "metadata": {},
   "source": [
    "## Mapping pain target variable to numerical classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ecd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = df_train_merged['label'].unique()\n",
    "print(f\"Unique pain labels: {unique_labels}\")\n",
    "pain_label_mapping = {\n",
    "    'no_pain': 0,\n",
    "    'low_pain': 1,\n",
    "    'high_pain': 2\n",
    "}\n",
    "df_train_merged['pain_level'] = df_train_merged['label'].map(pain_label_mapping)\n",
    "df_train_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529e9f61",
   "metadata": {},
   "source": [
    "## **Joint Columns**\n",
    "Then we analyze the joint columns in the dataset, and their correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "anova_results = {}\n",
    "\n",
    "for col in joint_cols:\n",
    "    # Group data by pain level\n",
    "    group0 = df_train_merged[df_train_merged['pain_level'] == 0][col]\n",
    "    group1 = df_train_merged[df_train_merged['pain_level'] == 1][col]\n",
    "    group2 = df_train_merged[df_train_merged['pain_level'] == 2][col]\n",
    "\n",
    "    # Perform ANOVA test\n",
    "    # Ensure all groups have data to avoid errors\n",
    "    if len(group0) > 1 and len(group1) > 1 and len(group2) > 1:\n",
    "        f_statistic, p_value = f_oneway(group0, group1, group2)\n",
    "        anova_results[col] = p_value\n",
    "    else:\n",
    "        anova_results[col] = float('nan') # Assign NaN if a group is too small for ANOVA\n",
    "\n",
    "# Sort results by p-value for easier interpretation\n",
    "sorted_anova_results = sorted(anova_results.items(), key=lambda x: x[1])\n",
    "\n",
    "print(\"ANOVA p-values for joint columns (sorted by significance):\")\n",
    "for col, p_val in sorted_anova_results:\n",
    "    print(f\"  {col}: {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd5e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_data_train = df_train[joint_cols]\n",
    "correlation_matrix_train = joint_data_train.corr()\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(correlation_matrix_train, annot=False, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of Joint Columns in df_train')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628961a0",
   "metadata": {},
   "source": [
    "The correlation matrix shows that several joint columns are highly correlated with each other. For example, \"joint_10\" and \"joint_11\" have a correlation of >0.9, indicating a strong linear relationship between these two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c39488",
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_data_test = df_test[joint_cols]\n",
    "correlation_matrix_test = joint_data_test.corr()\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(correlation_matrix_test, annot=False, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of Joint Columns in df_test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa983224",
   "metadata": {},
   "source": [
    "Again, no significant difference between train and test sets. The same correlation we saw in the train set is also present in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc83d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Statistical Descriptions for Joint Columns in df_train:\")\n",
    "display(df_train[joint_cols].describe())\n",
    "print(\"Statistical Descriptions for Joint Columns in df_test:\")\n",
    "display(df_test[joint_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690f8fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set style for attractive visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "# Calculate outliers using IQR method for each joint column\n",
    "outlier_stats = []\n",
    "for col in joint_cols:\n",
    "    Q1 = df_train[col].quantile(0.25)\n",
    "    Q3 = df_train[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df_train[(df_train[col] < lower_bound) | (df_train[col] > upper_bound)][col]\n",
    "    outlier_count = len(outliers)\n",
    "    outlier_pct = (outlier_count / len(df_train)) * 100\n",
    "    \n",
    "    outlier_stats.append({\n",
    "        'joint': col,\n",
    "        'count': outlier_count,\n",
    "        'percentage': outlier_pct,\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_stats)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Bar chart of outlier percentages\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "colors = plt.cm.RdYlGn_r(outlier_df['percentage'] / outlier_df['percentage'].max())\n",
    "bars = ax1.bar(range(len(outlier_df)), outlier_df['percentage'], color=colors, edgecolor='black', linewidth=0.5)\n",
    "ax1.set_xlabel('Joint Column', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Outlier Percentage (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Percentage of Outliers per Joint Column (IQR Method)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(range(len(outlier_df)))\n",
    "ax1.set_xticklabels(outlier_df['joint'], rotation=45, ha='right')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for i, (bar, pct) in enumerate(zip(bars, outlier_df['percentage'])):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{pct:.1f}%', ha='center', va='bottom', fontsize=7)\n",
    "\n",
    "# 2. Box plots for top 15 joints with most outliers\n",
    "ax2 = fig.add_subplot(gs[1, :])\n",
    "top_outliers = outlier_df.nlargest(15, 'percentage')['joint'].tolist()\n",
    "box_data = [df_train[col].values for col in top_outliers]\n",
    "\n",
    "bp = ax2.boxplot(box_data, labels=top_outliers, patch_artist=True, \n",
    "                  flierprops=dict(marker='o', markerfacecolor='red', markersize=2, alpha=0.3))\n",
    "\n",
    "for patch, col in zip(bp['boxes'], top_outliers):\n",
    "    patch.set_facecolor(plt.cm.viridis(top_outliers.index(col) / len(top_outliers)))\n",
    "\n",
    "ax2.set_xlabel('Joint Column', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Value', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Box Plot: Top 15 Joints with Most Outliers', fontsize=14, fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Heatmap of outlier counts\n",
    "ax3 = fig.add_subplot(gs[2, 0])\n",
    "outlier_matrix = outlier_df['percentage'].values.reshape(5, 6)  # 30 joints in 5x6 grid\n",
    "im = ax3.imshow(outlier_matrix, cmap='YlOrRd', aspect='auto')\n",
    "ax3.set_xticks(range(6))\n",
    "ax3.set_yticks(range(5))\n",
    "ax3.set_xticklabels([f'Col {i+1}' for i in range(6)])\n",
    "ax3.set_yticklabels([f'Row {i+1}' for i in range(5)])\n",
    "ax3.set_title('Outlier Heatmap (% by Position)', fontsize=13, fontweight='bold')\n",
    "\n",
    "# Add values to heatmap\n",
    "for i in range(5):\n",
    "    for j in range(6):\n",
    "        idx = i * 6 + j\n",
    "        if idx < len(outlier_df):\n",
    "            text = ax3.text(j, i, f'{outlier_matrix[i, j]:.1f}%',\n",
    "                           ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "\n",
    "plt.colorbar(im, ax=ax3, label='Outlier %')\n",
    "\n",
    "# 4. Summary statistics table\n",
    "ax4 = fig.add_subplot(gs[2, 1])\n",
    "ax4.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "╔══════════════════════════════════════════════╗\n",
    "║          OUTLIER SUMMARY STATISTICS          ║\n",
    "╠══════════════════════════════════════════════╣\n",
    "║  Total Joints Analyzed:        {len(outlier_df):>12}  ║\n",
    "║  Total Data Points:            {len(df_train):>12,}  ║\n",
    "║                                              ║\n",
    "║  Avg Outliers per Joint:       {outlier_df['percentage'].mean():>11.2f}%  ║\n",
    "║  Max Outliers (joint):         {outlier_df['percentage'].max():>11.2f}%  ║\n",
    "║  Min Outliers (joint):         {outlier_df['percentage'].min():>11.2f}%  ║\n",
    "║                                              ║\n",
    "║  Joint with Most Outliers:                   ║\n",
    "║    {outlier_df.loc[outlier_df['percentage'].idxmax(), 'joint']:>12} ({outlier_df['percentage'].max():.2f}%)   ║\n",
    "║                                              ║\n",
    "║  Joint with Least Outliers:                  ║\n",
    "║    {outlier_df.loc[outlier_df['percentage'].idxmin(), 'joint']:>12} ({outlier_df['percentage'].min():.2f}%)   ║\n",
    "╚══════════════════════════════════════════════╝\n",
    "\"\"\"\n",
    "\n",
    "ax4.text(0.5, 0.5, summary_text, \n",
    "         fontsize=10, \n",
    "         family='monospace',\n",
    "         ha='center', \n",
    "         va='center',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "plt.suptitle('Joint Columns Outlier Analysis', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED OUTLIER STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(outlier_df.sort_values('percentage', ascending=False).to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c613c21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze each joint column for extreme anomalies\n",
    "anomaly_report = []\n",
    "\n",
    "for col in joint_cols:\n",
    "    data = df_train[col]\n",
    "    \n",
    "    # Calculate percentiles to understand typical range\n",
    "    p01 = data.quantile(0.01)\n",
    "    p50 = data.quantile(0.50)  # median\n",
    "    p99 = data.quantile(0.99)\n",
    "    \n",
    "    # Calculate mean and std of the bulk of the data (1st-99th percentile)\n",
    "    bulk_data = data[(data >= p01) & (data <= p99)]\n",
    "    bulk_mean = bulk_data.mean()\n",
    "    bulk_std = bulk_data.std()\n",
    "    \n",
    "    # Find values that are way outside the typical range\n",
    "    # Using 10 standard deviations as threshold for extreme anomalies\n",
    "    threshold = 10\n",
    "    extreme_low = bulk_mean - threshold * bulk_std\n",
    "    extreme_high = bulk_mean + threshold * bulk_std\n",
    "    \n",
    "    anomalies = data[(data < extreme_low) | (data > extreme_high)]\n",
    "    \n",
    "    # Also check for magnitude differences (e.g., 0.8 among 1e-05 values)\n",
    "    # If median is very small, check for values that are orders of magnitude larger\n",
    "    if p50 < 0.01:  # Column has very small values\n",
    "        magnitude_threshold = p50 * 100  # Values 100x larger than median\n",
    "        magnitude_anomalies = data[data > magnitude_threshold]\n",
    "    else:\n",
    "        magnitude_anomalies = pd.Series(dtype=float)\n",
    "    \n",
    "    anomaly_report.append({\n",
    "        'joint': col,\n",
    "        'median': p50,\n",
    "        'p01': p01,\n",
    "        'p99': p99,\n",
    "        'bulk_mean': bulk_mean,\n",
    "        'bulk_std': bulk_std,\n",
    "        'extreme_anomalies': len(anomalies),\n",
    "        'magnitude_anomalies': len(magnitude_anomalies),\n",
    "        'total_anomalies': len(set(anomalies.index) | set(magnitude_anomalies.index)),\n",
    "        'anomaly_pct': (len(set(anomalies.index) | set(magnitude_anomalies.index)) / len(data)) * 100,\n",
    "        'min_val': data.min(),\n",
    "        'max_val': data.max()\n",
    "    })\n",
    "\n",
    "anomaly_df = pd.DataFrame(anomaly_report)\n",
    "\n",
    "# Display joints with significant anomalies\n",
    "print(\"=\"*100)\n",
    "print(\"EXTREME ANOMALY DETECTION IN JOINT COLUMNS\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\nJoints with extreme out-of-range values (sorted by anomaly percentage):\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "significant_anomalies = anomaly_df[anomaly_df['total_anomalies'] > 0].sort_values('anomaly_pct', ascending=False)\n",
    "\n",
    "for _, row in significant_anomalies.iterrows():\n",
    "    print(f\"\\n{row['joint']}:\")\n",
    "    print(f\"  Median: {row['median']:.6e}  |  Range: [{row['min_val']:.6e}, {row['max_val']:.6e}]\")\n",
    "    print(f\"  Bulk mean±std: {row['bulk_mean']:.6e} ± {row['bulk_std']:.6e}\")\n",
    "    print(f\"  Extreme anomalies: {row['extreme_anomalies']:,} ({row['anomaly_pct']:.2f}%)\")\n",
    "    print(f\"  Magnitude anomalies: {row['magnitude_anomalies']:,}\")\n",
    "    \n",
    "    # Show example anomalous values\n",
    "    col = row['joint']\n",
    "    data = df_train[col]\n",
    "    bulk_mean = row['bulk_mean']\n",
    "    bulk_std = row['bulk_std']\n",
    "    extreme_vals = data[(data < bulk_mean - 10*bulk_std) | (data > bulk_mean + 10*bulk_std)]\n",
    "    \n",
    "    if len(extreme_vals) > 0:\n",
    "        print(f\"  Example anomalous values: {extreme_vals.head(5).values}\")\n",
    "\n",
    "# Visualize the most anomalous columns\n",
    "top_anomalous = significant_anomalies.head(6)['joint'].tolist()\n",
    "\n",
    "if len(top_anomalous) > 0:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(top_anomalous):\n",
    "        if i >= 6:\n",
    "            break\n",
    "        ax = axes[i]\n",
    "        \n",
    "        data = df_train[col]\n",
    "        row = anomaly_df[anomaly_df['joint'] == col].iloc[0]\n",
    "        \n",
    "        # Create histogram with log scale if needed\n",
    "        ax.hist(data, bins=100, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "        ax.axvline(row['median'], color='red', linestyle='--', linewidth=2, label=f'Median: {row[\"median\"]:.2e}')\n",
    "        ax.axvline(row['bulk_mean'], color='green', linestyle='--', linewidth=2, label=f'Mean: {row[\"bulk_mean\"]:.2e}')\n",
    "        \n",
    "        ax.set_title(f'{col}\\nAnomalies: {row[\"total_anomalies\"]:,} ({row[\"anomaly_pct\"]:.2f}%)', \n",
    "                     fontweight='bold', fontsize=11)\n",
    "        ax.set_xlabel('Value', fontsize=9)\n",
    "        ax.set_ylabel('Frequency', fontsize=9)\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(alpha=0.3)\n",
    "        \n",
    "        # Use log scale for y-axis if there's high variance\n",
    "        if data.max() / data.median() > 100:\n",
    "            ax.set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Distribution of Joints with Extreme Anomalies', fontsize=14, fontweight='bold', y=1.00)\n",
    "    plt.subplots_adjust(top=0.96)\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Joints with no anomalies: {len(anomaly_df[anomaly_df['total_anomalies'] == 0])}\")\n",
    "print(f\"Joints with anomalies: {len(anomaly_df[anomaly_df['total_anomalies'] > 0])}\")\n",
    "print(f\"Most anomalous joint: {anomaly_df.loc[anomaly_df['anomaly_pct'].idxmax(), 'joint']} \"\n",
    "      f\"({anomaly_df['anomaly_pct'].max():.2f}% anomalies)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4131f7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 6, figsize=(24, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(joint_cols):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot KDE for train and test\n",
    "    sns.kdeplot(df_train[col], label='Train', fill=True, alpha=0.5, ax=ax, color='blue')\n",
    "    sns.kdeplot(df_test[col], label='Test', fill=True, alpha=0.5, ax=ax, color='orange')\n",
    "    \n",
    "    ax.set_title(f'{col}', fontsize=10, fontweight='bold')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Density', fontsize=8)\n",
    "    \n",
    "    # Add legend only to the first subplot\n",
    "    if i == 0:\n",
    "        ax.legend(loc='upper right', fontsize=8)\n",
    "    \n",
    "    # Determine x-axis limits based on data range\n",
    "    combined_data = pd.concat([df_train[col], df_test[col]])\n",
    "    \n",
    "    # Use percentiles to handle outliers\n",
    "    p1 = combined_data.quantile(0.01)\n",
    "    p99 = combined_data.quantile(0.99)\n",
    "    \n",
    "    data_min = combined_data.min()\n",
    "    data_max = combined_data.max()\n",
    "    \n",
    "    # Calculate range\n",
    "    data_range = p99 - p1\n",
    "    \n",
    "    if data_range > 0:\n",
    "        # Add 10% padding to the percentile range\n",
    "        padding = data_range * 0.1\n",
    "        lower_lim = max(p1 - padding, data_min)\n",
    "        upper_lim = min(p99 + padding, data_max)\n",
    "    else:\n",
    "        # If all values are the same, create a small range around the value\n",
    "        if data_min == 0:\n",
    "            lower_lim = -1e-8\n",
    "            upper_lim = 1e-8\n",
    "        else:\n",
    "            abs_val = abs(data_min)\n",
    "            lower_lim = data_min - abs_val * 0.1\n",
    "            upper_lim = data_min + abs_val * 0.1\n",
    "    \n",
    "    # Ensure lower limit doesn't go negative if all data is non-negative\n",
    "    if data_min >= 0 and lower_lim < 0:\n",
    "        lower_lim = 0\n",
    "    \n",
    "    ax.set_xlim(lower_lim, upper_lim)\n",
    "    ax.tick_params(axis='both', labelsize=8)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Distribution of Joint Columns: Train vs Test', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.subplots_adjust(top=0.98)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8dd0a0",
   "metadata": {},
   "source": [
    "## **Time Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28ef079",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating time-based features from 'time' column\")\n",
    "\n",
    "# Feature 1: Normalized time (position in sequence: 0.0 to 1.0)\n",
    "print(\"\\n1. Normalized Time (relative position in sequence)\")\n",
    "df_train['time_normalized'] = df_train.groupby('sample_index')['time'].transform(\n",
    "    lambda x: x / x.max() if x.max() > 0 else 0\n",
    ")\n",
    "df_test['time_normalized'] = df_test.groupby('sample_index')['time'].transform(\n",
    "    lambda x: x / x.max() if x.max() > 0 else 0\n",
    ")\n",
    "\n",
    "# Analyze sequence lengths to determine cyclical period\n",
    "train_lengths = df_train.groupby('sample_index')['time'].max()\n",
    "test_lengths = df_test.groupby('sample_index')['time'].max()\n",
    "avg_length = train_lengths.mean()\n",
    "\n",
    "print(f\"   - Average sequence length: {avg_length:.1f} timesteps\")\n",
    "print(f\"   - Train range: {train_lengths.min():.0f} to {train_lengths.max():.0f}\")\n",
    "print(f\"   - Test range: {test_lengths.min():.0f} to {test_lengths.max():.0f}\")\n",
    "\n",
    "# Feature 2: Cyclical encoding (captures periodic patterns)\n",
    "# Use a period based on average sequence length for meaningful cycles\n",
    "period = max(50, avg_length / 3)  # Create ~3 cycles per sequence\n",
    "print(f\"\\n2. Cyclical Encoding (period={period:.1f} timesteps)\")\n",
    "print(f\"   - Captures repeating patterns within sequences\")\n",
    "\n",
    "df_train['time_sin'] = np.sin(2 * np.pi * df_train['time'] / period)\n",
    "df_train['time_cos'] = np.cos(2 * np.pi * df_train['time'] / period)\n",
    "df_test['time_sin'] = np.sin(2 * np.pi * df_test['time'] / period)\n",
    "df_test['time_cos'] = np.cos(2 * np.pi * df_test['time'] / period)\n",
    "\n",
    "# Feature 3: Time position categories (early/mid/late)\n",
    "print(\"\\n3. Time Position Category (early/mid/late in sequence)\")\n",
    "\n",
    "def categorize_time_position(group):\n",
    "    normalized = group / group.max() if group.max() > 0 else 0\n",
    "    return pd.cut(normalized, bins=[0, 0.33, 0.66, 1.0], \n",
    "                    labels=[0, 1, 2], include_lowest=True).astype(int)\n",
    "\n",
    "df_train['time_position'] = df_train.groupby('sample_index')['time'].transform(categorize_time_position)\n",
    "df_test['time_position'] = df_test.groupby('sample_index')['time'].transform(categorize_time_position)\n",
    "\n",
    "print(\"   - 0: Early (0-33% of sequence)\")\n",
    "print(\"   - 1: Mid (33-66% of sequence)\")\n",
    "print(\"   - 2: Late (66-100% of sequence)\")\n",
    "\n",
    "# Show distribution of time position categories\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Distribution of time position categories:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nTraining set:\")\n",
    "train_dist = df_train['time_position'].value_counts().sort_index()\n",
    "for value, count in train_dist.items():\n",
    "    label = ['Early', 'Mid', 'Late'][value]\n",
    "    pct = (count / len(df_train)) * 100\n",
    "    print(f\"  {value} ({label:5s}): {count:6,} samples ({pct:.2f}%)\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "test_dist = df_test['time_position'].value_counts().sort_index()\n",
    "for value, count in test_dist.items():\n",
    "    label = ['Early', 'Mid', 'Late'][value]\n",
    "    pct = (count / len(df_test)) * 100\n",
    "    print(f\"  {value} ({label:5s}): {count:6,} samples ({pct:.2f}%)\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Summary: Created 4 new time features\")\n",
    "print(\" time_normalized: Continuous [0.0, 1.0] - position in sequence\")\n",
    "print(\" time_sin: Continuous [-1.0, 1.0] - cyclical encoding\")\n",
    "print(\" time_cos: Continuous [-1.0, 1.0] - cyclical encoding\")\n",
    "print(\" time_position: Categorical [0, 1, 2] - early/mid/late (for embeddings)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f6b584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize time features for a single pirate\n",
    "pirate_id = 0\n",
    "pirate_data = df_train[df_train['sample_index'] == pirate_id]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Normalized time progression\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(pirate_data['time'], pirate_data['time_normalized'], 'b-', linewidth=2)\n",
    "ax1.set_xlabel('Time (timestep)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Normalized Time', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Time Normalization: Linear Progression', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Plot 2: Cyclical encoding (sin/cos)\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(pirate_data['time'], pirate_data['time_sin'], 'r-', linewidth=2, label='sin(time)', alpha=0.7)\n",
    "ax2.plot(pirate_data['time'], pirate_data['time_cos'], 'b-', linewidth=2, label='cos(time)', alpha=0.7)\n",
    "ax2.set_xlabel('Time (timestep)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Cyclical Value', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Cyclical Encoding: Captures Periodic Patterns', fontsize=13, fontweight='bold')\n",
    "ax2.legend(loc='upper right', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(-1.2, 1.2)\n",
    "\n",
    "# Plot 3: Time position categories\n",
    "ax3 = axes[1, 0]\n",
    "time_pos_counts = pirate_data['time_position'].value_counts().sort_index()\n",
    "colors = ['#2ecc71', '#f39c12', '#e74c3c']  # Green, Orange, Red\n",
    "ax3.bar(time_pos_counts.index, time_pos_counts.values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax3.set_xlabel('Time Position Category', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Time Position: Early/Mid/Late Distribution', fontsize=13, fontweight='bold')\n",
    "ax3.set_xticks([0, 1, 2])\n",
    "ax3.set_xticklabels(['Early\\n(0-33%)', 'Mid\\n(33-66%)', 'Late\\n(66-100%)'], fontsize=10)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Cyclical encoding in 2D space (phase diagram)\n",
    "ax4 = axes[1, 1]\n",
    "scatter = ax4.scatter(pirate_data['time_cos'], pirate_data['time_sin'], \n",
    "                     c=pirate_data['time'], cmap='viridis', s=50, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax4.set_xlabel('cos(time)', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('sin(time)', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Cyclical Encoding: 2D Phase Space', fontsize=13, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.set_xlim(-1.2, 1.2)\n",
    "ax4.set_ylim(-1.2, 1.2)\n",
    "ax4.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "ax4.axvline(x=0, color='k', linestyle='--', alpha=0.3)\n",
    "cbar = plt.colorbar(scatter, ax=ax4)\n",
    "cbar.set_label('Timestep', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'Time Feature Visualization (Pirate {pirate_id})', fontsize=15, fontweight='bold', y=1.00)\n",
    "plt.subplots_adjust(top=0.96)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Time feature summary for pirate {pirate_id}:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total timesteps: {len(pirate_data)}\")\n",
    "print(f\"Time range: {pirate_data['time'].min():.0f} to {pirate_data['time'].max():.0f}\")\n",
    "print(f\"Normalized range: {pirate_data['time_normalized'].min():.3f} to {pirate_data['time_normalized'].max():.3f}\")\n",
    "print(f\"Time position distribution: {time_pos_counts.to_dict()}\")\n",
    "\n",
    "df_train.drop(columns=['time'], inplace=True)\n",
    "df_test.drop(columns=['time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d27ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlation between time features and pain labels\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Merge with labels\n",
    "df = pd.merge(df_train, train_labels, on='sample_index', how='left')\n",
    "\n",
    "# Map labels to integers\n",
    "pain_label_mapping = {'no_pain': 0, 'low_pain': 1, 'high_pain': 2}\n",
    "df['pain_level'] = df['label'].map(pain_label_mapping)\n",
    "# Perform ANOVA for each time feature\n",
    "time_feature_cols = ['time_normalized', 'time_sin', 'time_cos', 'time_position']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANOVA: Time Features vs Pain Labels\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTesting if time features differ across pain levels (no_pain, low_pain, high_pain)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for col in time_feature_cols:\n",
    "    group0 = df[df['pain_level'] == 0][col]\n",
    "    group1 = df[df['pain_level'] == 1][col]\n",
    "    group2 = df[df['pain_level'] == 2][col]\n",
    "    \n",
    "    if len(group0) > 1 and len(group1) > 1 and len(group2) > 1:\n",
    "        f_statistic, p_value = f_oneway(group0, group1, group2)\n",
    "        \n",
    "        # Interpret significance\n",
    "        if p_value < 0.001:\n",
    "            significance = \"*** Highly significant\"\n",
    "        elif p_value < 0.01:\n",
    "            significance = \"** Very significant\"\n",
    "        elif p_value < 0.05:\n",
    "            significance = \"* Significant\"\n",
    "        else:\n",
    "            significance = \"Not significant\"\n",
    "        \n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  F-statistic: {f_statistic:.4f}\")\n",
    "        print(f\"  P-value: {p_value:.4f}  {significance}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Interpretation:\")\n",
    "print(\"=\"*70)\n",
    "print(\"p < 0.001: Strong evidence that time feature relates to pain level\")\n",
    "print(\"p < 0.05:  Evidence of relationship (statistically significant)\")\n",
    "print(\"p ≥ 0.05:  No clear relationship detected\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2488ca67",
   "metadata": {},
   "source": [
    "# **Data Preprocessing and Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1313f76",
   "metadata": {},
   "source": [
    "## **Drop Redundant Joint Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b906efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['joint_30', 'joint_11'], inplace=True)\n",
    "df_test.drop(columns=['joint_30', 'joint_11'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26cfa1c",
   "metadata": {},
   "source": [
    "## Unify n_legs, n_arms and n_eyes into single feature 'has_prosthetics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072ff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the new feature\n",
    "df['has_prosthetics'] = (df['n_legs'] != 'two').astype(int)\n",
    "df_test['has_prosthetics'] = (df_test['n_legs'] != 'two').astype(int)\n",
    "\n",
    "# Show distribution\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Distribution of new feature:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nTraining set:\")\n",
    "train_dist = df['has_prosthetics'].value_counts().sort_index()\n",
    "for value, count in train_dist.items():\n",
    "    label = \"Natural\" if value == 0 else \"Prosthetics\"\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"  {value} ({label:12s}): {count:6,} samples ({pct:.2f}%)\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "test_dist = df_test['has_prosthetics'].value_counts().sort_index()\n",
    "for value, count in test_dist.items():\n",
    "    label = \"Natural\" if value == 0 else \"Prosthetics\"\n",
    "    pct = (count / len(df_test)) * 100\n",
    "    print(f\"  {value} ({label:12s}): {count:6,} samples ({pct:.2f}%)\")\n",
    "\n",
    "\n",
    "# Columns to drop\n",
    "cols_to_drop = ['n_legs', 'n_hands', 'n_eyes', \n",
    "                'n_legs_encoded', 'n_hands_encoded', 'n_eyes_encoded']\n",
    "\n",
    "# Drop from both train and test\n",
    "df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "df_test = df_test.drop(columns=[col for col in cols_to_drop if col in df_test.columns])\n",
    "\n",
    "print(\"\\nFeature created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6caae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(\"\\nApplying Min-Max normalization to joint columns...\")\n",
    "print(\"=\" * 60)\n",
    "# List of joint columns to normalize\n",
    "joint_cols = [\"joint_\" + str(i).zfill(2) for i in range(30)]\n",
    "joint_cols.remove(\"joint_11\")  # Removed earlier\n",
    "\n",
    "for col in joint_cols:\n",
    "    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Min-Max normalization to the joint columns\n",
    "df[joint_cols] = minmax_scaler.fit_transform(df[joint_cols])\n",
    "\n",
    "# Use the same scaler on test data\n",
    "df_test[joint_cols] = minmax_scaler.transform(df_test[joint_cols])\n",
    "\n",
    "print(f\"Scaler learned from training data - Min: {minmax_scaler.data_min_[:5]}\")\n",
    "print(f\"Scaler learned from training data - Max: {minmax_scaler.data_max_[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d719457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Weights\n",
    "WEIGHTS = []\n",
    "for label in np.unique(target['label']):\n",
    "    print(f\"Label: {label}, Count: {len(target[target['label'] == label])}\")\n",
    "    WEIGHTS.append(len(target) / len(target[target['label'] == label]))\n",
    "WEIGHTS = torch.Tensor(WEIGHTS).to(device)\n",
    "\n",
    "# Define a mapping of pain indexes to integer labels\n",
    "label_mapping = {\n",
    "    'no_pain': 0,\n",
    "    'low_pain': 1,\n",
    "    'high_pain': 2\n",
    "}\n",
    "\n",
    "# Map pain indexes to integers\n",
    "target['label'] = target['label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "print(\"\\nPerforming train/validation split based on unique users...\")\n",
    "print(\"=\" * 60)\n",
    "# Get unique user IDs and shuffle them\n",
    "unique_users = df['sample_index'].unique()\n",
    "random.seed(SEED) # Ensure reproducibility of shuffling\n",
    "random.shuffle(unique_users)\n",
    "input_shape = df.shape\n",
    "\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "\n",
    "# Determine the number of users for validation\n",
    "num_val_users = int(len(unique_users) * 0.2)\n",
    "val_users = unique_users[:num_val_users]\n",
    "train_users = unique_users[num_val_users:]\n",
    "print(f\"Number of training users: {len(train_users)}\")\n",
    "print(f\"Number of validation users: {len(val_users)}\")\n",
    "# Split the DataFrame and target based on user IDs\n",
    "train_df = df[df['sample_index'].isin(train_users)].reset_index(drop=True)\n",
    "val_df = df[df['sample_index'].isin(val_users)].reset_index(drop=True)\n",
    "train_target = target[target['sample_index'].isin(train_users)].reset_index(drop=True)  \n",
    "val_target = target[target['sample_index'].isin(val_users)].reset_index(drop=True)\n",
    "print(f\"Training set shape: {train_df.shape}\")\n",
    "print(f\"Validation set shape: {val_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab8563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label mapping (robust to string or numeric labels)\n",
    "LABEL_MAP = {\"no_pain\": 0, \"low_pain\": 1, \"high_pain\": 2}\n",
    "\n",
    "def _detect_joint_cols(df):\n",
    "    return sorted([c for c in df.columns if c.startswith(\"joint_\")])\n",
    "\n",
    "def _get_data_cols(df):\n",
    "    cols = _detect_joint_cols(df)\n",
    "    if not cols:\n",
    "        raise ValueError(\"No 'joint_*' columns found in df.\")\n",
    "    return cols\n",
    "\n",
    "# Load labels if not already present\n",
    "if \"target\" not in globals():\n",
    "    try:\n",
    "        target = pd.read_csv(\"pirate_pain_train_labels.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: 'target' not defined and 'pirate_pain_train_labels.csv' not found.\")\n",
    "    else:\n",
    "        if \"label\" in target.columns:\n",
    "            # Map strings to ints if needed\n",
    "            if target[\"label\"].dtype == object:\n",
    "                target[\"label\"] = target[\"label\"].map(lambda x: LABEL_MAP.get(x, x))\n",
    "\n",
    "# --- Window builder ---\n",
    "def build_windows(\n",
    "    df: pd.DataFrame,\n",
    "    target: pd.DataFrame | None,\n",
    "    window: int = 300,\n",
    "    stride: int = 75,\n",
    "    padding: str = \"zero\",      # 'zero' or 'drop_last'\n",
    "    feature: str = \"3d\",        # '3d' (for RNNs) or 'flatten' (for traditional ML)\n",
    "    data_cols: list | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds sliding windows from df and returns (X, y, groups).\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with time series data\n",
    "        target: DataFrame with labels\n",
    "        window: Window size (number of timesteps)\n",
    "        stride: Stride for sliding window\n",
    "        padding: 'zero' to pad with zeros, 'drop_last' to drop incomplete windows\n",
    "        feature: '3d' returns (samples, timesteps, features) for RNNs,\n",
    "                 'flatten' returns (samples, timesteps*features) for traditional ML\n",
    "        data_cols: List of columns to use as features\n",
    "    \n",
    "    Returns:\n",
    "        X: numpy array of shape (n_samples, window, n_features) if feature='3d'\n",
    "           or (n_samples, window*n_features) if feature='flatten'\n",
    "        y: numpy array of labels\n",
    "        groups: numpy array of sample indices\n",
    "    \"\"\"\n",
    "    if data_cols is None:\n",
    "        data_cols = _get_data_cols(df)\n",
    "    X, y = [], []\n",
    "    for sid in df[\"sample_index\"].unique():\n",
    "        temp = df[df[\"sample_index\"] == sid][data_cols].values\n",
    "        # get label for this id\n",
    "        if target is not None:\n",
    "            lab_arr = target[target[\"sample_index\"] == sid][\"label\"].values\n",
    "            if len(lab_arr) == 0:\n",
    "                # if missing label, skip this id\n",
    "                continue\n",
    "            lab = lab_arr[0]\n",
    "            if isinstance(lab, str):\n",
    "                lab = LABEL_MAP.get(lab, lab)\n",
    "        # padding computation\n",
    "        pad = (window - (len(temp) % window)) % window\n",
    "        if padding == \"zero\" and pad:\n",
    "            temp = np.concatenate([temp, np.zeros((pad, temp.shape[1]), dtype=temp.dtype)], axis=0)\n",
    "        L = len(temp)\n",
    "        start = 0\n",
    "        while start + window <= L:\n",
    "            seg = temp[start:start + window]  # shape: (window, n_features)\n",
    "            if feature == \"flatten\":\n",
    "                feat = seg.reshape(-1)  # shape: (window * n_features,)\n",
    "            else:\n",
    "                feat = seg  # Keep 3D: (window, n_features)\n",
    "            X.append(feat)\n",
    "            if target is not None:\n",
    "                y.append(lab)\n",
    "            start += stride\n",
    "    if not X:\n",
    "        raise ValueError(\"No windows were created. Check your data and parameters.\")\n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e814f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "WINDOW_SIZE = 300\n",
    "STRIDE = 150\n",
    "\n",
    "# Build sequences - returns 3D arrays (samples, timesteps, features)\n",
    "X_train, y_train = build_windows(train_df, train_target, WINDOW_SIZE, STRIDE, feature=\"3d\")\n",
    "X_val, y_val = build_windows(val_df, val_target, WINDOW_SIZE, STRIDE, feature=\"3d\")\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set shape: {X_val.shape}, {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab20f4f",
   "metadata": {},
   "source": [
    "## Apply Weighted Sampling to Address Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a43b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "class_counts = np.bincount(y_train)\n",
    "print(\"\\n📊 Class distribution in training set:\")\n",
    "for cls, count in enumerate(class_counts):\n",
    "    print(f\"  Class {cls}: {count} samples ({count/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "# Calculate inverse-frequency weights per class\n",
    "class_weights = 1.0 / class_counts\n",
    "class_weights = class_weights / np.sum(class_weights)  # Normalize weights\n",
    "print(\"\\n⚖️  Sample weights (inverse frequency):\")\n",
    "for cls, weight in enumerate(class_weights):\n",
    "    print(f\"  Class {cls}: {weight:.4f}\")\n",
    "\n",
    "# Assign a weight to each sample based on its class (only for valid labels)\n",
    "sample_weights = np.zeros(len(y_train))\n",
    "sample_weights = class_weights[y_train]\n",
    "sample_weights = torch.from_numpy(sample_weights).double()\n",
    "\n",
    "# Create WeightedRandomSampler (oversamples minority classes)\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee699b",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1739946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def make_loader(ds, batch_size, shuffle, drop_last, sampler=None):\n",
    "    # Determine optimal number of worker processes for data loading\n",
    "    cpu_cores = os.cpu_count() or 2\n",
    "    num_workers = max(2, min(4, cpu_cores))\n",
    "\n",
    "    # Create DataLoader with performance optimizations\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle if sampler is None else False,  # shuffle and sampler are mutually exclusive\n",
    "        sampler=sampler,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,  # Faster GPU transfer\n",
    "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
    "        prefetch_factor=4,  # Load 4 batches ahead\n",
    "    )\n",
    "\n",
    "# Convert to PyTorch datasets\n",
    "train_ds = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "val_ds = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = make_loader(train_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=True, sampler=sampler)\n",
    "val_loader = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "# Store metadata for model creation\n",
    "input_shape = X_train.shape\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"\\n✅ DataLoaders created\")\n",
    "print(f\"   Training batches: {len(train_loader)}\")\n",
    "print(f\"   Validation batches: {len(val_loader)}\")\n",
    "print(f\"   Input shape: {input_shape}\")\n",
    "print(f\"   Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974fdb2c",
   "metadata": {},
   "source": [
    "# **Model Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708021fb",
   "metadata": {},
   "source": [
    "## **Inner Logic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f1a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n",
    "    \"\"\"\n",
    "    Perform one complete training epoch through the entire training dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to train\n",
    "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
    "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
    "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "        l1_lambda (float): Lambda for L1 regularization\n",
    "        l2_lambda (float): Lambda for L2 regularization\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Iterate through training batches\n",
    "    for _, (inputs, targets) in enumerate(train_loader):\n",
    "        # Move data to device (GPU/CPU)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Clear gradients from previous step\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Forward pass with mixed precision (if CUDA available)\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "          logits = model(inputs)\n",
    "          loss = criterion(logits, targets)\n",
    "\n",
    "          # --- REGULARIZATION ---\n",
    "          if l1_lambda > 0 or l2_lambda > 0:\n",
    "              for name, param in model.named_parameters():\n",
    "                  # Only regularize weight matrices\n",
    "                  if 'weight' in name:\n",
    "                      if l1_lambda > 0:\n",
    "                          loss += l1_lambda * torch.sum(torch.abs(param))\n",
    "                      if l2_lambda > 0:\n",
    "                          loss += l2_lambda * torch.sum(torch.pow(param, 2))\n",
    "\n",
    "\n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        all_predictions.append(predictions.cpu().numpy())\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_f1 = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='weighted',\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_f1\n",
    "\n",
    "\n",
    "def validate_one_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Perform one complete validation epoch through the entire validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n",
    "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
    "        criterion (nn.Module): Loss function used to calculate validation loss\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n",
    "\n",
    "    Note:\n",
    "        This function automatically sets the model to evaluation mode and disables\n",
    "        gradient computation for efficiency during validation.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Disable gradient computation for validation\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            # Move data to device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass with mixed precision (if CUDA available)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model(inputs)\n",
    "                loss = criterion(logits, targets)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_accuracy = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='weighted',\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "\n",
    "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n",
    "        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
    "        restore_best_weights=True, verbose=10, experiment_name=\"\"):\n",
    "    \"\"\"\n",
    "    Train the neural network model on the training data and validate on the validation data.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to train\n",
    "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
    "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
    "        epochs (int): Number of training epochs\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
    "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
    "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "        l1_lambda (float): L1 regularization coefficient (default: 0)\n",
    "        l2_lambda (float): L2 regularization coefficient (default: 0)\n",
    "        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n",
    "        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n",
    "        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n",
    "        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n",
    "        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n",
    "        verbose (int, optional): Frequency of printing training progress (default: 10)\n",
    "        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, training_history) - Trained model and metrics history\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize metrics tracking\n",
    "    training_history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_f1': [], 'val_f1': []\n",
    "    }\n",
    "\n",
    "    # Configure early stopping if patience is set\n",
    "    if patience > 0:\n",
    "        patience_counter = 0\n",
    "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
    "        best_epoch = 0\n",
    "\n",
    "    print(f\"Training {epochs} epochs...\")\n",
    "\n",
    "    # Main training loop: iterate through epochs\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        # Forward pass through training data, compute gradients, update weights\n",
    "        train_loss, train_f1 = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n",
    "        )\n",
    "\n",
    "        # Evaluate model on validation data without updating weights\n",
    "        val_loss, val_f1 = validate_one_epoch(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        # Store metrics for plotting and analysis\n",
    "        training_history['train_loss'].append(train_loss)\n",
    "        training_history['val_loss'].append(val_loss)\n",
    "        training_history['train_f1'].append(train_f1)\n",
    "        training_history['val_f1'].append(val_f1)\n",
    "\n",
    "        # Print progress every N epochs or on first epoch\n",
    "        if verbose > 0:\n",
    "            if epoch % verbose == 0 or epoch == 1:\n",
    "                print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
    "                    f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n",
    "                    f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n",
    "\n",
    "        # Early stopping logic: monitor metric and save best model\n",
    "        if patience > 0:\n",
    "            current_metric = training_history[evaluation_metric][-1]\n",
    "            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
    "\n",
    "            if is_improvement:\n",
    "                best_metric = current_metric\n",
    "                best_epoch = epoch\n",
    "                torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping triggered after {epoch} epochs.\")\n",
    "                    break\n",
    "\n",
    "    # Restore best model weights if early stopping was used\n",
    "    if restore_best_weights and patience > 0:\n",
    "        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n",
    "        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n",
    "\n",
    "    # Save final model if no early stopping\n",
    "    if patience == 0:\n",
    "        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
    "\n",
    "    return model, training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa938b",
   "metadata": {},
   "source": [
    "## **Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d9136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL SETUP\n",
    "# ============================================================================\n",
    "import torch.nn as nn\n",
    "from model_definitions.cnn import CNN1DClassifier\n",
    "\n",
    "model = CNN1DClassifier(\n",
    "    input_size=input_shape[-1],\n",
    "    num_classes=num_classes,\n",
    "    num_filters=[64, 128, 256],\n",
    "    kernel_sizes=[5, 5, 3],\n",
    "    dropout_rate=0.4\n",
    ").to(device)\n",
    "\n",
    "\n",
    "print(f\"\\n🔧 Model: {model.__class__.__name__}\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa00afd7",
   "metadata": {},
   "source": [
    "## Loss Function, Optimizer, Gradient Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0dcf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate class weights: inverse frequency with normalization\n",
    "train_class_counts = np.bincount(y_train.astype(int))\n",
    "class_weights_loss = len(y_train) / (len(train_class_counts) * train_class_counts)\n",
    "class_weights_loss = torch.tensor(class_weights_loss, dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"\\n⚖️  Loss weights (amplifies gradients for minority classes):\")\n",
    "for cls, weight in enumerate(class_weights_loss):\n",
    "    print(f\"  Class {cls}: {weight:.4f}x\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_loss, label_smoothing=0.1)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=5e-4,           # Learning rate\n",
    "    weight_decay=1e-4  # L2 regularization\n",
    ")\n",
    "\n",
    "scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f782e907",
   "metadata": {},
   "source": [
    "# **Fit Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2c1a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINING\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Training {model.__class__.__name__}...\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "_, history = fit(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=10,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scaler=scaler,\n",
    "    device=device,\n",
    "    writer=None,\n",
    "    verbose=3,\n",
    "    experiment_name=\"model_training\",\n",
    "    patience=0,       # Set > 0 for early stopping\n",
    "    l1_lambda=0,      # L1 regularization\n",
    "    l2_lambda=0       # L2 regularization (or use weight_decay in optimizer)\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# RESULTS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"📊 TRAINING RESULTS:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Initial val F1: {history['val_f1'][0]:.4f}\")\n",
    "print(f\"  Final val F1:   {history['val_f1'][-1]:.4f}\")\n",
    "print(f\"  Best val F1:    {max(history['val_f1']):.4f}\")\n",
    "print(f\"  Improvement:    {max(history['val_f1']) - history['val_f1'][0]:+.4f}\")\n",
    "\n",
    "# Per-class predictions\n",
    "from sklearn.metrics import classification_report\n",
    "model.eval()\n",
    "val_preds = []\n",
    "val_true = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        val_preds.extend(preds.cpu().numpy())\n",
    "        val_true.extend(targets.cpu().numpy())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"📈 CLASSIFICATION REPORT:\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(\n",
    "    val_true, val_preds,\n",
    "    target_names=['no_pain', 'low_pain', 'high_pain'],\n",
    "    digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed37f45d",
   "metadata": {},
   "source": [
    "## **Plot Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a77c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get predictions for the validation set\n",
    "model.eval()\n",
    "val_predictions = []\n",
    "val_targets = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        val_predictions.extend(predicted.cpu().numpy())\n",
    "        val_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(val_targets, val_predictions)\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['no_pain', 'low_pain', 'high_pain']\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix (Validation Set)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ca596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Plot History\n",
    "\n",
    "# Create a figure with two side-by-side subplots (two columns)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n",
    "\n",
    "# Plot of training and validation loss on the first axis\n",
    "ax1.plot(history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
    "ax1.plot(history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot of training and validation accuracy on the second axis\n",
    "ax2.plot(history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
    "ax2.plot(history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n",
    "ax2.set_title('F1 Score')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# Adjust the layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52380347",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a3709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset and loader\n",
    "test_df = build_windows(df_test, None, WINDOW_SIZE, STRIDE, feature=\"3d\")[0]\n",
    "X_test = test_df.astype(np.float32)\n",
    "test_loader = make_loader(\n",
    "    TensorDataset(torch.from_numpy(X_test).float()), \n",
    "    batch_size=32, \n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# Generate predictions for all windows\n",
    "all_window_preds = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb in test_loader:\n",
    "        xb = xb[0].to(device)\n",
    "        outputs = model(xb)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        all_window_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "print(f\"\\n📊 Generated {len(all_window_preds)} window predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab86a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# AGGREGATE PREDICTIONS PER PIRATE (sample_index)\n",
    "# ============================================================================\n",
    "# Calculate how many windows per sample_index\n",
    "num_test_samples = len(df_test['sample_index'].unique())\n",
    "windows_per_sample = len(all_window_preds) // num_test_samples\n",
    "\n",
    "print(f\"   Test samples: {num_test_samples}\")\n",
    "print(f\"   Windows per sample: {windows_per_sample}\")\n",
    "\n",
    "# Aggregate predictions using sum of logits (confidence-weighted voting)\n",
    "label_mapping = {0: 'no_pain', 1: 'low_pain', 2: 'high_pain'}\n",
    "final_predictions = []\n",
    "\n",
    "# Get probability scores for all windows\n",
    "all_window_probs = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb in test_loader:\n",
    "        xb = xb[0].to(device)\n",
    "        outputs = model(xb)\n",
    "        probs = torch.softmax(outputs, dim=1)  # Convert logits to probabilities\n",
    "        all_window_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_window_probs = np.array(all_window_probs)\n",
    "\n",
    "# Aggregate using sum of probabilities\n",
    "for sample_idx in range(num_test_samples):\n",
    "    # Get all window predictions for this sample_index\n",
    "    start_idx = sample_idx * windows_per_sample\n",
    "    end_idx = start_idx + windows_per_sample\n",
    "    window_probs = all_window_probs[start_idx:end_idx]\n",
    "    \n",
    "    # Sum probabilities across all windows for each class\n",
    "    class_scores = window_probs.sum(axis=0)  # Shape: (3,) for 3 classes\n",
    "    \n",
    "    # Winner: class with highest total confidence\n",
    "    predicted_class = class_scores.argmax()\n",
    "    final_predictions.append(label_mapping[predicted_class])\n",
    "\n",
    "print(f\"\\nAggregated to {len(final_predictions)} final predictions (one per pirate)\")\n",
    "\n",
    "# Create submission CSV\n",
    "from datetime import datetime\n",
    "predictions_df = pd.DataFrame({\n",
    "    'sample_index': np.arange(num_test_samples),\n",
    "    'label': final_predictions\n",
    "})\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "filename = f'predictions_{timestamp}.csv'\n",
    "predictions_df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\nPredictions saved to: {filename}\")\n",
    "print(f\"Total predictions: {len(final_predictions)} (one per pirate)\")\n",
    "print(f\"\\nDistribution:\")\n",
    "for label in ['no_pain', 'low_pain', 'high_pain']:\n",
    "    count = final_predictions.count(label)\n",
    "    pct = (count / len(final_predictions)) * 100\n",
    "    print(f\"   {label:10s}: {count:5d} ({pct:5.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
