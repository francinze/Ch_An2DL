{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3e4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KAGGLE IMPORTS\n",
    "# Clone repo\n",
    "!git clone https://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@github.com/francinze/Ch_An2DL.git /kaggle/working/ch2\n",
    "\n",
    "# Install kaggle API\n",
    "!pip install -q kaggle\n",
    "\n",
    "# Configure kaggle.json\n",
    "!mkdir -p /root/.config/kaggle\n",
    "\n",
    "# Copy your kaggle.json there\n",
    "!cp /kaggle/working/ch2/kaggle.json /root/.config/kaggle/\n",
    "\n",
    "# Set correct permissions\n",
    "!chmod 600 /root/.config/kaggle/kaggle.json\n",
    "\n",
    "# Download competition files\n",
    "!kaggle competitions download -c an2dl2526c2 -p /kaggle/working/ch2\n",
    "\n",
    "# Unzip dataset\n",
    "!unzip -o /kaggle/working/ch2/an2dl2526c2.zip -d /kaggle/working/ch2/\n",
    "\n",
    "# Move into the working directory\n",
    "%cd /kaggle/working/ch2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b1cef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# COLAB IMPORTS\n",
    "!git clone https://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@github.com/francinze/Ch_An2DL.git\n",
    "! pip install -q kaggle\n",
    "! mkdir ~/.kaggle\n",
    "! cp Ch_An2DL/kaggle.json ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle competitions download -c an2dl2526c2\n",
    "!unzip an2dl2526c2.zip -d Ch_An2DL/\n",
    "%cd /content/Ch_An2DL/\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8eea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341d217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Detect environment and set appropriate path prefix\n",
    "if 'data' in os.listdir():\n",
    "    # Local environment\n",
    "    PATH_PREFIX = ''\n",
    "else:\n",
    "    # Kaggle or Colab environment\n",
    "    PATH_PREFIX = '/'\n",
    "\n",
    "# Load image dataset\n",
    "train_dir = PATH_PREFIX + 'data/train_data/'\n",
    "test_dir = PATH_PREFIX + 'data/test_data/'\n",
    "train_labels = pd.read_csv(PATH_PREFIX + 'data/train_labels.csv')\n",
    "\n",
    "print(f\"Environment detected. Using path prefix: '{PATH_PREFIX}'\")\n",
    "\n",
    "# Display dataset info\n",
    "print(f\"Total training samples: {len(train_labels)}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(train_labels['label'].value_counts())\n",
    "\n",
    "# Check image properties\n",
    "sample_img = Image.open(os.path.join(train_dir, 'img_0000.png'))\n",
    "sample_mask = Image.open(os.path.join(train_dir, 'mask_0000.png'))\n",
    "print(f\"\\nImage shape: {np.array(sample_img).shape}\")\n",
    "print(f\"Mask shape: {np.array(sample_mask).shape}\")\n",
    "print(f\"Image dtype: {np.array(sample_img).dtype}\")\n",
    "print(f\"Mask unique values: {np.unique(np.array(sample_mask))}\")\n",
    "\n",
    "# Visualize a few samples\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "for i in range(3):\n",
    "    img_name = train_labels.iloc[i]['sample_index']\n",
    "    label = train_labels.iloc[i]['label']\n",
    "    \n",
    "    img = Image.open(os.path.join(train_dir, img_name))\n",
    "    mask = Image.open(os.path.join(train_dir, img_name.replace('img_', 'mask_')))\n",
    "    \n",
    "    axes[0, i].imshow(img)\n",
    "    axes[0, i].set_title(f'{img_name}\\n{label}')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(mask, cmap='gray')\n",
    "    axes[1, i].set_title(f'Mask for {img_name}')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef36cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove contaminated images from training data\n",
    "import shutil\n",
    "\n",
    "# Parse the contaminated indices from the text file\n",
    "contaminated_indices = []\n",
    "with open('shrek_and_slimes.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if line and line.isdigit():\n",
    "            contaminated_indices.append(int(line))\n",
    "\n",
    "print(f\"Found {len(contaminated_indices)} contaminated samples to remove\")\n",
    "\n",
    "# Remove corresponding image and mask files\n",
    "removed_count = 0\n",
    "for idx in contaminated_indices:\n",
    "    img_name = f'img_{idx:04d}.png'\n",
    "    mask_name = f'mask_{idx:04d}.png'\n",
    "    \n",
    "    img_path = os.path.join(train_dir, img_name)\n",
    "    mask_path = os.path.join(train_dir, mask_name)\n",
    "    \n",
    "    # Remove image if exists\n",
    "    if os.path.exists(img_path):\n",
    "        os.remove(img_path)\n",
    "        removed_count += 1\n",
    "    \n",
    "    # Remove mask if exists\n",
    "    if os.path.exists(mask_path):\n",
    "        os.remove(mask_path)\n",
    "        removed_count += 1\n",
    "\n",
    "print(f\"Removed {removed_count} files from {train_dir}\")\n",
    "\n",
    "# Update train_labels by removing contaminated indices\n",
    "train_labels = train_labels[~train_labels['sample_index'].str.extract(r'(\\d+)')[0].astype(int).isin(contaminated_indices)]\n",
    "print(f\"Training labels updated: {len(train_labels)} samples remaining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8b4216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Analizza la distribuzione delle classi DOPO la rimozione\n",
    "class_distribution = train_labels['label'].value_counts().sort_index()\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DISTRIBUZIONE CLASSI DOPO RIMOZIONE IMMAGINI CONTAMINATE\")\n",
    "print(\"=\"*60)\n",
    "print(class_distribution)\n",
    "print(f\"\\nTotale campioni: {len(train_labels)}\")\n",
    "\n",
    "# Calcola statistiche\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STATISTICHE PER AUGMENTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Classe con più campioni (maggioranza)\n",
    "max_class = class_distribution.max()\n",
    "max_class_name = class_distribution.idxmax()\n",
    "print(f\"\\nClasse con più campioni (Maggioranza): {max_class_name} ({max_class} campioni)\")\n",
    "\n",
    "# Classe con meno campioni (minoranza)\n",
    "min_class = class_distribution.min()\n",
    "min_class_name = class_distribution.idxmin()\n",
    "print(f\"Classe con meno campioni (Minoranza): {min_class_name} ({min_class} campioni)\")\n",
    "\n",
    "# Sbilancio\n",
    "imbalance_ratio = max_class / min_class\n",
    "print(f\"\\nRapporto di sbilancio (Max/Min): {imbalance_ratio:.2f}x\")\n",
    "\n",
    "# Proposta di augmentation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGIA DI AUGMENTATION CONSIGLIATA\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nAugmentazioni da applicare (come suggerito dal professore):\")\n",
    "print(\"  1. Horizontal Flip (p=0.5)\")\n",
    "print(\"  2. Vertical Flip (p=0.5)\")\n",
    "print(\"  3. Random Translation (0.2, 0.2)\")\n",
    "print(\"  4. Random Zoom/Scale (0.8, 1.2)\")\n",
    "print(\"  [ESCLUDERE: Random Rotation - cambierebbe le dimensioni]\\n\")\n",
    "\n",
    "# STRATEGIA: Tutte le classi crescono fino a raggiungere un target uguale per TUTTI\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"STRATEGIA EQUILIBRATA: TUTTE LE CLASSI CRESCONO A UN NUMERO FISSO E UGUALE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ===== MODIFICA QUI IL NUMERO DI CAMPIONI TARGET =====\n",
    "target_samples = 1000  # Numero di campioni desiderato per OGNI classe\n",
    "# =====================================================\n",
    "\n",
    "print(f\"\\nTarget: {target_samples} campioni per OGNI classe\\n\")\n",
    "\n",
    "# Calcola quanti augment applicare per classe\n",
    "print(\"Calcolo del numero di augmentation per classe:\")\n",
    "print(f\"{'Classe':<20} {'Originali':<12} {'Target':<12} {'Augment Necessari':<20}\")\n",
    "print(\"-\" * 64)\n",
    "\n",
    "augmentation_strategy_balanced = {}\n",
    "total_to_generate = 0\n",
    "\n",
    "for class_name in class_distribution.index:\n",
    "    n_samples = class_distribution[class_name]\n",
    "    n_needed = target_samples - n_samples\n",
    "    n_augmentations = max(0, n_needed)  # Non possiamo avere augment negativi\n",
    "    \n",
    "    augmentation_strategy_balanced[class_name] = {\n",
    "        'original': n_samples,\n",
    "        'target': target_samples,\n",
    "        'augment_count': n_augmentations,\n",
    "        'ratio_multiplier': n_augmentations / n_samples if n_samples > 0 else 0\n",
    "    }\n",
    "    \n",
    "    total_to_generate += n_augmentations\n",
    "    \n",
    "    print(f\"{class_name:<20} {n_samples:<12} {target_samples:<12} {n_augmentations:<20}\")\n",
    "\n",
    "print(\"-\" * 64)\n",
    "print(f\"{'TOTALE AUGMENTAZIONI DA GENERARE':<44} {total_to_generate:<20}\")\n",
    "\n",
    "# Proiezione del dataset dopo augmentation\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PROIEZIONE DATASET DOPO AUGMENTATION EQUILIBRATA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Classe':<20} {'Originali':<15} {'Nuovi Augment':<15} {'Totale':<15}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "total_original = 0\n",
    "total_augmented = 0\n",
    "for class_name in class_distribution.index:\n",
    "    n_original = class_distribution[class_name]\n",
    "    n_aug = augmentation_strategy_balanced[class_name]['augment_count']\n",
    "    n_total = n_original + n_aug\n",
    "    \n",
    "    total_original += n_original\n",
    "    total_augmented += n_total\n",
    "    \n",
    "    print(f\"{class_name:<20} {n_original:<15} {n_aug:<15} {n_total:<15}\")\n",
    "\n",
    "print(\"-\" * 65)\n",
    "print(f\"{'TOTALE':<20} {total_original:<15} {total_to_generate:<15} {total_augmented:<15}\")\n",
    "\n",
    "# Visualizza la distribuzione prima e dopo\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Prima\n",
    "class_distribution.plot(kind='bar', ax=axes[0], color='steelblue')\n",
    "axes[0].set_title('Distribuzione Classi - PRIMA Augmentation', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Numero campioni')\n",
    "axes[0].set_xlabel('Classe')\n",
    "axes[0].axhline(y=target_samples, color='red', linestyle='--', linewidth=2, label=f'Target: {target_samples}')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Dopo\n",
    "after_augmentation_balanced = {}\n",
    "for class_name in class_distribution.index:\n",
    "    after_augmentation_balanced[class_name] = augmentation_strategy_balanced[class_name]['target']\n",
    "\n",
    "after_series = pd.Series(after_augmentation_balanced)\n",
    "after_series.plot(kind='bar', ax=axes[1], color='seagreen')\n",
    "axes[1].set_title('Distribuzione Classi - DOPO Augmentation Equilibrata', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylabel('Numero campioni')\n",
    "axes[1].set_xlabel('Classe')\n",
    "axes[1].axhline(y=target_samples, color='red', linestyle='--', linewidth=2, label=f'Target: {target_samples}')\n",
    "axes[1].set_ylim([0, max_class * 1.1])\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETTAGLI PER IMPLEMENTAZIONE\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nPerciascuna classe, applica le seguenti augmentazioni:\")\n",
    "for class_name in sorted(augmentation_strategy_balanced.keys()):\n",
    "    info = augmentation_strategy_balanced[class_name]\n",
    "    print(f\"\\n{class_name}:\")\n",
    "    print(f\"  - Campioni originali: {info['original']}\")\n",
    "    print(f\"  - Campioni da generare: {info['augment_count']}\")\n",
    "    print(f\"  - Moltiplicatore di augmentation: {info['ratio_multiplier']:.2f}x\")\n",
    "    if info['augment_count'] > 0:\n",
    "        print(f\"  ✓ Per ogni immagine originale, genera {info['augment_count'] / info['original']:.1f} versioni augmentate\")\n",
    "\n",
    "print(\"\\n✓ Analisi completata! Procedi con l'augmentation usando questa strategia equilibrata.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f722ec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "\n",
    "# Crea cartella per salvare le immagini augmentate\n",
    "augmented_dir = PATH_PREFIX + 'data/train_data_augmented/'\n",
    "if not os.path.exists(augmented_dir):\n",
    "    os.makedirs(augmented_dir)\n",
    "    print(f\"Created directory: {augmented_dir}\")\n",
    "\n",
    "# Definisci le augmentazioni per ogni classe\n",
    "augmentation_transforms = {\n",
    "    'flip': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "    ]),\n",
    "    'translation': transforms.Compose([\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=None),\n",
    "    ]),\n",
    "    'zoom': transforms.Compose([\n",
    "        transforms.RandomAffine(degrees=0, translate=None, scale=(0.8, 1.2)),\n",
    "    ]),\n",
    "    'combined': transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomVerticalFlip(p=0.5),\n",
    "        transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.8, 1.2)),\n",
    "    ])\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INIZIO PROCESS DI AUGMENTATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Cicla per ogni classe e genera le augmentazioni\n",
    "total_augmented = 0\n",
    "\n",
    "for class_name in sorted(augmentation_strategy_balanced.keys()):\n",
    "    info = augmentation_strategy_balanced[class_name]\n",
    "    n_augment = info['augment_count']\n",
    "    \n",
    "    if n_augment == 0:\n",
    "        print(f\"\\n✓ {class_name}: Nessuna augmentation necessaria (già al target)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'-'*80}\")\n",
    "    print(f\"Classe: {class_name}\")\n",
    "    print(f\"Augmentazioni da generare: {n_augment}\")\n",
    "    print(f\"{'-'*80}\")\n",
    "    \n",
    "    # Ottieni le immagini originali di questa classe\n",
    "    class_samples = train_labels[train_labels['label'] == class_name]['sample_index'].tolist()\n",
    "    n_original = len(class_samples)\n",
    "    \n",
    "    # Calcola quante augmentazioni per immagine originale\n",
    "    aug_per_img = n_augment / n_original\n",
    "    \n",
    "    # Per ogni immagine originale\n",
    "    aug_count = 0\n",
    "    for img_idx, img_name in enumerate(class_samples):\n",
    "        img_path = os.path.join(train_dir, img_name)\n",
    "        \n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"  ⚠ Immagine non trovata: {img_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Carica l'immagine originale\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img_pil = img.copy()\n",
    "        \n",
    "        # Genera augmentazioni per questa immagine\n",
    "        n_to_generate = int(np.ceil(aug_per_img)) if img_idx < n_augment % n_original else int(np.floor(aug_per_img))\n",
    "        \n",
    "        for aug_num in range(n_to_generate):\n",
    "            if aug_count >= n_augment:\n",
    "                break\n",
    "            \n",
    "            # Scegli casualmente quale tipo di augmentation applicare\n",
    "            aug_type = np.random.choice(list(augmentation_transforms.keys()))\n",
    "            \n",
    "            # Applica augmentation\n",
    "            img_augmented = augmentation_transforms[aug_type](img_pil)\n",
    "            \n",
    "            # Genera nome file augmentato\n",
    "            base_name = img_name.replace('.png', '')\n",
    "            augmented_img_name = f\"{base_name}_aug_{aug_num}_{aug_type}.png\"\n",
    "            \n",
    "            # Salva immagine augmentata\n",
    "            augmented_img_path = os.path.join(augmented_dir, augmented_img_name)\n",
    "            img_augmented.save(augmented_img_path)\n",
    "            \n",
    "            aug_count += 1\n",
    "        \n",
    "        # Progress update\n",
    "        if (img_idx + 1) % max(1, n_original // 5) == 0 or img_idx == n_original - 1:\n",
    "            print(f\"  Elaborati {img_idx + 1}/{n_original} campioni originali ({aug_count} augmentazioni generate)\")\n",
    "    \n",
    "    total_augmented += aug_count\n",
    "    print(f\"  ✓ {class_name}: Completato! {aug_count} augmentazioni generate\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"AUGMENTATION COMPLETATA!\")\n",
    "print(f\"Totale immagini augmentate generate: {total_augmented}\")\n",
    "print(f\"Cartella di salvataggio: {augmented_dir}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verifica conteggio file\n",
    "augmented_files = os.listdir(augmented_dir)\n",
    "print(f\"\\nFile nella cartella augmented: {len(augmented_files)}\")\n",
    "print(f\"Primi 5 file: {augmented_files[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de093d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Define target image size\n",
    "IMG_SIZE = (224, 224)  # Standard size for many CNN architectures\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Carica le immagini originali + augmentate\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CARICAMENTO DATASET EQUILIBRATO (Originali + Augmentate)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crea lista delle immagini augmentate\n",
    "augmented_files = os.listdir(augmented_dir)\n",
    "print(f\"Immagini augmentate trovate: {len(augmented_files)}\")\n",
    "\n",
    "# Crea nuovo dataframe con tutte le immagini (originali + augmentate)\n",
    "train_labels_augmented = train_labels.copy()\n",
    "\n",
    "# Aggiungi le immagini augmentate\n",
    "augmented_rows = []\n",
    "for aug_img_name in augmented_files:\n",
    "    # Estrai il nome originale e la classe\n",
    "    base_name = aug_img_name.split('_aug_')[0] + '.png'\n",
    "    \n",
    "    # Trova la classe nel dataframe originale\n",
    "    original_row = train_labels[train_labels['sample_index'] == base_name]\n",
    "    if not original_row.empty:\n",
    "        class_label = original_row.iloc[0]['label']\n",
    "        augmented_rows.append({'sample_index': aug_img_name, 'label': class_label})\n",
    "\n",
    "augmented_df = pd.DataFrame(augmented_rows)\n",
    "train_labels_augmented = pd.concat([train_labels_augmented, augmented_df], ignore_index=True)\n",
    "\n",
    "print(f\"\\nDataset originale: {len(train_labels)} campioni\")\n",
    "print(f\"Dataset augmentato: {len(train_labels_augmented)} campioni\")\n",
    "print(f\"\\nDistribuzione nel dataset augmentato:\")\n",
    "print(train_labels_augmented['label'].value_counts().sort_index())\n",
    "\n",
    "# Carica le immagini in tensori (originali + augmentate)\n",
    "def load_augmented_images_to_tensor(train_dir, augmented_dir, labels_df, img_size=IMG_SIZE):\n",
    "    \"\"\"Load original and augmented images into tensors\"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for idx, row in labels_df.iterrows():\n",
    "        img_name = row['sample_index']\n",
    "        label = row['label']\n",
    "        \n",
    "        # Determina da quale cartella caricare\n",
    "        if '_aug_' not in img_name:\n",
    "            # Immagine originale\n",
    "            img_path = os.path.join(train_dir, img_name)\n",
    "        else:\n",
    "            # Immagine augmentata\n",
    "            img_path = os.path.join(augmented_dir, img_name)\n",
    "        \n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"⚠ Warning: Image not found: {img_path}\")\n",
    "            continue\n",
    "        \n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        img = img.resize(img_size, Image.BILINEAR)\n",
    "        img_array = np.array(img)\n",
    "        images.append(img_array)\n",
    "        labels.append(label)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    images = np.array(images)\n",
    "    images_tensor = torch.from_numpy(images).permute(0, 3, 1, 2).float() / 255.0\n",
    "    \n",
    "    label_map = {'Triple negative': 0, 'Luminal A': 1, 'Luminal B': 2, 'HER2(+)': 3}\n",
    "    label_indices = [label_map[label] for label in labels]\n",
    "    labels_tensor = torch.tensor(label_indices, dtype=torch.long)\n",
    "    \n",
    "    return images_tensor, labels_tensor, label_map\n",
    "\n",
    "print(\"\\nCaricamento immagini in tensori...\")\n",
    "X_train_augmented, y_train_augmented, label_map = load_augmented_images_to_tensor(\n",
    "    train_dir, augmented_dir, train_labels_augmented, IMG_SIZE\n",
    ")\n",
    "\n",
    "print(f\"Tensore immagini shape: {X_train_augmented.shape}\")\n",
    "print(f\"Tensore labels shape: {y_train_augmented.shape}\")\n",
    "\n",
    "# Split training/validation (stratificato)\n",
    "X_train_aug, X_val_aug, y_train_aug, y_val_aug = train_test_split(\n",
    "    X_train_augmented, y_train_augmented, test_size=0.2, random_state=42, stratify=y_train_augmented\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set augmentato: {X_train_aug.shape[0]} campioni\")\n",
    "print(f\"Validation set augmentato: {X_val_aug.shape[0]} campioni\")\n",
    "\n",
    "# Crea nuovi DataLoaders\n",
    "train_dataset_aug = TensorDataset(X_train_aug, y_train_aug)\n",
    "val_dataset_aug = TensorDataset(X_val_aug, y_val_aug)\n",
    "\n",
    "train_loader_aug = DataLoader(train_dataset_aug, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_aug = DataLoader(val_dataset_aug, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"\\nDataLoaders augmentati creati:\")\n",
    "print(f\"Train batches: {len(train_loader_aug)}\")\n",
    "print(f\"Val batches: {len(val_loader_aug)}\")\n",
    "\n",
    "print(\"\\n✓ Dataset equilibrato pronto per l'addestramento!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1673d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all images and labels into tensors\n",
    "def load_images_to_tensor(data_dir, labels_df=None, is_test=False, img_size=IMG_SIZE):\n",
    "    \"\"\"Load all images from directory into a tensor with resizing\"\"\"\n",
    "    if not is_test:\n",
    "        image_files = labels_df['sample_index'].tolist()\n",
    "    else:\n",
    "        image_files = sorted([f for f in os.listdir(data_dir) if f.startswith('img_')])\n",
    "    \n",
    "    images = []\n",
    "    for img_name in image_files:\n",
    "        img_path = os.path.join(data_dir, img_name)\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        # Resize image to fixed size\n",
    "        img = img.resize(img_size, Image.BILINEAR)\n",
    "        img_array = np.array(img)\n",
    "        images.append(img_array)\n",
    "    \n",
    "    # Stack into numpy array: (N, H, W, C)\n",
    "    images = np.array(images)\n",
    "    # Convert to tensor and permute to (N, C, H, W)\n",
    "    images_tensor = torch.from_numpy(images).permute(0, 3, 1, 2).float() / 255.0\n",
    "    \n",
    "    if not is_test:\n",
    "        # Create label mapping and convert labels to tensor\n",
    "        label_map = {'Triple negative': 0, 'Luminal A': 1, 'Luminal B': 2, 'HER2(+)': 3}\n",
    "        labels = [label_map[label] for label in labels_df['label']]\n",
    "        labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "        return images_tensor, labels_tensor, label_map\n",
    "    else:\n",
    "        return images_tensor, image_files\n",
    "\n",
    "# Load test data\n",
    "print(\"\\nLoading test images...\")\n",
    "X_test, test_filenames = load_images_to_tensor(test_dir, is_test=True)\n",
    "print(f\"Test images shape: {X_test.shape}\")\n",
    "\n",
    "test_dataset = TensorDataset(X_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"\\nDataLoader created:\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6b729",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train_aug.shape[1:]  # (C, H, W)\n",
    "num_classes = len(label_map)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00880a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Number of training epochs\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 10\n",
    "PATIENCE = 50\n",
    "\n",
    "# Regularisation\n",
    "DROPOUT_RATE = 0.2         # Dropout probability\n",
    "L1_LAMBDA = 0            # L1 penalty\n",
    "L2_LAMBDA = 0            # L2 penalty\n",
    "\n",
    "# Set up loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Print the defined parameters\n",
    "print(\"Epochs:\", EPOCHS)\n",
    "print(\"Batch Size:\", BATCH_SIZE)\n",
    "print(\"Learning Rate:\", LEARNING_RATE)\n",
    "print(\"Dropout Rate:\", DROPOUT_RATE)\n",
    "print(\"L1 Penalty:\", L1_LAMBDA)\n",
    "print(\"L2 Penalty:\", L2_LAMBDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfb42d0",
   "metadata": {},
   "source": [
    "# Model Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36adec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Architecture parameters\n",
    "# Number of convolutional blocks\n",
    "NUM_BLOCKS = 2\n",
    "\n",
    "# Number of conv layers per block\n",
    "CONVS_PER_BLOCK = 1\n",
    "\n",
    "# Use strided convolutions instead of pooling\n",
    "USE_STRIDE = False\n",
    "\n",
    "# Stride value when USE_STRIDE is True\n",
    "STRIDE_VALUE = 2\n",
    "\n",
    "# Padding size\n",
    "PADDING_SIZE = 1\n",
    "\n",
    "# Pooling size when USE_STRIDE is False\n",
    "POOL_SIZE = 2\n",
    "\n",
    "# Number of channels in first block\n",
    "INITIAL_CHANNELS = 32\n",
    "\n",
    "# Channel multiplication factor between blocks\n",
    "CHANNEL_MULTIPLIER = 2\n",
    "\n",
    "print(\"Num Blocks:\", NUM_BLOCKS)\n",
    "print(\"Convs per Block:\", CONVS_PER_BLOCK)\n",
    "print(\"Use Stride:\", USE_STRIDE)\n",
    "print(\"Stride Value:\", STRIDE_VALUE)\n",
    "print(\"Padding Size:\", PADDING_SIZE)\n",
    "print(\"Pool Size:\", POOL_SIZE)\n",
    "print(\"Initial Channels:\", INITIAL_CHANNELS)\n",
    "print(\"Channel Multiplier:\", CHANNEL_MULTIPLIER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a55b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single convolutional block with multiple conv layers, ReLU and pooling/stride\n",
    "class VanillaCNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, num_convs=1, use_stride=False, stride_value=2, padding_size=1, pool_size=2):\n",
    "        super().__init__()\n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # First convolution: in_channels -> out_channels\n",
    "        if num_convs == 1:\n",
    "            # Single conv: apply stride here if use_stride is True\n",
    "            stride = stride_value if use_stride else 1\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=padding_size, stride=stride))\n",
    "        else:\n",
    "            # Multiple convs: first one always has stride=1\n",
    "            layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=1))\n",
    "\n",
    "            # Intermediate convolutions (all with stride=1)\n",
    "            for i in range(1, num_convs - 1):\n",
    "                layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, stride=1))\n",
    "\n",
    "            # Last convolution: apply stride here if use_stride is True\n",
    "            stride = stride_value if use_stride else 1\n",
    "            layers.append(nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=padding_size, stride=stride))\n",
    "\n",
    "        # ReLU activation\n",
    "        layers.append(nn.ReLU())\n",
    "\n",
    "        # Pooling only if not using stride for spatial reduction\n",
    "        if not use_stride:\n",
    "            layers.append(nn.MaxPool2d(kernel_size=pool_size, stride=pool_size))\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "# Convolutional Neural Network architecture for CIFAR10 classification\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_shape=(3,32,32), num_classes=10, dropout_rate=DROPOUT_RATE,\n",
    "                 num_blocks=NUM_BLOCKS, convs_per_block=CONVS_PER_BLOCK,\n",
    "                 use_stride=USE_STRIDE, stride_value=STRIDE_VALUE, padding_size=PADDING_SIZE, pool_size=POOL_SIZE,\n",
    "                 initial_channels=INITIAL_CHANNELS, channel_multiplier=CHANNEL_MULTIPLIER):\n",
    "        super().__init__()\n",
    "\n",
    "        # Build convolutional blocks\n",
    "        blocks = []\n",
    "        in_channels = input_shape[0]\n",
    "        out_channels = initial_channels\n",
    "\n",
    "        for i in range(num_blocks):\n",
    "            blocks.append(VanillaCNNBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                num_convs=convs_per_block,\n",
    "                use_stride=use_stride,\n",
    "                stride_value=stride_value,\n",
    "                padding_size=padding_size,\n",
    "                pool_size=pool_size\n",
    "            ))\n",
    "\n",
    "            # Prepare for next block: increase channels\n",
    "            in_channels = out_channels\n",
    "            out_channels = out_channels * channel_multiplier\n",
    "\n",
    "        self.features = nn.Sequential(*blocks)\n",
    "\n",
    "        # Calculate flattened size after all blocks using a dummy forward pass\n",
    "        # This approach is robust and works with any configuration of padding, stride, and pooling\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, *input_shape)\n",
    "            dummy_output = self.features(dummy_input)\n",
    "            flattened_size = dummy_output.view(1, -1).shape[1]\n",
    "\n",
    "        # Classification head: flatten features and apply dropout before final layer\n",
    "        self.classifier_head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(flattened_size, num_classes)\n",
    "        )\n",
    "\n",
    "    # Forward pass through the network\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier_head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea301fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "# Instantiate CNN model and move to computing device (CPU/GPU)\n",
    "cnn_model = CNN(\n",
    "    input_shape,\n",
    "    num_classes,\n",
    "    num_blocks=NUM_BLOCKS,\n",
    "    convs_per_block=CONVS_PER_BLOCK,\n",
    "    use_stride=USE_STRIDE,\n",
    "    stride_value=STRIDE_VALUE,\n",
    "    padding_size=PADDING_SIZE,\n",
    "    pool_size=POOL_SIZE,\n",
    "    initial_channels=INITIAL_CHANNELS,\n",
    "    channel_multiplier=CHANNEL_MULTIPLIER\n",
    "    ).to(device)\n",
    "\n",
    "# Display model architecture summary\n",
    "summary(cnn_model, input_size=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d3174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer with L2 regularization\n",
    "optimizer = torch.optim.AdamW(cnn_model.parameters(), lr=LEARNING_RATE, weight_decay=L2_LAMBDA)\n",
    "\n",
    "# Enable mixed precision training for GPU acceleration\n",
    "scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9f5f56",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a4724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize best model tracking variables\n",
    "best_model = None\n",
    "best_performance = float('-inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7e4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n",
    "    \"\"\"\n",
    "    Perform one complete training epoch through the entire training dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to train\n",
    "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
    "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
    "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "        l1_lambda (float): Lambda for L1 regularization\n",
    "        l2_lambda (float): Lambda for L2 regularization\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n",
    "    \"\"\"\n",
    "    model.train()  # Set model to training mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Iterate through training batches\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        # Move data to device (GPU/CPU)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Clear gradients from previous step\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Forward pass with mixed precision (if CUDA available)\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "            logits = model(inputs)\n",
    "            loss = criterion(logits, targets)\n",
    "\n",
    "            # Add L1 and L2 regularization\n",
    "            l1_norm = sum(p.abs().sum() for p in model.parameters())\n",
    "            l2_norm = sum(p.pow(2).sum() for p in model.parameters())\n",
    "            loss = loss + l1_lambda * l1_norm + l2_lambda * l2_norm\n",
    "\n",
    "\n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        all_predictions.append(predictions.cpu().numpy())\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_f1 = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='weighted'\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b99110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Perform one complete validation epoch through the entire validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n",
    "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
    "        criterion (nn.Module): Loss function used to calculate validation loss\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n",
    "\n",
    "    Note:\n",
    "        This function automatically sets the model to evaluation mode and disables\n",
    "        gradient computation for efficiency during validation.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Disable gradient computation for validation\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            # Move data to device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass with mixed precision (if CUDA available)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model(inputs)\n",
    "                loss = criterion(logits, targets)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_accuracy = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='weighted'\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05834891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n",
    "        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
    "        restore_best_weights=True, writer=None, verbose=10, experiment_name=\"\"):\n",
    "    \"\"\"\n",
    "    Train the neural network model on the training data and validate on the validation data.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to train\n",
    "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
    "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
    "        epochs (int): Number of training epochs\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
    "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
    "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "        l1_lambda (float): L1 regularization coefficient (default: 0)\n",
    "        l2_lambda (float): L2 regularization coefficient (default: 0)\n",
    "        patience (int): Number of epochs to wait for improvement before early stopping (default: 0)\n",
    "        evaluation_metric (str): Metric to monitor for early stopping (default: \"val_f1\")\n",
    "        mode (str): 'max' for maximizing the metric, 'min' for minimizing (default: 'max')\n",
    "        restore_best_weights (bool): Whether to restore model weights from best epoch (default: True)\n",
    "        writer (SummaryWriter, optional): TensorBoard SummaryWriter object for logging (default: None)\n",
    "        verbose (int, optional): Frequency of printing training progress (default: 10)\n",
    "        experiment_name (str, optional): Experiment name for saving models (default: \"\")\n",
    "\n",
    "    Returns:\n",
    "        tuple: (model, training_history) - Trained model and metrics history\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize metrics tracking\n",
    "    training_history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_f1': [], 'val_f1': []\n",
    "    }\n",
    "\n",
    "    # Configure early stopping if patience is set\n",
    "    if patience > 0:\n",
    "        patience_counter = 0\n",
    "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
    "        best_epoch = 0\n",
    "\n",
    "    print(f\"Training {epochs} epochs...\")\n",
    "\n",
    "    # Main training loop: iterate through epochs\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        # Forward pass through training data, compute gradients, update weights\n",
    "        train_loss, train_f1 = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n",
    "        )\n",
    "\n",
    "        # Evaluate model on validation data without updating weights\n",
    "        val_loss, val_f1 = validate_one_epoch(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        # Store metrics for plotting and analysis\n",
    "        training_history['train_loss'].append(train_loss)\n",
    "        training_history['val_loss'].append(val_loss)\n",
    "        training_history['train_f1'].append(train_f1)\n",
    "        training_history['val_f1'].append(val_f1)\n",
    "\n",
    "        # Print progress every N epochs or on first epoch\n",
    "        if verbose > 0:\n",
    "            if epoch % verbose == 0 or epoch == 1:\n",
    "                print(f\"Epoch {epoch:3d}/{epochs} | \"\n",
    "                    f\"Train: Loss={train_loss:.4f}, F1 Score={train_f1:.4f} | \"\n",
    "                    f\"Val: Loss={val_loss:.4f}, F1 Score={val_f1:.4f}\")\n",
    "\n",
    "        # Early stopping logic: monitor metric and save best model\n",
    "        if patience > 0:\n",
    "            current_metric = training_history[evaluation_metric][-1]\n",
    "            is_improvement = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
    "\n",
    "            if is_improvement:\n",
    "                best_metric = current_metric\n",
    "                best_epoch = epoch\n",
    "                torch.save(model.state_dict(), PATH_PREFIX + \"models/\"+experiment_name+'_model.pt')\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping triggered after {epoch} epochs.\")\n",
    "                    break\n",
    "\n",
    "    # Restore best model weights if early stopping was used\n",
    "    if restore_best_weights and patience > 0:\n",
    "        model.load_state_dict(torch.load(PATH_PREFIX + \"models/\"+experiment_name+'_model.pt'))\n",
    "        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n",
    "\n",
    "    # Save final model if no early stopping\n",
    "    if patience == 0:\n",
    "        torch.save(model.state_dict(), PATH_PREFIX + \"models/\"+experiment_name+'_model.pt')\n",
    "\n",
    "    # Close TensorBoard writer\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "\n",
    "    return model, training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Usa i DataLoader augmentati (equilibrati) per l'addestramento\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ADDESTRAMENTO CON DATASET EQUILIBRATO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train loader: {len(train_loader_aug)} batches\")\n",
    "print(f\"Val loader: {len(val_loader_aug)} batches\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Train model and track training history usando il dataset AUGMENTATO\n",
    "cnn_model, training_history = fit(\n",
    "    model=cnn_model,\n",
    "    train_loader=train_loader_aug,  # ← USA IL LOADER AUGMENTATO\n",
    "    val_loader=val_loader_aug,      # ← USA IL LOADER AUGMENTATO\n",
    "    epochs=EPOCHS,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scaler=scaler,\n",
    "    device=device,\n",
    "    verbose=1,\n",
    "    experiment_name=\"cnn_augmented\",  # Nome file salvato cambiato\n",
    "    patience=20\n",
    ")\n",
    "\n",
    "# Update best model if current performance is superior\n",
    "if training_history['val_f1'][-1] > best_performance:\n",
    "    best_model = cnn_model\n",
    "    best_performance = training_history['val_f1'][-1]\n",
    "    print(f\"\\n✓ Nuovo modello migliore salvato con F1 Score: {best_performance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9229c1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect predictions\n",
    "test_preds = []\n",
    "best_model.eval()  # Set model to evaluation mode\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    for batch in test_loader:\n",
    "        xb = batch[0].to(device)  # Extract tensor from tuple and move to device\n",
    "\n",
    "        # Forward pass: get model predictions\n",
    "        logits = best_model(xb)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        # Store batch results\n",
    "        test_preds.append(preds)\n",
    "\n",
    "# Combine all batches into single array\n",
    "test_preds = np.concatenate(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe5e407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation predictions\n",
    "val_preds = []\n",
    "val_targets = []\n",
    "best_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        logits = best_model(inputs)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        \n",
    "        val_preds.append(preds)\n",
    "        val_targets.append(targets.numpy())\n",
    "\n",
    "val_preds = np.concatenate(val_preds)\n",
    "val_targets = np.concatenate(val_targets)\n",
    "\n",
    "# Calculate overall validation set metrics\n",
    "val_acc = accuracy_score(val_targets, val_preds)\n",
    "val_prec = precision_score(val_targets, val_preds, average='weighted')\n",
    "val_rec = recall_score(val_targets, val_preds, average='weighted')\n",
    "val_f1 = f1_score(val_targets, val_preds, average='weighted')\n",
    "\n",
    "print(f\"Accuracy over the validation set: {val_acc:.4f}\")\n",
    "print(f\"Precision over the validation set: {val_prec:.4f}\")\n",
    "print(f\"Recall over the validation set: {val_rec:.4f}\")\n",
    "print(f\"F1 score over the validation set: {val_f1:.4f}\")\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(val_targets, val_preds)\n",
    "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.heatmap(cm, annot=labels, fmt='', cmap='Blues')\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Confusion Matrix — Validation Set')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reverse label mapping\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "# Create submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'sample_index': test_filenames,\n",
    "    'label': [reverse_label_map[pred] for pred in test_preds]\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(f\"Submission file created with {len(submission_df)} predictions\")\n",
    "print(\"\\nFirst few predictions:\")\n",
    "print(submission_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
