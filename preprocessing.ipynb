{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d86673",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è **Libraries Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a97415e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cpu\n",
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Import other libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84573b5b",
   "metadata": {},
   "source": [
    "## ‚è≥ **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e3320b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"pirate_pain_train.csv\")\n",
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95e9d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"pirate_pain_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9583ca7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59cf2e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.drop(columns=['joint_30'])\n",
    "df_test = df_test.drop(columns=['joint_30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c60318a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating consolidated feature: 'has_prosthetics'\n",
      "============================================================\n",
      "\n",
      "Mapping:\n",
      "  has_prosthetics = 0 ‚Üí All natural body parts (two legs, two hands, two eyes)\n",
      "  has_prosthetics = 1 ‚Üí Has prosthetics (peg leg, hook hand, eye patch)\n",
      "\n",
      "============================================================\n",
      "Distribution of new feature:\n",
      "============================================================\n",
      "\n",
      "Training set:\n",
      "  0 (Natural     ): 104,800 samples (99.09%)\n",
      "  1 (Prosthetics ):    960 samples (0.91%)\n",
      "\n",
      "Test set:\n",
      "  0 (Natural     ): 209,760 samples (99.02%)\n",
      "  1 (Prosthetics ):  2,080 samples (0.98%)\n",
      "\n",
      "Feature created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create binary 'has_prosthetics' feature (0 = all natural, 1 = has prosthetics)\n",
    "print(\"Creating consolidated feature: 'has_prosthetics'\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create the new feature\n",
    "df_train['has_prosthetics'] = (df_train['n_legs'] != 'two').astype(int)\n",
    "df_test['has_prosthetics'] = (df_test['n_legs'] != 'two').astype(int)\n",
    "\n",
    "# Show the mapping\n",
    "print(\"\\nMapping:\")\n",
    "print(\"  has_prosthetics = 0 ‚Üí All natural body parts (two legs, two hands, two eyes)\")\n",
    "print(\"  has_prosthetics = 1 ‚Üí Has prosthetics (peg leg, hook hand, eye patch)\")\n",
    "\n",
    "# Show distribution\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Distribution of new feature:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nTraining set:\")\n",
    "train_dist = df_train['has_prosthetics'].value_counts().sort_index()\n",
    "for value, count in train_dist.items():\n",
    "    label = \"Natural\" if value == 0 else \"Prosthetics\"\n",
    "    pct = (count / len(df_train)) * 100\n",
    "    print(f\"  {value} ({label:12s}): {count:6,} samples ({pct:.2f}%)\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "test_dist = df_test['has_prosthetics'].value_counts().sort_index()\n",
    "for value, count in test_dist.items():\n",
    "    label = \"Natural\" if value == 0 else \"Prosthetics\"\n",
    "    pct = (count / len(df_test)) * 100\n",
    "    print(f\"  {value} ({label:12s}): {count:6,} samples ({pct:.2f}%)\")\n",
    "\n",
    "\n",
    "# Columns to drop\n",
    "cols_to_drop = ['n_legs', 'n_hands', 'n_eyes', \n",
    "                'n_legs_encoded', 'n_hands_encoded', 'n_eyes_encoded']\n",
    "\n",
    "# Drop from both train and test\n",
    "df_train = df_train.drop(columns=[col for col in cols_to_drop if col in df_train.columns])\n",
    "df_test = df_test.drop(columns=[col for col in cols_to_drop if col in df_test.columns])\n",
    "\n",
    "print(\"\\nFeature created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ecfc017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>time</th>\n",
       "      <th>pain_survey_1</th>\n",
       "      <th>pain_survey_2</th>\n",
       "      <th>pain_survey_3</th>\n",
       "      <th>pain_survey_4</th>\n",
       "      <th>joint_00</th>\n",
       "      <th>joint_01</th>\n",
       "      <th>joint_02</th>\n",
       "      <th>joint_03</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_21</th>\n",
       "      <th>joint_22</th>\n",
       "      <th>joint_23</th>\n",
       "      <th>joint_24</th>\n",
       "      <th>joint_25</th>\n",
       "      <th>joint_26</th>\n",
       "      <th>joint_27</th>\n",
       "      <th>joint_28</th>\n",
       "      <th>joint_29</th>\n",
       "      <th>has_prosthetics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777507</td>\n",
       "      <td>0.738252</td>\n",
       "      <td>0.779512</td>\n",
       "      <td>0.804419</td>\n",
       "      <td>...</td>\n",
       "      <td>2.426544e-06</td>\n",
       "      <td>1.374706e-06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.162813e-04</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.014214</td>\n",
       "      <td>0.011376</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>0.020291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.806256</td>\n",
       "      <td>0.765147</td>\n",
       "      <td>0.761153</td>\n",
       "      <td>0.838021</td>\n",
       "      <td>...</td>\n",
       "      <td>2.757563e-07</td>\n",
       "      <td>4.026520e-07</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>9.828600e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767592</td>\n",
       "      <td>0.721439</td>\n",
       "      <td>0.772834</td>\n",
       "      <td>0.777832</td>\n",
       "      <td>...</td>\n",
       "      <td>1.063529e-07</td>\n",
       "      <td>1.440847e-08</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>6.626013e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.013097</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.016856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666220</td>\n",
       "      <td>0.810416</td>\n",
       "      <td>0.763971</td>\n",
       "      <td>0.785928</td>\n",
       "      <td>...</td>\n",
       "      <td>6.981461e-06</td>\n",
       "      <td>3.065580e-07</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.199337e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>0.017981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.774297</td>\n",
       "      <td>0.773366</td>\n",
       "      <td>0.772162</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>...</td>\n",
       "      <td>3.076737e-06</td>\n",
       "      <td>1.723862e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.307199e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.023389</td>\n",
       "      <td>0.018477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
       "0             0     0              2              0              2   \n",
       "1             0     1              2              2              2   \n",
       "2             0     2              2              0              2   \n",
       "3             0     3              2              2              2   \n",
       "4             0     4              2              2              2   \n",
       "\n",
       "   pain_survey_4  joint_00  joint_01  joint_02  joint_03  ...      joint_21  \\\n",
       "0              1  0.777507  0.738252  0.779512  0.804419  ...  2.426544e-06   \n",
       "1              2  0.806256  0.765147  0.761153  0.838021  ...  2.757563e-07   \n",
       "2              2  0.767592  0.721439  0.772834  0.777832  ...  1.063529e-07   \n",
       "3              2  0.666220  0.810416  0.763971  0.785928  ...  6.981461e-06   \n",
       "4              2  0.774297  0.773366  0.772162  0.767017  ...  3.076737e-06   \n",
       "\n",
       "       joint_22  joint_23      joint_24  joint_25  joint_26  joint_27  \\\n",
       "0  1.374706e-06  0.000015  3.162813e-04  0.000004  0.014214  0.011376   \n",
       "1  4.026520e-07  0.000022  9.828600e-07  0.000000  0.010748  0.000000   \n",
       "2  1.440847e-08  0.000005  6.626013e-05  0.000003  0.013097  0.006830   \n",
       "3  3.065580e-07  0.000007  1.199337e-06  0.000000  0.009505  0.006274   \n",
       "4  1.723862e-08  0.000006  1.307199e-06  0.000007  0.004216  0.002132   \n",
       "\n",
       "   joint_28  joint_29  has_prosthetics  \n",
       "0  0.018978  0.020291                0  \n",
       "1  0.009473  0.010006                0  \n",
       "2  0.017065  0.016856                0  \n",
       "3  0.020264  0.017981                0  \n",
       "4  0.023389  0.018477                0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# List of joint columns to normalize\n",
    "joint_cols = [\"joint_\" + str(i).zfill(2) for i in range(30)]\n",
    "\n",
    "for col in joint_cols:\n",
    "  df_train[col] = df_train[col].astype(np.float32)\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Min-Max normalization to the joint columns\n",
    "df_train[joint_cols] = minmax_scaler.fit_transform(df_train[joint_cols])\n",
    "\n",
    "data_cols = ['has_prosthetics'] + joint_cols\n",
    "\n",
    "display(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ac53296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scaler saved successfully!\n",
      "Scaler learned from training data - Min: [0.         0.         0.00101504 0.00540321 0.        ]\n",
      "Scaler learned from training data - Max: [1.407968  1.3346131 1.3060458 1.2547286 1.3592042]\n"
     ]
    }
   ],
   "source": [
    "# Save the fitted scaler for later use on test data\n",
    "import pickle\n",
    "\n",
    "# Save the scaler that was fitted on training data\n",
    "with open('minmax_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(minmax_scaler, f)\n",
    "\n",
    "print(\"‚úÖ Scaler saved successfully!\")\n",
    "print(f\"Scaler learned from training data - Min: {minmax_scaler.data_min_[:5]}\")\n",
    "print(f\"Scaler learned from training data - Max: {minmax_scaler.data_max_[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7b1b6c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>low_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>no_pain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_index     label\n",
       "0             0   no_pain\n",
       "1             1   no_pain\n",
       "2             2  low_pain\n",
       "3             3   no_pain\n",
       "4             4   no_pain"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv(\"pirate_pain_train_labels.csv\")\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19538042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: high_pain, Count: 56\n",
      "Label: low_pain, Count: 94\n",
      "Label: no_pain, Count: 511\n"
     ]
    }
   ],
   "source": [
    "# Define Weights\n",
    "WEIGHTS = []\n",
    "for label in np.unique(target['label']):\n",
    "    print(f\"Label: {label}, Count: {len(target[target['label'] == label])}\")\n",
    "    WEIGHTS.append(len(target) / len(target[target['label'] == label]))\n",
    "WEIGHTS = torch.Tensor(WEIGHTS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c11a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping of pain indexes to integer labels\n",
    "label_mapping = {\n",
    "    'no_pain': 0,\n",
    "    'low_pain': 1,\n",
    "    'high_pain': 2\n",
    "}\n",
    "\n",
    "# Map pain indexes to integers\n",
    "target['label'] = target['label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755828b",
   "metadata": {},
   "source": [
    "## üîÑ **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b04d0b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique user IDs and shuffle them\n",
    "unique_users = df_train['sample_index'].unique()\n",
    "random.seed(SEED) # Ensure reproducibility of shuffling\n",
    "random.shuffle(unique_users)\n",
    "\n",
    "input_shape = df_train.shape\n",
    "num_classes = len(np.unique(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c5532f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to build sequences from the dataset\n",
    "def build_sequences(df, window=200, stride=200):\n",
    "    # Sanity check to ensure the window is divisible by the stride\n",
    "    assert window % stride == 0\n",
    "\n",
    "    # Initialise lists to store sequences and their corresponding labels\n",
    "    dataset = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over unique IDs in the DataFrame\n",
    "    for id in df['sample_index'].unique():\n",
    "        # Extract sensor data for the current ID\n",
    "        temp = df[df['sample_index'] == id][data_cols].values\n",
    "\n",
    "        # Retrieve the activity label for the current ID\n",
    "        label = target[target['sample_index'] == id]['label'].values[0]\n",
    "\n",
    "        # Calculate padding length to ensure full windows\n",
    "        padding_len = window - len(temp) % window\n",
    "\n",
    "        # Create zero padding and concatenate with the data\n",
    "        padding = np.zeros((padding_len, len(data_cols)), dtype='float32')\n",
    "        temp = np.concatenate((temp, padding))\n",
    "\n",
    "        # Build feature windows and associate them with labels\n",
    "        idx = 0\n",
    "        while idx + window <= len(temp):\n",
    "            dataset.append(temp[idx:idx + window])\n",
    "            labels.append(label)\n",
    "            idx += stride\n",
    "\n",
    "    # Convert lists to numpy arrays for further processing\n",
    "    dataset = np.array(dataset)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "def build_test_sequences(df, window=200, stride=200):\n",
    "    # Sanity check to ensure the window is divisible by the stride\n",
    "    assert window % stride == 0\n",
    "\n",
    "    # Initialise lists to store sequences and their corresponding labels\n",
    "    dataset = []\n",
    "\n",
    "    # Iterate over unique IDs in the DataFrame\n",
    "    for id in df['sample_index'].unique():\n",
    "        # Extract sensor data for the current ID\n",
    "        temp = df[df['sample_index'] == id][data_cols].values\n",
    "\n",
    "        # Calculate padding length to ensure full windows\n",
    "        padding_len = window - len(temp) % window\n",
    "\n",
    "        # Create zero padding and concatenate with the data\n",
    "        padding = np.zeros((padding_len, len(data_cols)), dtype='float32')\n",
    "        temp = np.concatenate((temp, padding))\n",
    "\n",
    "        # Build feature windows\n",
    "        idx = 0\n",
    "        while idx + window <= len(temp):\n",
    "            dataset.append(temp[idx:idx + window])\n",
    "            idx += stride\n",
    "\n",
    "    # Convert lists to numpy arrays for further processing\n",
    "    dataset = np.array(dataset)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcb01755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the window size\n",
    "WINDOW_SIZE = 300\n",
    "\n",
    "# Define the stride for overlapping windows\n",
    "STRIDE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b741135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_loader(ds, batch_size, shuffle, drop_last):\n",
    "    # Determine optimal number of worker processes for data loading\n",
    "    cpu_cores = os.cpu_count() or 2\n",
    "    num_workers = max(2, min(4, cpu_cores))\n",
    "\n",
    "    # Create DataLoader with performance optimizations\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,  # Faster GPU transfer\n",
    "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
    "        prefetch_factor=4,  # Load 4 batches ahead\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8c6a3",
   "metadata": {},
   "source": [
    "joint diversi tra train e test\n",
    "da 13 a 17 da 19 a 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a375342",
   "metadata": {},
   "source": [
    "## üî¨ Valutazione strategie di sequenziamento (windowing) / Sequencing strategy evaluation\n",
    "\n",
    "Questa sezione aggiunge funzioni per confrontare diversi schemi di finestratura (window/stride/labeling/padding) usando GroupKFold e macro‚ÄëF1.  \n",
    "This section adds functions to compare different windowing schemes (window/stride/labeling/padding) with GroupKFold and macro‚ÄëF1.\n",
    "\n",
    "> Nota/Note: le celle **non** vengono eseguite automaticamente. Esegui in ordine dall'alto verso il basso dopo aver caricato `df_train` e (se necessario) `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3d72d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & setup for the evaluation harness ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Label mapping (robust to string or numeric labels)\n",
    "LABEL_MAP = {\"no_pain\": 0, \"low_pain\": 1, \"high_pain\": 2}\n",
    "\n",
    "def _detect_joint_cols(df):\n",
    "    return sorted([c for c in df.columns if c.startswith(\"joint_\")])\n",
    "\n",
    "def _get_data_cols(df):\n",
    "    cols = _detect_joint_cols(df)\n",
    "    if not cols:\n",
    "        raise ValueError(\"Nessuna colonna 'joint_*' trovata in df. / No 'joint_*' columns found in df.\")\n",
    "    return cols\n",
    "\n",
    "# Load labels if not already present\n",
    "if \"target\" not in globals():\n",
    "    try:\n",
    "        target = pd.read_csv(\"pirate_pain_train_labels.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Avviso/Warning: 'target' non definito e file 'pirate_pain_train_labels.csv' non trovato.\")\n",
    "    else:\n",
    "        if \"label\" in target.columns:\n",
    "            # Map strings to ints if needed\n",
    "            if target[\"label\"].dtype == object:\n",
    "                target[\"label\"] = target[\"label\"].map(lambda x: LABEL_MAP.get(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "50378f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Window builder ---\n",
    "def build_windows(\n",
    "    df: pd.DataFrame,\n",
    "    target: pd.DataFrame,\n",
    "    window: int = 300,\n",
    "    stride: int = 75,\n",
    "    labeling: str = \"id\",       # currently supports: 'id'\n",
    "    padding: str = \"zero\",      # 'zero' or 'drop_last'\n",
    "    feature: str = \"flatten\",   # 'flatten' (simple baseline)\n",
    "    data_cols: list | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Costruisce finestre scorrevoli a partire da df e restituisce (X, y, groups).\n",
    "    Builds sliding windows from df and returns (X, y, groups).\n",
    "    \"\"\"\n",
    "    if data_cols is None:\n",
    "        data_cols = _get_data_cols(df)\n",
    "    X, y, groups = [], [], []\n",
    "    for sid in df[\"sample_index\"].unique():\n",
    "        temp = df[df[\"sample_index\"] == sid][data_cols].values\n",
    "        # get label for this id\n",
    "        lab_arr = target[target[\"sample_index\"] == sid][\"label\"].values\n",
    "        if len(lab_arr) == 0:\n",
    "            # if missing label, skip this id\n",
    "            continue\n",
    "        lab = lab_arr[0]\n",
    "        if isinstance(lab, str):\n",
    "            lab = LABEL_MAP.get(lab, lab)\n",
    "        # padding computation\n",
    "        pad = (window - (len(temp) % window)) % window\n",
    "        if padding == \"zero\" and pad:\n",
    "            temp = np.concatenate([temp, np.zeros((pad, temp.shape[1]), dtype=temp.dtype)], axis=0)\n",
    "        L = len(temp)\n",
    "        start = 0\n",
    "        while start + window <= L:\n",
    "            seg = temp[start:start + window]\n",
    "            if feature == \"flatten\":\n",
    "                feat = seg.reshape(-1)\n",
    "            else:\n",
    "                feat = seg.reshape(-1)  # default fallback\n",
    "            X.append(feat)\n",
    "            y.append(lab)\n",
    "            groups.append(sid)\n",
    "            start += stride\n",
    "    if not X:\n",
    "        raise ValueError(\"Nessuna finestra generata: controlla window/stride e la presenza di colonne joint_.\")\n",
    "    return np.asarray(X), np.asarray(y), np.asarray(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0afdf168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Strategy evaluator ---\n",
    "def eval_strategy(df: pd.DataFrame, target: pd.DataFrame, params: dict, n_splits: int = 5):\n",
    "    X, y, groups = build_windows(df, target, **params)\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    scores = []\n",
    "    for tr, te in gkf.split(X, y, groups):\n",
    "        clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", n_jobs=None)\n",
    "        clf.fit(X[tr], y[tr])\n",
    "        pred = clf.predict(X[te])\n",
    "        scores.append(f1_score(y[te], pred, average=\"macro\"))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c22bca03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risultati / Results (mean, std, fold_scores):\n",
      "{'window': 128, 'stride': 32, 'labeling': 'id', 'padding': 'zero'} -> (np.float64(0.535554626658966), np.float64(0.030318517367946034), [0.5575568481135713, 0.4784556964586573, 0.5640875456957871, 0.5360074084401983, 0.5416656345866163])\n",
      "{'window': 256, 'stride': 64, 'labeling': 'id', 'padding': 'zero'} -> (np.float64(0.5744914366114311), np.float64(0.05140432771327308), [0.6315323565323566, 0.528096416254311, 0.6086213303604607, 0.4990065786568944, 0.6052005012531328])\n",
      "{'window': 300, 'stride': 75, 'labeling': 'id', 'padding': 'drop_last'} -> Errore/Error: Nessuna finestra generata: controlla window/stride e la presenza di colonne joint_.\n"
     ]
    }
   ],
   "source": [
    "# --- Example grid & runner (not executed automatically) ---\n",
    "# Ensure df_train exists before running this cell.\n",
    "try:\n",
    "    _ = df_train\n",
    "except NameError:\n",
    "    print(\"Definisci/Load 'df_train' prima di eseguire questa cella. / Please define 'df_train' first.\")\n",
    "else:\n",
    "    grid = [\n",
    "        {\"window\": 128, \"stride\": 32,  \"labeling\": \"id\", \"padding\": \"zero\"},\n",
    "        {\"window\": 256, \"stride\": 64,  \"labeling\": \"id\", \"padding\": \"zero\"},\n",
    "        {\"window\": 300, \"stride\": 75,  \"labeling\": \"id\", \"padding\": \"drop_last\"},\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "    for p in grid:\n",
    "        try:\n",
    "            scores = eval_strategy(df_train, target, p, n_splits=5)\n",
    "            results[str(p)] = (scores.mean(), scores.std(), scores.tolist())\n",
    "        except Exception as e:\n",
    "            results[str(p)] = f\"Errore/Error: {e}\"\n",
    "\n",
    "    print(\"Risultati / Results (mean, std, fold_scores):\")\n",
    "    for name, res in results.items():\n",
    "        print(name, \"->\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17d62ba",
   "metadata": {},
   "source": [
    "{'window': 256, 'stride': 64, 'labeling': 'id', 'padding': 'zero'} -> (np.float64(0.5744914366114311), np.float64(0.05140432771327308), [0.6315323565323566, 0.528096416254311, 0.6086213303604607, 0.4990065786568944, 0.6052005012531328])\n",
    "\n",
    "Questo √® il milgiore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d0d641",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c576ee2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
