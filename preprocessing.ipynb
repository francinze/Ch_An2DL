{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84d86673",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è **Libraries Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97415e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "\n",
    "# Set environment variables before importing modules\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['MPLCONFIGDIR'] = os.getcwd() + '/configs/'\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "# Import necessary modules\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for random number generators in NumPy and Python\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Import PyTorch\n",
    "import torch\n",
    "torch.manual_seed(SEED)\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Import other libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84573b5b",
   "metadata": {},
   "source": [
    "## ‚è≥ **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cf2e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (105760, 39)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"pirate_pain_train.csv\")\n",
    "df_test = pd.read_csv(\"pirate_pain_test.csv\")\n",
    "df = df.drop(columns=['joint_30'])\n",
    "df_test = df_test.drop(columns=['joint_30'])\n",
    "\n",
    "print(\"Training data shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60318a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating consolidated feature: 'has_prosthetics'\n",
      "============================================================\n",
      "\n",
      "Mapping:\n",
      "  has_prosthetics = 0 ‚Üí All natural body parts (two legs, two hands, two eyes)\n",
      "  has_prosthetics = 1 ‚Üí Has prosthetics (peg leg, hook hand, eye patch)\n",
      "\n",
      "============================================================\n",
      "Distribution of new feature:\n",
      "============================================================\n",
      "\n",
      "Training set:\n",
      "  0 (Natural     ): 104,800 samples (99.09%)\n",
      "  1 (Prosthetics ):    960 samples (0.91%)\n",
      "\n",
      "Test set:\n",
      "  0 (Natural     ): 209,760 samples (99.02%)\n",
      "  1 (Prosthetics ):  2,080 samples (0.98%)\n",
      "\n",
      "Feature created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create binary 'has_prosthetics' feature (0 = all natural, 1 = has prosthetics)\n",
    "print(\"Creating consolidated feature: 'has_prosthetics'\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create the new feature\n",
    "df['has_prosthetics'] = (df['n_legs'] != 'two').astype(int)\n",
    "df_test['has_prosthetics'] = (df_test['n_legs'] != 'two').astype(int)\n",
    "\n",
    "# Show the mapping\n",
    "print(\"\\nMapping:\")\n",
    "print(\"  has_prosthetics = 0 ‚Üí All natural body parts (two legs, two hands, two eyes)\")\n",
    "print(\"  has_prosthetics = 1 ‚Üí Has prosthetics (peg leg, hook hand, eye patch)\")\n",
    "\n",
    "# Show distribution\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Distribution of new feature:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nTraining set:\")\n",
    "train_dist = df['has_prosthetics'].value_counts().sort_index()\n",
    "for value, count in train_dist.items():\n",
    "    label = \"Natural\" if value == 0 else \"Prosthetics\"\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"  {value} ({label:12s}): {count:6,} samples ({pct:.2f}%)\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "test_dist = df_test['has_prosthetics'].value_counts().sort_index()\n",
    "for value, count in test_dist.items():\n",
    "    label = \"Natural\" if value == 0 else \"Prosthetics\"\n",
    "    pct = (count / len(df_test)) * 100\n",
    "    print(f\"  {value} ({label:12s}): {count:6,} samples ({pct:.2f}%)\")\n",
    "\n",
    "\n",
    "# Columns to drop\n",
    "cols_to_drop = ['n_legs', 'n_hands', 'n_eyes', \n",
    "                'n_legs_encoded', 'n_hands_encoded', 'n_eyes_encoded']\n",
    "\n",
    "# Drop from both train and test\n",
    "df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "df_test = df_test.drop(columns=[col for col in cols_to_drop if col in df_test.columns])\n",
    "\n",
    "print(\"\\nFeature created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecfc017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sample_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "time",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pain_survey_1",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pain_survey_2",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pain_survey_3",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pain_survey_4",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "joint_00",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_01",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_02",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_03",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_04",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_05",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_06",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_07",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_08",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_09",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_10",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_11",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_12",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_13",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_14",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_15",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_16",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_17",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_18",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_19",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_20",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_21",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_22",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_23",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_24",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_25",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_26",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_27",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_28",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "joint_29",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "has_prosthetics",
         "rawType": "int32",
         "type": "integer"
        }
       ],
       "ref": "4a3974af-7344-4a84-a9de-9dce13b27adb",
       "rows": [
        [
         "0",
         "0",
         "0",
         "2",
         "0",
         "2",
         "1",
         "0.7775072",
         "0.73825186",
         "0.7795117",
         "0.8044193",
         "0.7149161",
         "0.73664325",
         "0.6393011",
         "0.7339808",
         "0.4783819",
         "0.7557072",
         "0.27674192",
         "0.26950964",
         "0.7629471",
         "0.0",
         "1.1010252e-07",
         "4.774861e-05",
         "2.3317198e-05",
         "0.0",
         "2.3132805e-05",
         "1.9646883e-05",
         "5.6023447e-07",
         "2.4265441e-06",
         "1.3747061e-06",
         "1.4584098e-05",
         "0.00031628134",
         "4.017432e-06",
         "0.014213627",
         "0.011375809",
         "0.018978015",
         "0.020291287",
         "0"
        ],
        [
         "1",
         "0",
         "1",
         "2",
         "2",
         "2",
         "2",
         "0.8062563",
         "0.7651466",
         "0.7611533",
         "0.83802074",
         "0.73568356",
         "0.7295326",
         "0.6546045",
         "0.7605536",
         "0.48623142",
         "0.7630596",
         "0.22243235",
         "0.24584588",
         "0.7279103",
         "0.00016688886",
         "1.7144182e-05",
         "0.0",
         "2.052431e-05",
         "2.0684116e-05",
         "0.0",
         "1.6547332e-05",
         "1.7627315e-06",
         "2.7575626e-07",
         "4.02652e-07",
         "2.1950129e-05",
         "9.8286e-07",
         "0.0",
         "0.010748026",
         "0.0",
         "0.00947325",
         "0.01000604",
         "0"
        ],
        [
         "2",
         "0",
         "2",
         "2",
         "0",
         "2",
         "2",
         "0.7675919",
         "0.7214393",
         "0.7728343",
         "0.7778321",
         "0.7244974",
         "0.73496205",
         "0.69233954",
         "0.7876475",
         "0.44199404",
         "0.7277106",
         "0.21303913",
         "0.25813314",
         "0.7607566",
         "0.0",
         "1.3735757e-07",
         "0.0",
         "5.485442e-06",
         "0.0",
         "1.3355282e-05",
         "3.2854164e-06",
         "5.2288e-07",
         "1.06352935e-07",
         "1.4408471e-08",
         "5.272918e-06",
         "6.626013e-05",
         "2.6531989e-06",
         "0.013096542",
         "0.0068303123",
         "0.017065361",
         "0.016855564",
         "0"
        ],
        [
         "3",
         "0",
         "3",
         "2",
         "2",
         "2",
         "2",
         "0.66622007",
         "0.8104164",
         "0.7639709",
         "0.78592783",
         "0.67992777",
         "0.72250426",
         "0.5891266",
         "0.79352415",
         "0.4695538",
         "0.75359744",
         "0.24343303",
         "0.25032386",
         "0.7674341",
         "0.0",
         "1.5094281e-07",
         "0.0",
         "1.3265037e-05",
         "8.211184e-05",
         "0.0",
         "1.1172791e-05",
         "3.3553275e-05",
         "6.9814614e-06",
         "3.0655798e-07",
         "6.737126e-06",
         "1.199337e-06",
         "0.0",
         "0.009505061",
         "0.006274173",
         "0.020263739",
         "0.017981347",
         "0"
        ],
        [
         "4",
         "0",
         "4",
         "2",
         "2",
         "2",
         "2",
         "0.77429664",
         "0.7733662",
         "0.77216166",
         "0.7670174",
         "0.74771",
         "0.743156",
         "0.6777643",
         "0.7254371",
         "0.47774032",
         "0.75179595",
         "0.2264337",
         "0.29046425",
         "0.772967",
         "0.0",
         "3.21004e-07",
         "1.877239e-05",
         "5.496563e-06",
         "0.0",
         "4.090925e-05",
         "3.3025467e-06",
         "1.8594093e-05",
         "3.0767374e-06",
         "1.723862e-08",
         "5.661887e-06",
         "1.307199e-06",
         "7.436324e-06",
         "0.004215624",
         "0.0021319746",
         "0.023389036",
         "0.018477248",
         "0"
        ]
       ],
       "shape": {
        "columns": 37,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>time</th>\n",
       "      <th>pain_survey_1</th>\n",
       "      <th>pain_survey_2</th>\n",
       "      <th>pain_survey_3</th>\n",
       "      <th>pain_survey_4</th>\n",
       "      <th>joint_00</th>\n",
       "      <th>joint_01</th>\n",
       "      <th>joint_02</th>\n",
       "      <th>joint_03</th>\n",
       "      <th>...</th>\n",
       "      <th>joint_21</th>\n",
       "      <th>joint_22</th>\n",
       "      <th>joint_23</th>\n",
       "      <th>joint_24</th>\n",
       "      <th>joint_25</th>\n",
       "      <th>joint_26</th>\n",
       "      <th>joint_27</th>\n",
       "      <th>joint_28</th>\n",
       "      <th>joint_29</th>\n",
       "      <th>has_prosthetics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.777507</td>\n",
       "      <td>0.738252</td>\n",
       "      <td>0.779512</td>\n",
       "      <td>0.804419</td>\n",
       "      <td>...</td>\n",
       "      <td>2.426544e-06</td>\n",
       "      <td>1.374706e-06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>3.162813e-04</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.014214</td>\n",
       "      <td>0.011376</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>0.020291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.806256</td>\n",
       "      <td>0.765147</td>\n",
       "      <td>0.761153</td>\n",
       "      <td>0.838021</td>\n",
       "      <td>...</td>\n",
       "      <td>2.757563e-07</td>\n",
       "      <td>4.026520e-07</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>9.828600e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009473</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.767592</td>\n",
       "      <td>0.721439</td>\n",
       "      <td>0.772834</td>\n",
       "      <td>0.777832</td>\n",
       "      <td>...</td>\n",
       "      <td>1.063529e-07</td>\n",
       "      <td>1.440847e-08</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>6.626013e-05</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.013097</td>\n",
       "      <td>0.006830</td>\n",
       "      <td>0.017065</td>\n",
       "      <td>0.016856</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666220</td>\n",
       "      <td>0.810416</td>\n",
       "      <td>0.763971</td>\n",
       "      <td>0.785928</td>\n",
       "      <td>...</td>\n",
       "      <td>6.981461e-06</td>\n",
       "      <td>3.065580e-07</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.199337e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009505</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>0.017981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.774297</td>\n",
       "      <td>0.773366</td>\n",
       "      <td>0.772162</td>\n",
       "      <td>0.767017</td>\n",
       "      <td>...</td>\n",
       "      <td>3.076737e-06</td>\n",
       "      <td>1.723862e-08</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.307199e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.002132</td>\n",
       "      <td>0.023389</td>\n",
       "      <td>0.018477</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_index  time  pain_survey_1  pain_survey_2  pain_survey_3  \\\n",
       "0             0     0              2              0              2   \n",
       "1             0     1              2              2              2   \n",
       "2             0     2              2              0              2   \n",
       "3             0     3              2              2              2   \n",
       "4             0     4              2              2              2   \n",
       "\n",
       "   pain_survey_4  joint_00  joint_01  joint_02  joint_03  ...      joint_21  \\\n",
       "0              1  0.777507  0.738252  0.779512  0.804419  ...  2.426544e-06   \n",
       "1              2  0.806256  0.765147  0.761153  0.838021  ...  2.757563e-07   \n",
       "2              2  0.767592  0.721439  0.772834  0.777832  ...  1.063529e-07   \n",
       "3              2  0.666220  0.810416  0.763971  0.785928  ...  6.981461e-06   \n",
       "4              2  0.774297  0.773366  0.772162  0.767017  ...  3.076737e-06   \n",
       "\n",
       "       joint_22  joint_23      joint_24  joint_25  joint_26  joint_27  \\\n",
       "0  1.374706e-06  0.000015  3.162813e-04  0.000004  0.014214  0.011376   \n",
       "1  4.026520e-07  0.000022  9.828600e-07  0.000000  0.010748  0.000000   \n",
       "2  1.440847e-08  0.000005  6.626013e-05  0.000003  0.013097  0.006830   \n",
       "3  3.065580e-07  0.000007  1.199337e-06  0.000000  0.009505  0.006274   \n",
       "4  1.723862e-08  0.000006  1.307199e-06  0.000007  0.004216  0.002132   \n",
       "\n",
       "   joint_28  joint_29  has_prosthetics  \n",
       "0  0.018978  0.020291                0  \n",
       "1  0.009473  0.010006                0  \n",
       "2  0.017065  0.016856                0  \n",
       "3  0.020264  0.017981                0  \n",
       "4  0.023389  0.018477                0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# List of joint columns to normalize\n",
    "joint_cols = [\"joint_\" + str(i).zfill(2) for i in range(30)]\n",
    "\n",
    "for col in joint_cols:\n",
    "  df[col] = df[col].astype(np.float32)\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Min-Max normalization to the joint columns\n",
    "df[joint_cols] = minmax_scaler.fit_transform(df[joint_cols])\n",
    "\n",
    "data_cols = ['has_prosthetics'] + joint_cols\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac53296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Scaler saved successfully!\n",
      "Scaler learned from training data - Min: [0.         0.         0.00101504 0.00540321 0.        ]\n",
      "Scaler learned from training data - Max: [1.407968  1.3346131 1.3060458 1.2547286 1.3592042]\n"
     ]
    }
   ],
   "source": [
    "# Save the fitted scaler for later use on test data\n",
    "import pickle\n",
    "\n",
    "# Save the scaler that was fitted on training data\n",
    "with open('minmax_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(minmax_scaler, f)\n",
    "\n",
    "print(\"‚úÖ Scaler saved successfully!\")\n",
    "print(f\"Scaler learned from training data - Min: {minmax_scaler.data_min_[:5]}\")\n",
    "print(f\"Scaler learned from training data - Max: {minmax_scaler.data_max_[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1b6c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sample_index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "label",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "5adfe458-7d2c-44dd-8ab9-8fbce87c7c14",
       "rows": [
        [
         "0",
         "0",
         "no_pain"
        ],
        [
         "1",
         "1",
         "no_pain"
        ],
        [
         "2",
         "2",
         "low_pain"
        ],
        [
         "3",
         "3",
         "no_pain"
        ],
        [
         "4",
         "4",
         "no_pain"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>low_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>no_pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>no_pain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_index     label\n",
       "0             0   no_pain\n",
       "1             1   no_pain\n",
       "2             2  low_pain\n",
       "3             3   no_pain\n",
       "4             4   no_pain"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv(\"pirate_pain_train_labels.csv\")\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19538042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: high_pain, Count: 56\n",
      "Label: low_pain, Count: 94\n",
      "Label: no_pain, Count: 511\n"
     ]
    }
   ],
   "source": [
    "# Define Weights\n",
    "WEIGHTS = []\n",
    "for label in np.unique(target['label']):\n",
    "    print(f\"Label: {label}, Count: {len(target[target['label'] == label])}\")\n",
    "    WEIGHTS.append(len(target) / len(target[target['label'] == label]))\n",
    "WEIGHTS = torch.Tensor(WEIGHTS).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c11a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping of pain indexes to integer labels\n",
    "label_mapping = {\n",
    "    'no_pain': 0,\n",
    "    'low_pain': 1,\n",
    "    'high_pain': 2\n",
    "}\n",
    "\n",
    "# Map pain indexes to integers\n",
    "target['label'] = target['label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7755828b",
   "metadata": {},
   "source": [
    "## üîÑ **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04d0b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (105760, 37)\n"
     ]
    }
   ],
   "source": [
    "# Get unique user IDs and shuffle them\n",
    "unique_users = df['sample_index'].unique()\n",
    "random.seed(SEED) # Ensure reproducibility of shuffling\n",
    "random.shuffle(unique_users)\n",
    "\n",
    "input_shape = df.shape\n",
    "num_classes = len(np.unique(target))\n",
    "\n",
    "print(f\"Input shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5532f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to build sequences from the dataset\n",
    "def build_sequences(df, window=200, stride=200):\n",
    "    # Sanity check to ensure the window is divisible by the stride\n",
    "    assert window % stride == 0\n",
    "\n",
    "    # Initialise lists to store sequences and their corresponding labels\n",
    "    dataset = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over unique IDs in the DataFrame\n",
    "    for id in df['sample_index'].unique():\n",
    "        # Extract sensor data for the current ID\n",
    "        temp = df[df['sample_index'] == id][data_cols].values\n",
    "\n",
    "        # Retrieve the activity label for the current ID\n",
    "        label = target[target['sample_index'] == id]['label'].values[0]\n",
    "\n",
    "        # Calculate padding length to ensure full windows\n",
    "        padding_len = window - len(temp) % window\n",
    "\n",
    "        # Create zero padding and concatenate with the data\n",
    "        padding = np.zeros((padding_len, len(data_cols)), dtype='float32')\n",
    "        temp = np.concatenate((temp, padding))\n",
    "\n",
    "        # Build feature windows and associate them with labels\n",
    "        idx = 0\n",
    "        while idx + window <= len(temp):\n",
    "            dataset.append(temp[idx:idx + window])\n",
    "            labels.append(label)\n",
    "            idx += stride\n",
    "\n",
    "    # Convert lists to numpy arrays for further processing\n",
    "    dataset = np.array(dataset)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "def build_test_sequences(df, window=200, stride=200):\n",
    "    # Sanity check to ensure the window is divisible by the stride\n",
    "    assert window % stride == 0\n",
    "\n",
    "    # Initialise lists to store sequences and their corresponding labels\n",
    "    dataset = []\n",
    "\n",
    "    # Iterate over unique IDs in the DataFrame\n",
    "    for id in df['sample_index'].unique():\n",
    "        # Extract sensor data for the current ID\n",
    "        temp = df[df['sample_index'] == id][data_cols].values\n",
    "\n",
    "        # Calculate padding length to ensure full windows\n",
    "        padding_len = window - len(temp) % window\n",
    "\n",
    "        # Create zero padding and concatenate with the data\n",
    "        padding = np.zeros((padding_len, len(data_cols)), dtype='float32')\n",
    "        temp = np.concatenate((temp, padding))\n",
    "\n",
    "        # Build feature windows\n",
    "        idx = 0\n",
    "        while idx + window <= len(temp):\n",
    "            dataset.append(temp[idx:idx + window])\n",
    "            idx += stride\n",
    "\n",
    "    # Convert lists to numpy arrays for further processing\n",
    "    dataset = np.array(dataset)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8c6a3",
   "metadata": {},
   "source": [
    "joint diversi tra train e test\n",
    "da 13 a 17 da 19 a 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9974e0",
   "metadata": {},
   "source": [
    "## üî¨ Valutazione strategie di sequenziamento (windowing) / Sequencing strategy evaluation\n",
    "\n",
    "Questa sezione aggiunge funzioni per confrontare diversi schemi di finestratura (window/stride/labeling/padding) usando GroupKFold e macro‚ÄëF1.  \n",
    "This section adds functions to compare different windowing schemes (window/stride/labeling/padding) with GroupKFold and macro‚ÄëF1.\n",
    "\n",
    "> Nota/Note: le celle **non** vengono eseguite automaticamente. Esegui in ordine dall'alto verso il basso dopo aver caricato `df_train` e (se necessario) `target`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb7a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports & setup for the evaluation harness ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Label mapping (robust to string or numeric labels)\n",
    "LABEL_MAP = {\"no_pain\": 0, \"low_pain\": 1, \"high_pain\": 2}\n",
    "\n",
    "def _detect_joint_cols(df):\n",
    "    return sorted([c for c in df.columns if c.startswith(\"joint_\")])\n",
    "\n",
    "def _get_data_cols(df):\n",
    "    cols = _detect_joint_cols(df)\n",
    "    if not cols:\n",
    "        raise ValueError(\"Nessuna colonna 'joint_*' trovata in df. / No 'joint_*' columns found in df.\")\n",
    "    return cols\n",
    "\n",
    "# Load labels if not already present\n",
    "if \"target\" not in globals():\n",
    "    try:\n",
    "        target = pd.read_csv(\"pirate_pain_train_labels.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Avviso/Warning: 'target' non definito e file 'pirate_pain_train_labels.csv' non trovato.\")\n",
    "    else:\n",
    "        if \"label\" in target.columns:\n",
    "            # Map strings to ints if needed\n",
    "            if target[\"label\"].dtype == object:\n",
    "                target[\"label\"] = target[\"label\"].map(lambda x: LABEL_MAP.get(x, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98325051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Window builder ---\n",
    "def build_windows(\n",
    "    df: pd.DataFrame,\n",
    "    target: pd.DataFrame,\n",
    "    window: int = 300,\n",
    "    stride: int = 75,\n",
    "    labeling: str = \"id\",       # currently supports: 'id'\n",
    "    padding: str = \"zero\",      # 'zero' or 'drop_last'\n",
    "    feature: str = \"flatten\",   # 'flatten' (simple baseline)\n",
    "    data_cols: list | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Costruisce finestre scorrevoli a partire da df e restituisce (X, y, groups).\n",
    "    Builds sliding windows from df and returns (X, y, groups).\n",
    "    \"\"\"\n",
    "    if data_cols is None:\n",
    "        data_cols = _get_data_cols(df)\n",
    "    X, y, groups = [], [], []\n",
    "    for sid in df[\"sample_index\"].unique():\n",
    "        temp = df[df[\"sample_index\"] == sid][data_cols].values\n",
    "        # get label for this id\n",
    "        lab_arr = target[target[\"sample_index\"] == sid][\"label\"].values\n",
    "        if len(lab_arr) == 0:\n",
    "            # if missing label, skip this id\n",
    "            continue\n",
    "        lab = lab_arr[0]\n",
    "        if isinstance(lab, str):\n",
    "            lab = LABEL_MAP.get(lab, lab)\n",
    "        # padding computation\n",
    "        pad = (window - (len(temp) % window)) % window\n",
    "        if padding == \"zero\" and pad:\n",
    "            temp = np.concatenate([temp, np.zeros((pad, temp.shape[1]), dtype=temp.dtype)], axis=0)\n",
    "        L = len(temp)\n",
    "        start = 0\n",
    "        while start + window <= L:\n",
    "            seg = temp[start:start + window]\n",
    "            if feature == \"flatten\":\n",
    "                feat = seg.reshape(-1)\n",
    "            else:\n",
    "                feat = seg.reshape(-1)  # default fallback\n",
    "            X.append(feat)\n",
    "            y.append(lab)\n",
    "            groups.append(sid)\n",
    "            start += stride\n",
    "    if not X:\n",
    "        raise ValueError(\"Nessuna finestra generata: controlla window/stride e la presenza di colonne joint_.\")\n",
    "    return np.asarray(X), np.asarray(y), np.asarray(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231bf848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Strategy evaluator ---\n",
    "def eval_strategy(df: pd.DataFrame, target: pd.DataFrame, params: dict, n_splits: int = 5):\n",
    "    X, y, groups = build_windows(df, target, **params)\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "    scores = []\n",
    "    for tr, te in gkf.split(X, y, groups):\n",
    "        clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\", n_jobs=None)\n",
    "        clf.fit(X[tr], y[tr])\n",
    "        pred = clf.predict(X[te])\n",
    "        scores.append(f1_score(y[te], pred, average=\"macro\"))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85e409a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risultati / Results (mean, std, fold_scores):\n",
      "{'window': 128, 'stride': 32, 'labeling': 'id', 'padding': 'zero'} -> (np.float64(0.535554626658966), np.float64(0.030318517367946034), [0.5575568481135713, 0.4784556964586573, 0.5640875456957871, 0.5360074084401983, 0.5416656345866163])\n",
      "{'window': 256, 'stride': 64, 'labeling': 'id', 'padding': 'zero'} -> (np.float64(0.5744914366114311), np.float64(0.05140432771327308), [0.6315323565323566, 0.528096416254311, 0.6086213303604607, 0.4990065786568944, 0.6052005012531328])\n",
      "{'window': 300, 'stride': 75, 'labeling': 'id', 'padding': 'drop_last'} -> Errore/Error: Nessuna finestra generata: controlla window/stride e la presenza di colonne joint_.\n"
     ]
    }
   ],
   "source": [
    "# --- Example grid & runner (not executed automatically) ---\n",
    "# Ensure df_train exists before running this cell.\n",
    "try:\n",
    "    _ = df_train\n",
    "except NameError:\n",
    "    print(\"Definisci/Load 'df_train' prima di eseguire questa cella. / Please define 'df_train' first.\")\n",
    "else:\n",
    "    grid = [\n",
    "        {\"window\": 128, \"stride\": 32,  \"labeling\": \"id\", \"padding\": \"zero\"},\n",
    "        {\"window\": 256, \"stride\": 64,  \"labeling\": \"id\", \"padding\": \"zero\"},\n",
    "        {\"window\": 300, \"stride\": 75,  \"labeling\": \"id\", \"padding\": \"drop_last\"},\n",
    "    ]\n",
    "\n",
    "    results = {}\n",
    "    for p in grid:\n",
    "        try:\n",
    "            scores = eval_strategy(df_train, target, p, n_splits=5)\n",
    "            results[str(p)] = (scores.mean(), scores.std(), scores.tolist())\n",
    "        except Exception as e:\n",
    "            results[str(p)] = f\"Errore/Error: {e}\"\n",
    "\n",
    "    print(\"Risultati / Results (mean, std, fold_scores):\")\n",
    "    for name, res in results.items():\n",
    "        print(name, \"->\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea4365d",
   "metadata": {},
   "source": [
    "{'window': 256, 'stride': 64, 'labeling': 'id', 'padding': 'zero'} -> (np.float64(0.5744914366114311), np.float64(0.05140432771327308), [0.6315323565323566, 0.528096416254311, 0.6086213303604607, 0.4990065786568944, 0.6052005012531328])\n",
    "\n",
    "Questo √® il milgiore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a395edca",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d45ca830",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb60389a",
   "metadata": {},
   "source": [
    "## üß≠ 2D Grid Sweep: `window` √ó `stride` (step 10, 10‚Üí600) ‚Äî due conti separati per `padding`\n",
    "\n",
    "Questa cella valuta **tutte** le combinazioni di `window` e `stride` nell'intervallo 10..600 (passo 10),\n",
    "eseguendo **due conti separati**: `padding=\"zero\"` e `padding=\"drop_last\"`.\n",
    "\n",
    "> Eseguila **dopo** aver definito `df_train`, `target`, `build_windows` ed `eval_strategy`.\n",
    "> I risultati vengono salvati come CSV: `grid_window_stride_results_padding_zero.csv`, `grid_window_stride_results_padding_drop_last.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f326cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> Running 2D grid with padding = zero\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pad \u001b[38;5;129;01min\u001b[39;00m PADDING_RUNS:\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m>>> Running 2D grid with padding = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpad\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     df_res = \u001b[43mrun_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDATA_COLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits_max\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_SPLITS_MAX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     all_results.append(df_res)\n\u001b[32m     55\u001b[39m     out_csv = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgrid_window_stride_results_padding_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpad\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mrun_grid\u001b[39m\u001b[34m(df, target, padding, data_cols, n_splits_max)\u001b[39m\n\u001b[32m     32\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mdata_cols\u001b[39m\u001b[33m\"\u001b[39m] = data_cols\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     scores = \u001b[43meval_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     rows.append({\u001b[33m\"\u001b[39m\u001b[33mwindow\u001b[39m\u001b[33m\"\u001b[39m: w, \u001b[33m\"\u001b[39m\u001b[33mstride\u001b[39m\u001b[33m\"\u001b[39m: s, \u001b[33m\"\u001b[39m\u001b[33mpadding\u001b[39m\u001b[33m\"\u001b[39m: padding,\n\u001b[32m     36\u001b[39m                  \u001b[33m\"\u001b[39m\u001b[33mmean_macroF1\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(scores.mean()), \u001b[33m\"\u001b[39m\u001b[33mstd\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(scores.std())})\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36meval_strategy\u001b[39m\u001b[34m(df, target, params, n_splits)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tr, te \u001b[38;5;129;01min\u001b[39;00m gkf.split(X, y, groups):\n\u001b[32m      7\u001b[39m     clf = LogisticRegression(max_iter=\u001b[32m1000\u001b[39m, class_weight=\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, n_jobs=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtr\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     pred = clf.predict(X[te])\n\u001b[32m     10\u001b[39m     scores.append(f1_score(y[te], pred, average=\u001b[33m\"\u001b[39m\u001b[33mmacro\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1384\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1382\u001b[39m     n_threads = \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m fold_coefs_ = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1386\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1387\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1388\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1389\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1390\u001b[39m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1391\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1394\u001b[39m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1395\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1396\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1397\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1398\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1409\u001b[39m fold_coefs_, _, n_iter_ = \u001b[38;5;28mzip\u001b[39m(*fold_coefs_)\n\u001b[32m   1410\u001b[39m \u001b[38;5;28mself\u001b[39m.n_iter_ = np.asarray(n_iter_, dtype=np.int32)[:, \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config), warnings.catch_warnings():\n\u001b[32m    146\u001b[39m     warnings.filters = warning_filters\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:459\u001b[39m, in \u001b[36m_logistic_regression_path\u001b[39m\u001b[34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[39m\n\u001b[32m    455\u001b[39m l2_reg_strength = \u001b[32m1.0\u001b[39m / (C * sw_sum)\n\u001b[32m    456\u001b[39m iprint = [-\u001b[32m1\u001b[39m, \u001b[32m50\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m101\u001b[39m][\n\u001b[32m    457\u001b[39m     np.searchsorted(np.array([\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m]), verbose)\n\u001b[32m    458\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m opt_res = \u001b[43moptimize\u001b[49m\u001b[43m.\u001b[49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mL-BFGS-B\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxiter\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaxls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# default is 20\u001b[39;49;00m\n\u001b[32m    468\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgtol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mftol\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_get_additional_lbfgs_options_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43miprint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    473\u001b[39m n_iter_i = _check_optimize_result(\n\u001b[32m    474\u001b[39m     solver,\n\u001b[32m    475\u001b[39m     opt_res,\n\u001b[32m    476\u001b[39m     max_iter,\n\u001b[32m    477\u001b[39m     extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[32m    478\u001b[39m )\n\u001b[32m    479\u001b[39m w0, loss = opt_res.x, opt_res.fun\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:784\u001b[39m, in \u001b[36mminimize\u001b[39m\u001b[34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[39m\n\u001b[32m    781\u001b[39m     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[32m    782\u001b[39m                              **options)\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33ml-bfgs-b\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     res = \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m meth == \u001b[33m'\u001b[39m\u001b[33mtnc\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    787\u001b[39m     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n\u001b[32m    788\u001b[39m                         **options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:469\u001b[39m, in \u001b[36m_minimize_lbfgsb\u001b[39m\u001b[34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, workers, **unknown_options)\u001b[39m\n\u001b[32m    461\u001b[39m _lbfgsb.setulb(m, x, low_bnd, upper_bnd, nbd, f, g, factr, pgtol, wa,\n\u001b[32m    462\u001b[39m                iwa, task, lsave, isave, dsave, maxls, ln_task)\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m3\u001b[39m:\n\u001b[32m    465\u001b[39m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[32m    466\u001b[39m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[32m    467\u001b[39m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[32m    468\u001b[39m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m469\u001b[39m     f, g = \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m task[\u001b[32m0\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    471\u001b[39m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[32m    472\u001b[39m     n_iterations += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:403\u001b[39m, in \u001b[36mScalarFunction.fun_and_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.array_equal(x, \u001b[38;5;28mself\u001b[39m.x):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_x(x)\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[38;5;28mself\u001b[39m._update_grad()\n\u001b[32m    405\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f, \u001b[38;5;28mself\u001b[39m.g\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:353\u001b[39m, in \u001b[36mScalarFunction._update_fun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    351\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    352\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f_updated:\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m         fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m         \u001b[38;5;28mself\u001b[39m._nfev += \u001b[32m1\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m fx < \u001b[38;5;28mself\u001b[39m._lowest_f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\_lib\\_util.py:590\u001b[39m, in \u001b[36m_ScalarFunctionWrapper.__call__\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    587\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    588\u001b[39m     \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[32m    589\u001b[39m     \u001b[38;5;66;03m# The user of this class might want `x` to remain unchanged.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m     fx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m     \u001b[38;5;28mself\u001b[39m.nfev += \u001b[32m1\u001b[39m\n\u001b[32m    593\u001b[39m     \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:80\u001b[39m, in \u001b[36mMemoizeJac.__call__\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, *args):\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:74\u001b[39m, in \u001b[36mMemoizeJac._compute_if_needed\u001b[39m\u001b[34m(self, x, *args)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.all(x == \u001b[38;5;28mself\u001b[39m.x) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.jac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28mself\u001b[39m.x = np.asarray(x).copy()\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     fg = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mself\u001b[39m.jac = fg[\u001b[32m1\u001b[39m]\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mself\u001b[39m._value = fg[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:316\u001b[39m, in \u001b[36mLinearModelLoss.loss_gradient\u001b[39m\u001b[34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    314\u001b[39m     weights, intercept = \u001b[38;5;28mself\u001b[39m.weight_intercept(coef)\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m loss, grad_pointwise = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbase_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloss_gradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw_prediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m sw_sum = n_samples \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m np.sum(sample_weight)\n\u001b[32m    323\u001b[39m loss = loss.sum() / sw_sum\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bobto\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\_loss\\loss.py:205\u001b[39m, in \u001b[36mBaseLoss.loss_gradient\u001b[39m\u001b[34m(self, y_true, raw_prediction, sample_weight, loss_out, gradient_out, n_threads)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28mself\u001b[39m.closs.loss(\n\u001b[32m    197\u001b[39m         y_true=y_true,\n\u001b[32m    198\u001b[39m         raw_prediction=raw_prediction,\n\u001b[32m   (...)\u001b[39m\u001b[32m    201\u001b[39m         n_threads=n_threads,\n\u001b[32m    202\u001b[39m     )\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_out\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mloss_gradient\u001b[39m(\n\u001b[32m    206\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    207\u001b[39m     y_true,\n\u001b[32m    208\u001b[39m     raw_prediction,\n\u001b[32m    209\u001b[39m     sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    210\u001b[39m     loss_out=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    211\u001b[39m     gradient_out=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    212\u001b[39m     n_threads=\u001b[32m1\u001b[39m,\n\u001b[32m    213\u001b[39m ):\n\u001b[32m    214\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute loss and gradient w.r.t. raw_prediction for each input.\u001b[39;00m\n\u001b[32m    215\u001b[39m \n\u001b[32m    216\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    241\u001b[39m \u001b[33;03m        Element-wise gradients.\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m loss_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 2D GRID SWEEP: window & stride\n",
    "# ===============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Configurazione griglia ----\n",
    "WINDOWS = list(range(10, 601, 10))   # 10..600 step 10 (0 escluso perch√© invalido)\n",
    "STRIDES = list(range(10, 601, 10))\n",
    "PADDING_RUNS = [\"zero\", \"drop_last\"]  # due conti separati\n",
    "N_SPLITS_MAX = 5                      # max fold per GroupKFold\n",
    "\n",
    "# Se vuoi forzare le feature, imposta DATA_COLS (altrimenti usa quelle auto-rilevate in build_windows)\n",
    "# DATA_COLS = ['has_prosthetics'] + [c for c in df_train.columns if c.startswith('joint_')]\n",
    "DATA_COLS = None\n",
    "\n",
    "def _effective_splits(df, n_splits_max=N_SPLITS_MAX):\n",
    "    n_groups = int(df[\"sample_index\"].nunique())\n",
    "    return max(2, min(n_splits_max, n_groups))\n",
    "\n",
    "def run_grid(df, target, padding=\"zero\", data_cols=DATA_COLS, n_splits_max=N_SPLITS_MAX):\n",
    "    \"\"\"Valuta tutte le combinazioni (window, stride) ‚àà WINDOWS√óSTRIDES con il padding richiesto.\n",
    "    Ritorna un DataFrame con mean_macroF1/std per ciascuna coppia.\"\"\"\n",
    "    if \"eval_strategy\" not in globals():\n",
    "        raise RuntimeError(\"Serve eval_strategy()/build_windows(). Esegui prima le celle dell'harness.\")\n",
    "    rows = []\n",
    "    n_splits = _effective_splits(df, n_splits_max)\n",
    "    for w in WINDOWS:\n",
    "        for s in STRIDES:\n",
    "            params = {\"window\": w, \"stride\": s, \"labeling\": \"id\", \"padding\": padding}\n",
    "            if data_cols is not None:\n",
    "                params[\"data_cols\"] = data_cols\n",
    "            try:\n",
    "                scores = eval_strategy(df, target, params, n_splits=n_splits)\n",
    "                rows.append({\"window\": w, \"stride\": s, \"padding\": padding,\n",
    "                             \"mean_macroF1\": float(scores.mean()), \"std\": float(scores.std())})\n",
    "            except Exception as e:\n",
    "                rows.append({\"window\": w, \"stride\": s, \"padding\": padding,\n",
    "                             \"mean_macroF1\": np.nan, \"std\": np.nan, \"error\": str(e)})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ---- Pre-flight check ----\n",
    "needed = [\"df_train\", \"target\", \"build_windows\", \"eval_strategy\"]\n",
    "missing = [n for n in needed if n not in globals()]\n",
    "if missing:\n",
    "    print(\"‚ö†Ô∏è Mancano variabili/funzioni:\", missing)\n",
    "    print(\"Esegui le celle che definiscono df_train/target/build_windows/eval_strategy e riprova.\")\n",
    "else:\n",
    "    # ---- Esecuzione dei due conti separati (padding diverso) ----\n",
    "    all_results = []\n",
    "    for pad in PADDING_RUNS:\n",
    "        print(f\"\\n>>> Running 2D grid with padding = {pad}\")\n",
    "        df_res = run_grid(df_train, target, padding=pad, data_cols=DATA_COLS, n_splits_max=N_SPLITS_MAX)\n",
    "        all_results.append(df_res)\n",
    "        out_csv = f\"grid_window_stride_results_padding_{pad}.csv\"\n",
    "        df_res.to_csv(out_csv, index=False)\n",
    "        # Mostra le migliori 15 combinazioni\n",
    "        try:\n",
    "            top = (df_res.dropna(subset=[\"mean_macroF1\"])  # noqa\n",
    "                          .sort_values(\"mean_macroF1\", ascending=False)\n",
    "                          .head(15))\n",
    "            print(\"Top-15:\") \n",
    "            print(top.to_string(index=False))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # ---- Unione e best complessivo ----\n",
    "    results = pd.concat(all_results, ignore_index=True)\n",
    "    print(\"\\n=== BEST OVERALL (top 20 su entrambi i padding) ===\")\n",
    "    print(results.dropna(subset=[\"mean_macroF1\"])  # noqa\n",
    "                 .sort_values(\"mean_macroF1\", ascending=False)\n",
    "                 .head(20)\n",
    "                 .to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
