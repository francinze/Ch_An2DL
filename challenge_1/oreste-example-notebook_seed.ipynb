{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff2a540e",
   "metadata": {},
   "source": [
    "# **Notebook Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9407c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:12:50.514337Z",
     "iopub.status.busy": "2025-11-17T14:12:50.514089Z",
     "iopub.status.idle": "2025-11-17T14:12:59.440143Z",
     "shell.execute_reply": "2025-11-17T14:12:59.439465Z",
     "shell.execute_reply.started": "2025-11-17T14:12:50.514317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# KAGGLE IMPORTS\n",
    "# Clone repo\n",
    "!git clone https://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@github.com/francinze/Ch1_An2DL.git /kaggle/working/ch1\n",
    "\n",
    "# Install kaggle API\n",
    "!pip install -q kaggle\n",
    "\n",
    "# Configure kaggle.json\n",
    "!mkdir -p /root/.config/kaggle\n",
    "\n",
    "# Copy your kaggle.json there\n",
    "!cp /kaggle/working/ch1/kaggle.json /root/.config/kaggle/\n",
    "\n",
    "# Set correct permissions\n",
    "!chmod 600 /root/.config/kaggle/kaggle.json\n",
    "\n",
    "# Download competition files\n",
    "!kaggle competitions download -c an2dl2526c1 -p /kaggle/working/ch1\n",
    "\n",
    "# Unzip dataset\n",
    "!unzip -o /kaggle/working/ch1/an2dl2526c1.zip -d /kaggle/working/ch1/\n",
    "\n",
    "# Move into the working directory\n",
    "%cd /kaggle/working/ch1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1290150",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:12:59.441916Z",
     "iopub.status.busy": "2025-11-17T14:12:59.441536Z",
     "iopub.status.idle": "2025-11-17T14:13:03.797818Z",
     "shell.execute_reply": "2025-11-17T14:13:03.796990Z",
     "shell.execute_reply.started": "2025-11-17T14:12:59.441893Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SEED CONFIGURATION - Multiple seeds experiment\n",
    "# ============================================================================\n",
    "SEED_LIST = [10742318, 359782, 7, 27, 2010, 2011, 250203, 46006157]  # Lista di seed da testare\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"\\nðŸŽ² Will test {len(SEED_LIST)} different seeds: {SEED_LIST}\")\n",
    "print(f\"   Each seed will be used to train a separate model\")\n",
    "print(f\"   Best model (highest val F1) will be saved\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fb25c2",
   "metadata": {},
   "source": [
    "# **Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1d2772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:03.798784Z",
     "iopub.status.busy": "2025-11-17T14:13:03.798492Z",
     "iopub.status.idle": "2025-11-17T14:13:05.901937Z",
     "shell.execute_reply": "2025-11-17T14:13:05.901294Z",
     "shell.execute_reply.started": "2025-11-17T14:13:03.798768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"pirate_pain_train.csv\")\n",
    "df_test = pd.read_csv(\"pirate_pain_test.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ee1b1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:05.903642Z",
     "iopub.status.busy": "2025-11-17T14:13:05.903333Z",
     "iopub.status.idle": "2025-11-17T14:13:05.911816Z",
     "shell.execute_reply": "2025-11-17T14:13:05.911093Z",
     "shell.execute_reply.started": "2025-11-17T14:13:05.903622Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "target = pd.read_csv(\"pirate_pain_train_labels.csv\")\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5102ca4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:05.912794Z",
     "iopub.status.busy": "2025-11-17T14:13:05.912555Z",
     "iopub.status.idle": "2025-11-17T14:13:05.918096Z",
     "shell.execute_reply": "2025-11-17T14:13:05.917360Z",
     "shell.execute_reply.started": "2025-11-17T14:13:05.912766Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pain_survey_cols = ['pain_survey_1', 'pain_survey_2', 'pain_survey_3', 'pain_survey_4']\n",
    "joint_cols = [f'joint_{str(i).zfill(2)}' for i in range(1, 31)]\n",
    "body_cols = ['n_legs', 'n_eyes', 'n_hands']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb728bb",
   "metadata": {},
   "source": [
    "# **Data Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20a8e7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:05.919147Z",
     "iopub.status.busy": "2025-11-17T14:13:05.918904Z",
     "iopub.status.idle": "2025-11-17T14:13:05.981806Z",
     "shell.execute_reply": "2025-11-17T14:13:05.981232Z",
     "shell.execute_reply.started": "2025-11-17T14:13:05.919123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974e08ea",
   "metadata": {},
   "source": [
    "## **Body columns**\n",
    "Investigate the body columns in the dataset. Use pandas to load the dataset and display the first few rows to understand its structure.\n",
    "\n",
    "We will see how correlated these columns are between themselves, and with respect to the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6310da2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:05.982669Z",
     "iopub.status.busy": "2025-11-17T14:13:05.982442Z",
     "iopub.status.idle": "2025-11-17T14:13:06.303655Z",
     "shell.execute_reply": "2025-11-17T14:13:06.302981Z",
     "shell.execute_reply.started": "2025-11-17T14:13:05.982646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create encoded versions for correlation analysis\n",
    "for col in body_cols:\n",
    "    df[f'{col}_encoded'] = (df[col] == 'two').astype(int)\n",
    "    df_test[f'{col}_encoded'] = (df_test[col] == 'two').astype(int)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_features = [f'{col}_encoded' for col in body_cols]\n",
    "corr_matrix = df[correlation_features].corr()\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.4f', cmap='coolwarm', \n",
    "            square=True, vmin=0, vmax=1, cbar_kws={'label': 'Correlation'})\n",
    "plt.title('Correlation Matrix: n_legs, n_hands, n_eyes', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(3), body_cols, rotation=45)\n",
    "plt.yticks(range(3), body_cols, rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print correlation values\n",
    "print(\"Correlation Matrix:\")\n",
    "print(\"=\" * 50)\n",
    "corr_matrix.index = body_cols\n",
    "corr_matrix.columns = body_cols\n",
    "print(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8be2f8",
   "metadata": {},
   "source": [
    "### Result: Perfect correlation (1.0) detected!\n",
    "These three features are 100% identical. It means that there is a perfect correspondence between their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a682cff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:06.304598Z",
     "iopub.status.busy": "2025-11-17T14:13:06.304380Z",
     "iopub.status.idle": "2025-11-17T14:13:06.370842Z",
     "shell.execute_reply": "2025-11-17T14:13:06.370225Z",
     "shell.execute_reply.started": "2025-11-17T14:13:06.304581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Verify that all three features always have the same value\n",
    "print(\"Verifying redundancy...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show unique combinations\n",
    "print(\"Unique combinations in the data:\")\n",
    "print(\"=\" * 60)\n",
    "unique_combos = df[body_cols].drop_duplicates()\n",
    "for idx, row in unique_combos.iterrows():\n",
    "    count = ((df['n_legs'] == row['n_legs']) & \n",
    "             (df['n_hands'] == row['n_hands']) & \n",
    "             (df['n_eyes'] == row['n_eyes'])).sum()\n",
    "    print(f\"  {row['n_legs']:15s} | {row['n_hands']:15s} | {row['n_eyes']:15s} â†’ {count:,} samples\")\n",
    "\n",
    "print(\"\\nConclusion: Only 2 combinations exist (all natural OR all prosthetic) â†’ Safe to consolidate into a single binary feature!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0209b8d",
   "metadata": {},
   "source": [
    "## **Pain Surveys**\n",
    "Instead we see here the pain survey columns, and we investigate their values and correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6eeebe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:06.371819Z",
     "iopub.status.busy": "2025-11-17T14:13:06.371553Z",
     "iopub.status.idle": "2025-11-17T14:13:06.969807Z",
     "shell.execute_reply": "2025-11-17T14:13:06.969166Z",
     "shell.execute_reply.started": "2025-11-17T14:13:06.371795Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(pain_survey_cols):\n",
    "    ax = axes[i]\n",
    "\n",
    "    # percentages\n",
    "    train_pct = df[col].value_counts(normalize=True).mul(100)\n",
    "    test_pct = df_test[col].value_counts(normalize=True).mul(100)\n",
    "\n",
    "    # ensure same levels and sorted order\n",
    "    levels = sorted(set(train_pct.index).union(set(test_pct.index)))\n",
    "    train_pct = train_pct.reindex(levels, fill_value=0)\n",
    "    test_pct = test_pct.reindex(levels, fill_value=0)\n",
    "\n",
    "    # prepare long dataframe for seaborn\n",
    "    plot_df = pd.DataFrame({\n",
    "        'Pain Level': levels,\n",
    "        'Train': train_pct.values,\n",
    "        'Test': test_pct.values\n",
    "    }).melt(id_vars='Pain Level', var_name='Dataset', value_name='percentage')\n",
    "\n",
    "    sns.barplot(x='Pain Level', y='percentage', hue='Dataset', data=plot_df, ax=ax, palette='viridis')\n",
    "    ax.set_title(f'{col} - Train vs Test')\n",
    "    ax.set_xlabel('Pain Level')\n",
    "    ax.set_ylabel('Percentage (%)')\n",
    "    ax.set_ylim(0, 100)\n",
    "\n",
    "    # keep legend only on the first subplot\n",
    "    try:\n",
    "        if i == 0:\n",
    "            ax.legend(title='Dataset')\n",
    "        else:\n",
    "            ax.get_legend().remove()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "fig.suptitle('Percentage Distribution of Pain Surveys: Train vs Test', fontsize=16)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45288f55",
   "metadata": {},
   "source": [
    "No significant difference in distribution for the surveys, both between the train and test sets, and between the different survey types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ad141b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:06.972333Z",
     "iopub.status.busy": "2025-11-17T14:13:06.971979Z",
     "iopub.status.idle": "2025-11-17T14:13:07.507236Z",
     "shell.execute_reply": "2025-11-17T14:13:07.506571Z",
     "shell.execute_reply.started": "2025-11-17T14:13:06.972317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Calculate the Pearson correlation matrix for the pain_survey_cols in df\n",
    "corr_matrix_train = df[pain_survey_cols].corr(method='pearson')\n",
    "\n",
    "# 2. Calculate the Pearson correlation matrix for the pain_survey_cols in df_test\n",
    "corr_matrix_test = df_test[pain_survey_cols].corr(method='pearson')\n",
    "\n",
    "# 3. Create a figure with two subplots for heatmaps\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "fig.suptitle('Inter-correlation of Pain Survey Columns (Train vs. Test)', fontsize=18)\n",
    "\n",
    "# Heatmap for Training Data\n",
    "sns.heatmap(corr_matrix_train, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, ax=axes[0])\n",
    "axes[0].set_title('Pain Survey Correlation Matrix - Train Data', fontsize=14)\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].tick_params(axis='y', rotation=0)\n",
    "\n",
    "# Heatmap for Testing Data\n",
    "sns.heatmap(corr_matrix_test, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, ax=axes[1])\n",
    "axes[1].set_title('Pain Survey Correlation Matrix - Test Data', fontsize=14)\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].tick_params(axis='y', rotation=0)\n",
    "\n",
    "# Adjust the layout to prevent overlapping titles and display the plot\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust rect to make space for suptitle\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89983a4",
   "metadata": {},
   "source": [
    "The surveys do not appear to be correlated with each other. Maximal correlation is about 0.06 between \"pain_survey_1\" and \"pain_survey_3\", which is very low and can be considered negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3109c0e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:07.508430Z",
     "iopub.status.busy": "2025-11-17T14:13:07.508034Z",
     "iopub.status.idle": "2025-11-17T14:13:07.651442Z",
     "shell.execute_reply": "2025-11-17T14:13:07.650776Z",
     "shell.execute_reply.started": "2025-11-17T14:13:07.508381Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "df_merged = pd.merge(df, target, on='sample_index', how='left')\n",
    "\n",
    "print(\"Performing ANOVA for each pain_survey column against 'label' in df_merged:\")\n",
    "for pain_col in pain_survey_cols:\n",
    "    print(f\"\\n--- ANOVA for {pain_col} vs. label ---\")\n",
    "    # Get unique labels\n",
    "    labels = df_merged['label'].unique()\n",
    "\n",
    "    # Prepare data for ANOVA: a list of arrays, each array containing pain_col values for a specific label\n",
    "    data_for_anova = [df_merged[pain_col][df_merged['label'] == label].values for label in labels]\n",
    "\n",
    "    # Perform ANOVA test\n",
    "    f_statistic, p_value = f_oneway(*data_for_anova)\n",
    "\n",
    "    print(f\"F-statistic: {f_statistic:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "    # Interpret the p-value\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(f\"Conclusion: Since p-value ({p_value:.4f}) < alpha ({alpha}), we reject the null hypothesis. There is a statistically significant difference in {pain_col} means across different pain labels.\")\n",
    "    else:\n",
    "        print(f\"Conclusion: Since p-value ({p_value:.4f}) >= alpha ({alpha}), we fail to reject the null hypothesis. There is no statistically significant difference in {pain_col} means across different pain labels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d372a",
   "metadata": {},
   "source": [
    "ANOVA tests also confirm that all 4 survey columns have minimal p-values, they are all statistically significant towards the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a4c42",
   "metadata": {},
   "source": [
    "## Mapping pain target variable to numerical classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e33d1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:07.652934Z",
     "iopub.status.busy": "2025-11-17T14:13:07.652133Z",
     "iopub.status.idle": "2025-11-17T14:13:07.678533Z",
     "shell.execute_reply": "2025-11-17T14:13:07.677945Z",
     "shell.execute_reply.started": "2025-11-17T14:13:07.652908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "unique_labels = df_merged['label'].unique()\n",
    "print(f\"Unique pain labels: {unique_labels}\")\n",
    "pain_label_mapping = {\n",
    "    'no_pain': 0,\n",
    "    'low_pain': 1,\n",
    "    'high_pain': 2\n",
    "}\n",
    "df_merged['pain_level'] = df_merged['label'].map(pain_label_mapping)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95773c60",
   "metadata": {},
   "source": [
    "## **Joint Columns**\n",
    "Then we analyze the joint columns in the dataset, and their correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f0654a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:07.679373Z",
     "iopub.status.busy": "2025-11-17T14:13:07.679132Z",
     "iopub.status.idle": "2025-11-17T14:13:08.143099Z",
     "shell.execute_reply": "2025-11-17T14:13:08.142325Z",
     "shell.execute_reply.started": "2025-11-17T14:13:07.679357Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "anova_results = {}\n",
    "\n",
    "for col in joint_cols:\n",
    "    # Group data by pain level\n",
    "    group0 = df_merged[df_merged['pain_level'] == 0][col]\n",
    "    group1 = df_merged[df_merged['pain_level'] == 1][col]\n",
    "    group2 = df_merged[df_merged['pain_level'] == 2][col]\n",
    "\n",
    "    # Perform ANOVA test\n",
    "    # Ensure all groups have data to avoid errors\n",
    "    if len(group0) > 1 and len(group1) > 1 and len(group2) > 1:\n",
    "        f_statistic, p_value = f_oneway(group0, group1, group2)\n",
    "        anova_results[col] = p_value\n",
    "    else:\n",
    "        anova_results[col] = float('nan') # Assign NaN if a group is too small for ANOVA\n",
    "\n",
    "# Sort results by p-value for easier interpretation\n",
    "sorted_anova_results = sorted(anova_results.items(), key=lambda x: x[1])\n",
    "\n",
    "print(\"ANOVA p-values for joint columns (sorted by significance):\")\n",
    "for col, p_val in sorted_anova_results:\n",
    "    print(f\"  {col}: {p_val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bdf7cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:08.144576Z",
     "iopub.status.busy": "2025-11-17T14:13:08.144001Z",
     "iopub.status.idle": "2025-11-17T14:13:08.847916Z",
     "shell.execute_reply": "2025-11-17T14:13:08.847303Z",
     "shell.execute_reply.started": "2025-11-17T14:13:08.144550Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "joint_data_train = df[joint_cols]\n",
    "correlation_matrix_train = joint_data_train.corr()\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(correlation_matrix_train, annot=False, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of Joint Columns in df')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a7d40",
   "metadata": {},
   "source": [
    "The correlation matrix shows that several joint columns are highly correlated with each other. For example, \"joint_10\" and \"joint_11\" have a correlation of >0.9, indicating a strong linear relationship between these two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322bdaa2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:08.848862Z",
     "iopub.status.busy": "2025-11-17T14:13:08.848609Z",
     "iopub.status.idle": "2025-11-17T14:13:09.828313Z",
     "shell.execute_reply": "2025-11-17T14:13:09.827699Z",
     "shell.execute_reply.started": "2025-11-17T14:13:08.848837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "joint_data_test = df_test[joint_cols]\n",
    "correlation_matrix_test = joint_data_test.corr()\n",
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(correlation_matrix_test, annot=False, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Matrix of Joint Columns in df_test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e57f634",
   "metadata": {},
   "source": [
    "Again, no significant difference between train and test sets. The same correlation we saw in the train set is also present in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d731c119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:09.829359Z",
     "iopub.status.busy": "2025-11-17T14:13:09.829093Z",
     "iopub.status.idle": "2025-11-17T14:13:10.394281Z",
     "shell.execute_reply": "2025-11-17T14:13:10.393693Z",
     "shell.execute_reply.started": "2025-11-17T14:13:09.829334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Statistical Descriptions for Joint Columns in df:\")\n",
    "display(df[joint_cols].describe())\n",
    "print(\"Statistical Descriptions for Joint Columns in df_test:\")\n",
    "display(df_test[joint_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc12ede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:10.395269Z",
     "iopub.status.busy": "2025-11-17T14:13:10.395047Z",
     "iopub.status.idle": "2025-11-17T14:13:11.815435Z",
     "shell.execute_reply": "2025-11-17T14:13:11.814691Z",
     "shell.execute_reply.started": "2025-11-17T14:13:10.395252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set style for attractive visualizations\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "\n",
    "# Calculate outliers using IQR method for each joint column\n",
    "outlier_stats = []\n",
    "for col in joint_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
    "    outlier_count = len(outliers)\n",
    "    outlier_pct = (outlier_count / len(df)) * 100\n",
    "    \n",
    "    outlier_stats.append({\n",
    "        'joint': col,\n",
    "        'count': outlier_count,\n",
    "        'percentage': outlier_pct,\n",
    "        'lower_bound': lower_bound,\n",
    "        'upper_bound': upper_bound\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_stats)\n",
    "\n",
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = fig.add_gridspec(3, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Bar chart of outlier percentages\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "colors = plt.cm.RdYlGn_r(outlier_df['percentage'] / outlier_df['percentage'].max())\n",
    "bars = ax1.bar(range(len(outlier_df)), outlier_df['percentage'], color=colors, edgecolor='black', linewidth=0.5)\n",
    "ax1.set_xlabel('Joint Column', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Outlier Percentage (%)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Percentage of Outliers per Joint Column (IQR Method)', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(range(len(outlier_df)))\n",
    "ax1.set_xticklabels(outlier_df['joint'], rotation=45, ha='right')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for i, (bar, pct) in enumerate(zip(bars, outlier_df['percentage'])):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{pct:.1f}%', ha='center', va='bottom', fontsize=7)\n",
    "\n",
    "# 2. Box plots for top 15 joints with most outliers\n",
    "ax2 = fig.add_subplot(gs[1, :])\n",
    "top_outliers = outlier_df.nlargest(15, 'percentage')['joint'].tolist()\n",
    "box_data = [df[col].values for col in top_outliers]\n",
    "\n",
    "bp = ax2.boxplot(box_data, labels=top_outliers, patch_artist=True, \n",
    "                  flierprops=dict(marker='o', markerfacecolor='red', markersize=2, alpha=0.3))\n",
    "\n",
    "for patch, col in zip(bp['boxes'], top_outliers):\n",
    "    patch.set_facecolor(plt.cm.viridis(top_outliers.index(col) / len(top_outliers)))\n",
    "\n",
    "ax2.set_xlabel('Joint Column', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Value', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Box Plot: Top 15 Joints with Most Outliers', fontsize=14, fontweight='bold')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Heatmap of outlier counts\n",
    "ax3 = fig.add_subplot(gs[2, 0])\n",
    "outlier_matrix = outlier_df['percentage'].values.reshape(5, 6)  # 30 joints in 5x6 grid\n",
    "im = ax3.imshow(outlier_matrix, cmap='YlOrRd', aspect='auto')\n",
    "ax3.set_xticks(range(6))\n",
    "ax3.set_yticks(range(5))\n",
    "ax3.set_xticklabels([f'Col {i+1}' for i in range(6)])\n",
    "ax3.set_yticklabels([f'Row {i+1}' for i in range(5)])\n",
    "ax3.set_title('Outlier Heatmap (% by Position)', fontsize=13, fontweight='bold')\n",
    "\n",
    "# Add values to heatmap\n",
    "for i in range(5):\n",
    "    for j in range(6):\n",
    "        idx = i * 6 + j\n",
    "        if idx < len(outlier_df):\n",
    "            text = ax3.text(j, i, f'{outlier_matrix[i, j]:.1f}%',\n",
    "                           ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "\n",
    "plt.colorbar(im, ax=ax3, label='Outlier %')\n",
    "\n",
    "# 4. Summary statistics table\n",
    "ax4 = fig.add_subplot(gs[2, 1])\n",
    "ax4.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘          OUTLIER SUMMARY STATISTICS          â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘  Total Joints Analyzed:        {len(outlier_df):>12}  â•‘\n",
    "â•‘  Total Data Points:            {len(df):>12,}  â•‘\n",
    "â•‘                                              â•‘\n",
    "â•‘  Avg Outliers per Joint:       {outlier_df['percentage'].mean():>11.2f}%  â•‘\n",
    "â•‘  Max Outliers (joint):         {outlier_df['percentage'].max():>11.2f}%  â•‘\n",
    "â•‘  Min Outliers (joint):         {outlier_df['percentage'].min():>11.2f}%  â•‘\n",
    "â•‘                                              â•‘\n",
    "â•‘  Joint with Most Outliers:                   â•‘\n",
    "â•‘    {outlier_df.loc[outlier_df['percentage'].idxmax(), 'joint']:>12} ({outlier_df['percentage'].max():.2f}%)   â•‘\n",
    "â•‘                                              â•‘\n",
    "â•‘  Joint with Least Outliers:                  â•‘\n",
    "â•‘    {outlier_df.loc[outlier_df['percentage'].idxmin(), 'joint']:>12} ({outlier_df['percentage'].min():.2f}%)   â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "ax4.text(0.5, 0.5, summary_text, \n",
    "         fontsize=10, \n",
    "         family='monospace',\n",
    "         ha='center', \n",
    "         va='center',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "plt.suptitle('Joint Columns Outlier Analysis', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETAILED OUTLIER STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "print(outlier_df.sort_values('percentage', ascending=False).to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f70ccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:11.816581Z",
     "iopub.status.busy": "2025-11-17T14:13:11.816290Z",
     "iopub.status.idle": "2025-11-17T14:13:16.011416Z",
     "shell.execute_reply": "2025-11-17T14:13:16.010657Z",
     "shell.execute_reply.started": "2025-11-17T14:13:11.816558Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Analyze each joint column for extreme anomalies\n",
    "anomaly_report = []\n",
    "\n",
    "for col in joint_cols:\n",
    "    data = df[col]\n",
    "    \n",
    "    # Calculate percentiles to understand typical range\n",
    "    p01 = data.quantile(0.01)\n",
    "    p50 = data.quantile(0.50)  # median\n",
    "    p99 = data.quantile(0.99)\n",
    "    \n",
    "    # Calculate mean and std of the bulk of the data (1st-99th percentile)\n",
    "    bulk_data = data[(data >= p01) & (data <= p99)]\n",
    "    bulk_mean = bulk_data.mean()\n",
    "    bulk_std = bulk_data.std()\n",
    "    \n",
    "    # Find values that are way outside the typical range\n",
    "    # Using 10 standard deviations as threshold for extreme anomalies\n",
    "    threshold = 10\n",
    "    extreme_low = bulk_mean - threshold * bulk_std\n",
    "    extreme_high = bulk_mean + threshold * bulk_std\n",
    "    \n",
    "    anomalies = data[(data < extreme_low) | (data > extreme_high)]\n",
    "    \n",
    "    # Also check for magnitude differences (e.g., 0.8 among 1e-05 values)\n",
    "    # If median is very small, check for values that are orders of magnitude larger\n",
    "    if p50 < 0.01:  # Column has very small values\n",
    "        magnitude_threshold = p50 * 100  # Values 100x larger than median\n",
    "        magnitude_anomalies = data[data > magnitude_threshold]\n",
    "    else:\n",
    "        magnitude_anomalies = pd.Series(dtype=float)\n",
    "    \n",
    "    anomaly_report.append({\n",
    "        'joint': col,\n",
    "        'median': p50,\n",
    "        'p01': p01,\n",
    "        'p99': p99,\n",
    "        'bulk_mean': bulk_mean,\n",
    "        'bulk_std': bulk_std,\n",
    "        'extreme_anomalies': len(anomalies),\n",
    "        'magnitude_anomalies': len(magnitude_anomalies),\n",
    "        'total_anomalies': len(set(anomalies.index) | set(magnitude_anomalies.index)),\n",
    "        'anomaly_pct': (len(set(anomalies.index) | set(magnitude_anomalies.index)) / len(data)) * 100,\n",
    "        'min_val': data.min(),\n",
    "        'max_val': data.max()\n",
    "    })\n",
    "\n",
    "anomaly_df = pd.DataFrame(anomaly_report)\n",
    "\n",
    "# Display joints with significant anomalies\n",
    "print(\"=\"*100)\n",
    "print(\"EXTREME ANOMALY DETECTION IN JOINT COLUMNS\")\n",
    "print(\"=\"*100)\n",
    "print(\"\\nJoints with extreme out-of-range values (sorted by anomaly percentage):\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "significant_anomalies = anomaly_df[anomaly_df['total_anomalies'] > 0].sort_values('anomaly_pct', ascending=False)\n",
    "\n",
    "for _, row in significant_anomalies.iterrows():\n",
    "    print(f\"\\n{row['joint']}:\")\n",
    "    print(f\"  Median: {row['median']:.6e}  |  Range: [{row['min_val']:.6e}, {row['max_val']:.6e}]\")\n",
    "    print(f\"  Bulk meanÂ±std: {row['bulk_mean']:.6e} Â± {row['bulk_std']:.6e}\")\n",
    "    print(f\"  Extreme anomalies: {row['extreme_anomalies']:,} ({row['anomaly_pct']:.2f}%)\")\n",
    "    print(f\"  Magnitude anomalies: {row['magnitude_anomalies']:,}\")\n",
    "    \n",
    "    # Show example anomalous values\n",
    "    col = row['joint']\n",
    "    data = df[col]\n",
    "    bulk_mean = row['bulk_mean']\n",
    "    bulk_std = row['bulk_std']\n",
    "    extreme_vals = data[(data < bulk_mean - 10*bulk_std) | (data > bulk_mean + 10*bulk_std)]\n",
    "    \n",
    "    if len(extreme_vals) > 0:\n",
    "        print(f\"  Example anomalous values: {extreme_vals.head(5).values}\")\n",
    "\n",
    "# Visualize the most anomalous columns\n",
    "top_anomalous = significant_anomalies.head(6)['joint'].tolist()\n",
    "\n",
    "if len(top_anomalous) > 0:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(top_anomalous):\n",
    "        if i >= 6:\n",
    "            break\n",
    "        ax = axes[i]\n",
    "        \n",
    "        data = df[col]\n",
    "        row = anomaly_df[anomaly_df['joint'] == col].iloc[0]\n",
    "        \n",
    "        # Create histogram with log scale if needed\n",
    "        ax.hist(data, bins=100, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "        ax.axvline(row['median'], color='red', linestyle='--', linewidth=2, label=f'Median: {row[\"median\"]:.2e}')\n",
    "        ax.axvline(row['bulk_mean'], color='green', linestyle='--', linewidth=2, label=f'Mean: {row[\"bulk_mean\"]:.2e}')\n",
    "        \n",
    "        ax.set_title(f'{col}\\nAnomalies: {row[\"total_anomalies\"]:,} ({row[\"anomaly_pct\"]:.2f}%)', \n",
    "                     fontweight='bold', fontsize=11)\n",
    "        ax.set_xlabel('Value', fontsize=9)\n",
    "        ax.set_ylabel('Frequency', fontsize=9)\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.grid(alpha=0.3)\n",
    "        \n",
    "        # Use log scale for y-axis if there's high variance\n",
    "        if data.max() / data.median() > 100:\n",
    "            ax.set_yscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('Distribution of Joints with Extreme Anomalies', fontsize=14, fontweight='bold', y=1.00)\n",
    "    plt.subplots_adjust(top=0.96)\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(f\"Joints with no anomalies: {len(anomaly_df[anomaly_df['total_anomalies'] == 0])}\")\n",
    "print(f\"Joints with anomalies: {len(anomaly_df[anomaly_df['total_anomalies'] > 0])}\")\n",
    "print(f\"Most anomalous joint: {anomaly_df.loc[anomaly_df['anomaly_pct'].idxmax(), 'joint']} \"\n",
    "      f\"({anomaly_df['anomaly_pct'].max():.2f}% anomalies)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a2f9b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:16.012368Z",
     "iopub.status.busy": "2025-11-17T14:13:16.012173Z",
     "iopub.status.idle": "2025-11-17T14:13:58.686831Z",
     "shell.execute_reply": "2025-11-17T14:13:58.685954Z",
     "shell.execute_reply.started": "2025-11-17T14:13:16.012354Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(5, 6, figsize=(24, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(joint_cols):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot KDE for train and test\n",
    "    sns.kdeplot(df[col], label='Train', fill=True, alpha=0.5, ax=ax, color='blue')\n",
    "    sns.kdeplot(df_test[col], label='Test', fill=True, alpha=0.5, ax=ax, color='orange')\n",
    "    \n",
    "    ax.set_title(f'{col}', fontsize=10, fontweight='bold')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Density', fontsize=8)\n",
    "    \n",
    "    # Add legend only to the first subplot\n",
    "    if i == 0:\n",
    "        ax.legend(loc='upper right', fontsize=8)\n",
    "    \n",
    "    # Determine x-axis limits based on data range\n",
    "    combined_data = pd.concat([df[col], df_test[col]])\n",
    "    \n",
    "    # Use percentiles to handle outliers\n",
    "    p1 = combined_data.quantile(0.01)\n",
    "    p99 = combined_data.quantile(0.99)\n",
    "    \n",
    "    data_min = combined_data.min()\n",
    "    data_max = combined_data.max()\n",
    "    \n",
    "    # Calculate range\n",
    "    data_range = p99 - p1\n",
    "    \n",
    "    if data_range > 0:\n",
    "        # Add 10% padding to the percentile range\n",
    "        padding = data_range * 0.1\n",
    "        lower_lim = max(p1 - padding, data_min)\n",
    "        upper_lim = min(p99 + padding, data_max)\n",
    "    else:\n",
    "        # If all values are the same, create a small range around the value\n",
    "        if data_min == 0:\n",
    "            lower_lim = -1e-8\n",
    "            upper_lim = 1e-8\n",
    "        else:\n",
    "            abs_val = abs(data_min)\n",
    "            lower_lim = data_min - abs_val * 0.1\n",
    "            upper_lim = data_min + abs_val * 0.1\n",
    "    \n",
    "    # Ensure lower limit doesn't go negative if all data is non-negative\n",
    "    if data_min >= 0 and lower_lim < 0:\n",
    "        lower_lim = 0\n",
    "    \n",
    "    ax.set_xlim(lower_lim, upper_lim)\n",
    "    ax.tick_params(axis='both', labelsize=8)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Distribution of Joint Columns: Train vs Test', fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.subplots_adjust(top=0.98)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d186c5",
   "metadata": {},
   "source": [
    "## **Time Column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34526e07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:13:58.687925Z",
     "iopub.status.busy": "2025-11-17T14:13:58.687691Z",
     "iopub.status.idle": "2025-11-17T14:14:00.441509Z",
     "shell.execute_reply": "2025-11-17T14:14:00.440815Z",
     "shell.execute_reply.started": "2025-11-17T14:13:58.687908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nCreating time-based features from 'time' column\")\n",
    "\n",
    "# Feature 1: Normalized time (position in sequence: 0.0 to 1.0)\n",
    "print(\"\\n1. Normalized Time (relative position in sequence)\")\n",
    "df['time_normalized'] = df.groupby('sample_index')['time'].transform(\n",
    "    lambda x: x / x.max() if x.max() > 0 else 0\n",
    ")\n",
    "df_test['time_normalized'] = df_test.groupby('sample_index')['time'].transform(\n",
    "    lambda x: x / x.max() if x.max() > 0 else 0\n",
    ")\n",
    "\n",
    "# Analyze sequence lengths to determine cyclical period\n",
    "train_lengths = df.groupby('sample_index')['time'].max()\n",
    "test_lengths = df_test.groupby('sample_index')['time'].max()\n",
    "avg_length = train_lengths.mean()\n",
    "\n",
    "print(f\"   - Average sequence length: {avg_length:.1f} timesteps\")\n",
    "print(f\"   - Train range: {train_lengths.min():.0f} to {train_lengths.max():.0f}\")\n",
    "print(f\"   - Test range: {test_lengths.min():.0f} to {test_lengths.max():.0f}\")\n",
    "\n",
    "# Feature 2: Cyclical encoding (captures periodic patterns)\n",
    "# Use a period based on average sequence length for meaningful cycles\n",
    "period = max(50, avg_length / 3)  # Create ~3 cycles per sequence\n",
    "print(f\"\\n2. Cyclical Encoding (period={period:.1f} timesteps)\")\n",
    "print(f\"   - Captures repeating patterns within sequences\")\n",
    "\n",
    "df['time_sin'] = np.sin(2 * np.pi * df['time'] / period)\n",
    "df['time_cos'] = np.cos(2 * np.pi * df['time'] / period)\n",
    "df_test['time_sin'] = np.sin(2 * np.pi * df_test['time'] / period)\n",
    "df_test['time_cos'] = np.cos(2 * np.pi * df_test['time'] / period)\n",
    "\n",
    "# Feature 3: Time position categories (early/mid/late)\n",
    "print(\"\\n3. Time Position Category (early/mid/late in sequence)\")\n",
    "\n",
    "def categorize_time_position(group):\n",
    "    normalized = group / group.max() if group.max() > 0 else 0\n",
    "    return pd.cut(normalized, bins=[0, 0.33, 0.66, 1.0], \n",
    "                    labels=[0, 1, 2], include_lowest=True).astype(int)\n",
    "\n",
    "df['time_position'] = df.groupby('sample_index')['time'].transform(categorize_time_position)\n",
    "df_test['time_position'] = df_test.groupby('sample_index')['time'].transform(categorize_time_position)\n",
    "\n",
    "print(\"   - 0: Early (0-33% of sequence)\")\n",
    "print(\"   - 1: Mid (33-66% of sequence)\")\n",
    "print(\"   - 2: Late (66-100% of sequence)\")\n",
    "\n",
    "# Show distribution of time position categories\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Distribution of time position categories:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nTraining set:\")\n",
    "train_dist = df['time_position'].value_counts().sort_index()\n",
    "for value, count in train_dist.items():\n",
    "    label = ['Early', 'Mid', 'Late'][value]\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"  {value} ({label:5s}): {count:6,} samples ({pct:.2f}%)\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "test_dist = df_test['time_position'].value_counts().sort_index()\n",
    "for value, count in test_dist.items():\n",
    "    label = ['Early', 'Mid', 'Late'][value]\n",
    "    pct = (count / len(df_test)) * 100\n",
    "    print(f\"  {value} ({label:5s}): {count:6,} samples ({pct:.2f}%)\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Summary: Created 4 new time features\")\n",
    "print(\" time_normalized: Continuous [0.0, 1.0] - position in sequence\")\n",
    "print(\" time_sin: Continuous [-1.0, 1.0] - cyclical encoding\")\n",
    "print(\" time_cos: Continuous [-1.0, 1.0] - cyclical encoding\")\n",
    "print(\" time_position: Categorical [0, 1, 2] - early/mid/late (for embeddings)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3273a43b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:00.442604Z",
     "iopub.status.busy": "2025-11-17T14:14:00.442309Z",
     "iopub.status.idle": "2025-11-17T14:14:01.520081Z",
     "shell.execute_reply": "2025-11-17T14:14:01.519322Z",
     "shell.execute_reply.started": "2025-11-17T14:14:00.442574Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualize time features for a single pirate\n",
    "pirate_id = 0\n",
    "pirate_data = df[df['sample_index'] == pirate_id]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Normalized time progression\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(pirate_data['time'], pirate_data['time_normalized'], 'b-', linewidth=2)\n",
    "ax1.set_xlabel('Time (timestep)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Normalized Time', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Time Normalization: Linear Progression', fontsize=13, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "\n",
    "# Plot 2: Cyclical encoding (sin/cos)\n",
    "ax2 = axes[0, 1]\n",
    "ax2.plot(pirate_data['time'], pirate_data['time_sin'], 'r-', linewidth=2, label='sin(time)', alpha=0.7)\n",
    "ax2.plot(pirate_data['time'], pirate_data['time_cos'], 'b-', linewidth=2, label='cos(time)', alpha=0.7)\n",
    "ax2.set_xlabel('Time (timestep)', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Cyclical Value', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Cyclical Encoding: Captures Periodic Patterns', fontsize=13, fontweight='bold')\n",
    "ax2.legend(loc='upper right', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(-1.2, 1.2)\n",
    "\n",
    "# Plot 3: Time position categories\n",
    "ax3 = axes[1, 0]\n",
    "time_pos_counts = pirate_data['time_position'].value_counts().sort_index()\n",
    "colors = ['#2ecc71', '#f39c12', '#e74c3c']  # Green, Orange, Red\n",
    "ax3.bar(time_pos_counts.index, time_pos_counts.values, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax3.set_xlabel('Time Position Category', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "ax3.set_title('Time Position: Early/Mid/Late Distribution', fontsize=13, fontweight='bold')\n",
    "ax3.set_xticks([0, 1, 2])\n",
    "ax3.set_xticklabels(['Early\\n(0-33%)', 'Mid\\n(33-66%)', 'Late\\n(66-100%)'], fontsize=10)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Cyclical encoding in 2D space (phase diagram)\n",
    "ax4 = axes[1, 1]\n",
    "scatter = ax4.scatter(pirate_data['time_cos'], pirate_data['time_sin'], \n",
    "                     c=pirate_data['time'], cmap='viridis', s=50, alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "ax4.set_xlabel('cos(time)', fontsize=12, fontweight='bold')\n",
    "ax4.set_ylabel('sin(time)', fontsize=12, fontweight='bold')\n",
    "ax4.set_title('Cyclical Encoding: 2D Phase Space', fontsize=13, fontweight='bold')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.set_xlim(-1.2, 1.2)\n",
    "ax4.set_ylim(-1.2, 1.2)\n",
    "ax4.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "ax4.axvline(x=0, color='k', linestyle='--', alpha=0.3)\n",
    "cbar = plt.colorbar(scatter, ax=ax4)\n",
    "cbar.set_label('Timestep', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'Time Feature Visualization (Pirate {pirate_id})', fontsize=15, fontweight='bold', y=1.00)\n",
    "plt.subplots_adjust(top=0.96)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Time feature summary for pirate {pirate_id}:\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total timesteps: {len(pirate_data)}\")\n",
    "print(f\"Time range: {pirate_data['time'].min():.0f} to {pirate_data['time'].max():.0f}\")\n",
    "print(f\"Normalized range: {pirate_data['time_normalized'].min():.3f} to {pirate_data['time_normalized'].max():.3f}\")\n",
    "print(f\"Time position distribution: {time_pos_counts.to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1af7fc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:01.520991Z",
     "iopub.status.busy": "2025-11-17T14:14:01.520811Z",
     "iopub.status.idle": "2025-11-17T14:14:01.640203Z",
     "shell.execute_reply": "2025-11-17T14:14:01.639440Z",
     "shell.execute_reply.started": "2025-11-17T14:14:01.520977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Analyze correlation between time features and pain labels\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Merge with labels\n",
    "df = pd.merge(df, target, on='sample_index', how='left')\n",
    "\n",
    "# Map labels to integers\n",
    "pain_label_mapping = {'no_pain': 0, 'low_pain': 1, 'high_pain': 2}\n",
    "df['pain_level'] = df['label'].map(pain_label_mapping)\n",
    "# Perform ANOVA for each time feature\n",
    "time_feature_cols = ['time_normalized', 'time_sin', 'time_cos', 'time_position']\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANOVA: Time Features vs Pain Labels\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTesting if time features differ across pain levels (no_pain, low_pain, high_pain)\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for col in time_feature_cols:\n",
    "    group0 = df[df['pain_level'] == 0][col]\n",
    "    group1 = df[df['pain_level'] == 1][col]\n",
    "    group2 = df[df['pain_level'] == 2][col]\n",
    "    \n",
    "    if len(group0) > 1 and len(group1) > 1 and len(group2) > 1:\n",
    "        f_statistic, p_value = f_oneway(group0, group1, group2)\n",
    "        \n",
    "        # Interpret significance\n",
    "        if p_value < 0.001:\n",
    "            significance = \"*** Highly significant\"\n",
    "        elif p_value < 0.01:\n",
    "            significance = \"** Very significant\"\n",
    "        elif p_value < 0.05:\n",
    "            significance = \"* Significant\"\n",
    "        else:\n",
    "            significance = \"Not significant\"\n",
    "        \n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  F-statistic: {f_statistic:.4f}\")\n",
    "        print(f\"  P-value: {p_value:.4f}  {significance}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Interpretation:\")\n",
    "print(\"=\"*70)\n",
    "print(\"p < 0.001: Strong evidence that time feature relates to pain level\")\n",
    "print(\"p < 0.05:  Evidence of relationship (statistically significant)\")\n",
    "print(\"p â‰¥ 0.05:  No clear relationship detected\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da27853",
   "metadata": {},
   "source": [
    "# **Data Preprocessing and Feature Engineering**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409690a",
   "metadata": {},
   "source": [
    "## **Drop Redundant Joint Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19ccf2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:01.641327Z",
     "iopub.status.busy": "2025-11-17T14:14:01.641043Z",
     "iopub.status.idle": "2025-11-17T14:14:01.690105Z",
     "shell.execute_reply": "2025-11-17T14:14:01.689522Z",
     "shell.execute_reply.started": "2025-11-17T14:14:01.641303Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.drop(columns=['joint_30', 'joint_11', 'time'], inplace=True)\n",
    "df_test.drop(columns=['joint_30', 'joint_11', 'time'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60926275",
   "metadata": {},
   "source": [
    "## Unify n_legs, n_arms and n_eyes into single feature 'has_prosthetics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7f7607",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:01.690998Z",
     "iopub.status.busy": "2025-11-17T14:14:01.690816Z",
     "iopub.status.idle": "2025-11-17T14:14:01.761216Z",
     "shell.execute_reply": "2025-11-17T14:14:01.760531Z",
     "shell.execute_reply.started": "2025-11-17T14:14:01.690985Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create the new feature\n",
    "df['has_prosthetics'] = (df['n_legs'] != 'two').astype(int)\n",
    "df_test['has_prosthetics'] = (df_test['n_legs'] != 'two').astype(int)\n",
    "\n",
    "# Show distribution\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Distribution of new feature:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nTraining set:\")\n",
    "train_dist = df['has_prosthetics'].value_counts().sort_index()\n",
    "for value, count in train_dist.items():\n",
    "    label = \"Natural\" if value == 0 else \"Prosthetics\"\n",
    "    pct = (count / len(df)) * 100\n",
    "    print(f\"  {value} ({label:12s}): {count:6,} samples ({pct:.2f}%)\")\n",
    "\n",
    "print(\"\\nTest set:\")\n",
    "test_dist = df_test['has_prosthetics'].value_counts().sort_index()\n",
    "for value, count in test_dist.items():\n",
    "    label = \"Natural\" if value == 0 else \"Prosthetics\"\n",
    "    pct = (count / len(df_test)) * 100\n",
    "    print(f\"  {value} ({label:12s}): {count:6,} samples ({pct:.2f}%)\")\n",
    "\n",
    "\n",
    "# Columns to drop\n",
    "cols_to_drop = ['n_legs', 'n_hands', 'n_eyes', \n",
    "                'n_legs_encoded', 'n_hands_encoded', 'n_eyes_encoded']\n",
    "\n",
    "# Drop from both train and test\n",
    "df = df.drop(columns=[col for col in cols_to_drop if col in df.columns])\n",
    "df_test = df_test.drop(columns=[col for col in cols_to_drop if col in df_test.columns])\n",
    "\n",
    "print(\"\\nFeature created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043794a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:01.762229Z",
     "iopub.status.busy": "2025-11-17T14:14:01.761990Z",
     "iopub.status.idle": "2025-11-17T14:14:01.931924Z",
     "shell.execute_reply": "2025-11-17T14:14:01.931327Z",
     "shell.execute_reply.started": "2025-11-17T14:14:01.762204Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(\"\\nApplying Min-Max normalization to joint columns...\")\n",
    "print(\"=\" * 60)\n",
    "# List of joint columns to normalize\n",
    "joint_cols = [\"joint_\" + str(i).zfill(2) for i in range(30)]\n",
    "joint_cols.remove(\"joint_11\")  # Removed earlier\n",
    "\n",
    "for col in joint_cols:\n",
    "    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Min-Max normalization to the joint columns\n",
    "df[joint_cols] = minmax_scaler.fit_transform(df[joint_cols])\n",
    "\n",
    "# Use the same scaler on test data\n",
    "df_test[joint_cols] = minmax_scaler.transform(df_test[joint_cols])\n",
    "\n",
    "print(f\"Scaler learned from training data - Min: {minmax_scaler.data_min_[:5]}\")\n",
    "print(f\"Scaler learned from training data - Max: {minmax_scaler.data_max_[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549868f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:01.933741Z",
     "iopub.status.busy": "2025-11-17T14:14:01.932751Z",
     "iopub.status.idle": "2025-11-17T14:14:02.124542Z",
     "shell.execute_reply": "2025-11-17T14:14:02.123963Z",
     "shell.execute_reply.started": "2025-11-17T14:14:01.933707Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define Weights\n",
    "WEIGHTS = []\n",
    "for label in np.unique(target['label']):\n",
    "    print(f\"Label: {label}, Count: {len(target[target['label'] == label])}\")\n",
    "    WEIGHTS.append(len(target) / len(target[target['label'] == label]))\n",
    "WEIGHTS = torch.Tensor(WEIGHTS).to(device)\n",
    "\n",
    "# Define a mapping of pain indexes to integer labels\n",
    "label_mapping = {\n",
    "    'no_pain': 0,\n",
    "    'low_pain': 1,\n",
    "    'high_pain': 2\n",
    "}\n",
    "\n",
    "# Map pain indexes to integers\n",
    "target['label'] = target['label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233977ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:02.125666Z",
     "iopub.status.busy": "2025-11-17T14:14:02.125356Z",
     "iopub.status.idle": "2025-11-17T14:14:02.169193Z",
     "shell.execute_reply": "2025-11-17T14:14:02.168437Z",
     "shell.execute_reply.started": "2025-11-17T14:14:02.125641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def create_train_val_split(df, target, seed):\n",
    "    \"\"\"\n",
    "    Create train/validation split with given seed.\n",
    "    Returns train_df, val_df, train_target, val_target\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ“Š Creating train/validation split with seed={seed}...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get unique user IDs and shuffle them\n",
    "    unique_users = df['sample_index'].unique()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(unique_users)\n",
    "    \n",
    "    # Determine the number of users for validation\n",
    "    num_val_users = int(len(unique_users) * 0.2)\n",
    "    val_users = unique_users[:num_val_users]\n",
    "    train_users = unique_users[num_val_users:]\n",
    "    \n",
    "    print(f\"   Training users: {len(train_users)}\")\n",
    "    print(f\"   Validation users: {len(val_users)}\")\n",
    "    \n",
    "    # Split the DataFrame and target based on user IDs\n",
    "    train_df = df[df['sample_index'].isin(train_users)].reset_index(drop=True)\n",
    "    val_df = df[df['sample_index'].isin(val_users)].reset_index(drop=True)\n",
    "    train_target = target[target['sample_index'].isin(train_users)].reset_index(drop=True)\n",
    "    val_target = target[target['sample_index'].isin(val_users)].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"   Training set shape: {train_df.shape}\")\n",
    "    print(f\"   Validation set shape: {val_df.shape}\")\n",
    "    \n",
    "    return train_df, val_df, train_target, val_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b8fec6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:02.173181Z",
     "iopub.status.busy": "2025-11-17T14:14:02.172965Z",
     "iopub.status.idle": "2025-11-17T14:14:02.182783Z",
     "shell.execute_reply": "2025-11-17T14:14:02.182142Z",
     "shell.execute_reply.started": "2025-11-17T14:14:02.173165Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Label mapping (robust to string or numeric labels)\n",
    "LABEL_MAP = {\"no_pain\": 0, \"low_pain\": 1, \"high_pain\": 2}\n",
    "\n",
    "def _detect_joint_cols(df):\n",
    "    return sorted([c for c in df.columns if c.startswith(\"joint_\")])\n",
    "\n",
    "def _get_data_cols(df):\n",
    "    cols = _detect_joint_cols(df)\n",
    "    if not cols:\n",
    "        raise ValueError(\"No 'joint_*' columns found in df.\")\n",
    "    return cols\n",
    "\n",
    "# Load labels if not already present\n",
    "if \"target\" not in globals():\n",
    "    try:\n",
    "        target = pd.read_csv(\"pirate_pain_train_labels.csv\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: 'target' not defined and 'pirate_pain_train_labels.csv' not found.\")\n",
    "    else:\n",
    "        if \"label\" in target.columns:\n",
    "            # Map strings to ints if needed\n",
    "            if target[\"label\"].dtype == object:\n",
    "                target[\"label\"] = target[\"label\"].map(lambda x: LABEL_MAP.get(x, x))\n",
    "\n",
    "# --- Window builder ---\n",
    "def build_windows(\n",
    "    df: pd.DataFrame,\n",
    "    target: pd.DataFrame | None,\n",
    "    window: int = 300,\n",
    "    stride: int = 75,\n",
    "    padding: str = \"zero\",      # 'zero' or 'drop_last'\n",
    "    feature: str = \"3d\",        # '3d' (for RNNs) or 'flatten' (for traditional ML)\n",
    "    data_cols: list | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds sliding windows from df and returns (X, y, groups).\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with time series data\n",
    "        target: DataFrame with labels\n",
    "        window: Window size (number of timesteps)\n",
    "        stride: Stride for sliding window\n",
    "        padding: 'zero' to pad with zeros, 'drop_last' to drop incomplete windows\n",
    "        feature: '3d' returns (samples, timesteps, features) for RNNs,\n",
    "                 'flatten' returns (samples, timesteps*features) for traditional ML\n",
    "        data_cols: List of columns to use as features\n",
    "    \n",
    "    Returns:\n",
    "        X: numpy array of shape (n_samples, window, n_features) if feature='3d'\n",
    "           or (n_samples, window*n_features) if feature='flatten'\n",
    "        y: numpy array of labels\n",
    "        groups: numpy array of sample indices\n",
    "    \"\"\"\n",
    "    if data_cols is None:\n",
    "        data_cols = _get_data_cols(df)\n",
    "    X, y = [], []\n",
    "    for sid in df[\"sample_index\"].unique():\n",
    "        temp = df[df[\"sample_index\"] == sid][data_cols].values\n",
    "        # get label for this id\n",
    "        if target is not None:\n",
    "            lab_arr = target[target[\"sample_index\"] == sid][\"label\"].values\n",
    "            if len(lab_arr) == 0:\n",
    "                # if missing label, skip this id\n",
    "                continue\n",
    "            lab = lab_arr[0]\n",
    "            if isinstance(lab, str):\n",
    "                lab = LABEL_MAP.get(lab, lab)\n",
    "        # padding computation\n",
    "        pad = (window - (len(temp) % window)) % window\n",
    "        if padding == \"zero\" and pad:\n",
    "            temp = np.concatenate([temp, np.zeros((pad, temp.shape[1]), dtype=temp.dtype)], axis=0)\n",
    "        L = len(temp)\n",
    "        start = 0\n",
    "        while start + window <= L:\n",
    "            seg = temp[start:start + window]  # shape: (window, n_features)\n",
    "            if feature == \"flatten\":\n",
    "                feat = seg.reshape(-1)  # shape: (window * n_features,)\n",
    "            else:\n",
    "                feat = seg  # Keep 3D: (window, n_features)\n",
    "            X.append(feat)\n",
    "            if target is not None:\n",
    "                y.append(lab)\n",
    "            start += stride\n",
    "    if not X:\n",
    "        raise ValueError(\"No windows were created. Check your data and parameters.\")\n",
    "    return np.asarray(X), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e98d6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "\n",
    "def make_loader(ds, batch_size, shuffle, drop_last, sampler=None):\n",
    "    \"\"\"\n",
    "    Create a DataLoader with optimized settings for performance.\n",
    "    \"\"\"\n",
    "    # Determine optimal number of worker processes for data loading\n",
    "    cpu_cores = os.cpu_count() or 2\n",
    "    num_workers = max(2, min(4, cpu_cores))\n",
    "    \n",
    "    # Create DataLoader with performance optimizations\n",
    "    return DataLoader(\n",
    "        ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle if sampler is None else False,  # shuffle and sampler are mutually exclusive\n",
    "        sampler=sampler,\n",
    "        drop_last=drop_last,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True if torch.cuda.is_available() else False,  # Faster GPU transfer\n",
    "        pin_memory_device=\"cuda\" if torch.cuda.is_available() else \"\",\n",
    "        prefetch_factor=4 if num_workers > 0 else None,  # Load 4 batches ahead\n",
    "    )\n",
    "\n",
    "print(\"âœ… DataLoader utilities defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411a7972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:02.183704Z",
     "iopub.status.busy": "2025-11-17T14:14:02.183441Z",
     "iopub.status.idle": "2025-11-17T14:14:02.797475Z",
     "shell.execute_reply": "2025-11-17T14:14:02.796663Z",
     "shell.execute_reply.started": "2025-11-17T14:14:02.183684Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "WINDOW_SIZE = 20\n",
    "STRIDE = 5\n",
    "\n",
    "def prepare_data_for_seed(train_df, val_df, train_target, val_target, seed):\n",
    "    \"\"\"\n",
    "    Prepare windowed data and create dataloaders with given seed.\n",
    "    Returns X_train, y_train, X_val, y_val, train_loader, val_loader\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ”§ Building windows and dataloaders (seed={seed})...\")\n",
    "    \n",
    "    # Set seeds for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    # Build sequences - returns 3D arrays (samples, timesteps, features)\n",
    "    X_train, y_train = build_windows(train_df, train_target, WINDOW_SIZE, STRIDE, feature=\"3d\")\n",
    "    X_val, y_val = build_windows(val_df, val_target, WINDOW_SIZE, STRIDE, feature=\"3d\")\n",
    "    \n",
    "    print(f\"   Training set shape: {X_train.shape}, {y_train.shape}\")\n",
    "    print(f\"   Validation set shape: {X_val.shape}, {y_val.shape}\")\n",
    "    \n",
    "    # Calculate class weights and create sampler\n",
    "    class_counts = np.bincount(y_train)\n",
    "    class_weights = 1.0 / class_counts\n",
    "    class_weights = class_weights / np.sum(class_weights)\n",
    "    sample_weights = class_weights[y_train]\n",
    "    sample_weights = torch.from_numpy(sample_weights).double()\n",
    "    \n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    # Create datasets and dataloaders\n",
    "    train_ds = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
    "    val_ds = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
    "    \n",
    "    BATCH_SIZE = 128\n",
    "    train_loader = make_loader(train_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=True, sampler=sampler)\n",
    "    val_loader = make_loader(val_ds, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "    \n",
    "    print(f\"   Training batches: {len(train_loader)}\")\n",
    "    print(f\"   Validation batches: {len(val_loader)}\")\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4786ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/validation split\n",
    "SEED = 42\n",
    "train_df, val_df, train_target, val_target = create_train_val_split(df, target, SEED)\n",
    "\n",
    "# Call prepare_data_for_seed to create train/val data and loaders\n",
    "X_train, y_train, X_val, y_val, train_loader, val_loader = prepare_data_for_seed(\n",
    "    train_df, val_df, train_target, val_target, SEED\n",
    ")\n",
    "\n",
    "# Store metadata for model creation\n",
    "input_shape = X_train.shape\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "print(f\"\\nâœ… Data prepared successfully\")\n",
    "print(f\"   Input shape: {input_shape}\")\n",
    "print(f\"   Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df3803",
   "metadata": {},
   "source": [
    "# **Model Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b920aa9",
   "metadata": {},
   "source": [
    "## **Inner Logic**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b18f728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:02.837001Z",
     "iopub.status.busy": "2025-11-17T14:14:02.836795Z",
     "iopub.status.idle": "2025-11-17T14:14:02.922919Z",
     "shell.execute_reply": "2025-11-17T14:14:02.922430Z",
     "shell.execute_reply.started": "2025-11-17T14:14:02.836978Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def train_one_epoch(model, train_loader, criterion, optimizer, scaler, device, l1_lambda=0, l2_lambda=0):\n",
    "    \"\"\"\n",
    "    Perform one complete training epoch through the entire training dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to train\n",
    "        train_loader (DataLoader): PyTorch DataLoader containing training data batches\n",
    "        criterion (nn.Module): Loss function (e.g., CrossEntropyLoss, MSELoss)\n",
    "        optimizer (torch.optim): Optimization algorithm (e.g., Adam, SGD)\n",
    "        scaler (GradScaler): PyTorch's gradient scaler for mixed precision training\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "        l1_lambda (float): Lambda for L1 regularization\n",
    "        l2_lambda (float): Lambda for L2 regularization\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, f1 score) - Training loss and f1 score for this epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Iterate through training batches\n",
    "    for _, (inputs, targets) in enumerate(train_loader):\n",
    "        # Move data to device (GPU/CPU)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Clear gradients from previous step\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Forward pass with mixed precision (if CUDA available)\n",
    "        with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "          logits = model(inputs)\n",
    "          loss = criterion(logits, targets)\n",
    "\n",
    "          # --- REGULARIZATION ---\n",
    "          if l1_lambda > 0 or l2_lambda > 0:\n",
    "              for name, param in model.named_parameters():\n",
    "                  # Only regularize weight matrices\n",
    "                  if 'weight' in name:\n",
    "                      if l1_lambda > 0:\n",
    "                          loss += l1_lambda * torch.sum(torch.abs(param))\n",
    "                      if l2_lambda > 0:\n",
    "                          loss += l2_lambda * torch.sum(torch.pow(param, 2))\n",
    "\n",
    "\n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "        scaler.unscale_(optimizer)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Accumulate metrics\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        predictions = logits.argmax(dim=1)\n",
    "        all_predictions.append(predictions.cpu().numpy())\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_f1 = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='weighted',\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_f1\n",
    "\n",
    "\n",
    "def validate_one_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Perform one complete validation epoch through the entire validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model to evaluate (must be in eval mode)\n",
    "        val_loader (DataLoader): PyTorch DataLoader containing validation data batches\n",
    "        criterion (nn.Module): Loss function used to calculate validation loss\n",
    "        device (torch.device): Computing device ('cuda' for GPU, 'cpu' for CPU)\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, accuracy) - Validation loss and accuracy for this epoch\n",
    "\n",
    "    Note:\n",
    "        This function automatically sets the model to evaluation mode and disables\n",
    "        gradient computation for efficiency during validation.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    running_loss = 0.0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    # Disable gradient computation for validation\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            # Move data to device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass with mixed precision (if CUDA available)\n",
    "            with torch.amp.autocast(device_type=device.type, enabled=(device.type == 'cuda')):\n",
    "                logits = model(inputs)\n",
    "                loss = criterion(logits, targets)\n",
    "\n",
    "            # Accumulate metrics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            predictions = logits.argmax(dim=1)\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    epoch_accuracy = f1_score(\n",
    "        np.concatenate(all_targets),\n",
    "        np.concatenate(all_predictions),\n",
    "        average='weighted',\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    return epoch_loss, epoch_accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "def fit(model, train_loader, val_loader, epochs, criterion, optimizer, scaler, device,\n",
    "        l1_lambda=0, l2_lambda=0, patience=0, evaluation_metric=\"val_f1\", mode='max',\n",
    "        restore_best_weights=True, verbose=10, experiment_name=\"\", plot_live=False):\n",
    "    \"\"\"\n",
    "    Same as before, but with two live-updating subplots and preserved verbose output.\n",
    "    \"\"\"\n",
    "\n",
    "    training_history = {\n",
    "        'train_loss': [], 'val_loss': [],\n",
    "        'train_f1': [], 'val_f1': []\n",
    "    }\n",
    "\n",
    "    # Live plot setup\n",
    "    if plot_live:\n",
    "        plt.ion()\n",
    "        fig, (ax_loss, ax_f1) = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "    # Early stopping\n",
    "    if patience > 0:\n",
    "        patience_counter = 0\n",
    "        best_metric = float('-inf') if mode == 'max' else float('inf')\n",
    "        best_epoch = 0\n",
    "\n",
    "    print(f\"Training {epochs} epochs...\")\n",
    "\n",
    "    # --- Accumulate text output so clear_output doesn't remove it ---\n",
    "    logs = \"\"\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "\n",
    "        train_loss, train_f1 = train_one_epoch(\n",
    "            model, train_loader, criterion, optimizer, scaler, device, l1_lambda, l2_lambda\n",
    "        )\n",
    "\n",
    "        val_loss, val_f1 = validate_one_epoch(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "\n",
    "        training_history['train_loss'].append(train_loss)\n",
    "        training_history['val_loss'].append(val_loss)\n",
    "        training_history['train_f1'].append(train_f1)\n",
    "        training_history['val_f1'].append(val_f1)\n",
    "\n",
    "        # --- Verbose logging ---\n",
    "        if verbose > 0 and (epoch % verbose == 0 or epoch == 1):\n",
    "            log_line = (f\"Epoch {epoch:3d}/{epochs} | \"\n",
    "                        f\"Train: Loss={train_loss:.4f}, F1={train_f1:.4f} | \"\n",
    "                        f\"Val: Loss={val_loss:.4f}, F1={val_f1:.4f}\\n\")\n",
    "            logs += log_line\n",
    "\n",
    "        # --- ðŸ”¥ LIVE PLOTTING ---\n",
    "        if plot_live:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            # Plot 1: Loss\n",
    "            ax_loss.clear()\n",
    "            ax_loss.plot(range(1, len(training_history['train_loss']) + 1),\n",
    "                         training_history['train_loss'], linestyle='--', color='orange',\n",
    "                         label=\"Train Loss\")\n",
    "            ax_loss.plot(range(1, len(training_history['val_loss']) + 1),\n",
    "                         training_history['val_loss'], linestyle='-', color='orange',\n",
    "                         label=\"Val Loss\")\n",
    "            ax_loss.set_title(\"Loss\")\n",
    "            ax_loss.set_xlabel(\"Epoch\")\n",
    "            ax_loss.legend()\n",
    "            ax_loss.grid(True)\n",
    "\n",
    "            # Plot 2: F1\n",
    "            ax_f1.clear()\n",
    "            ax_f1.plot(range(1, len(training_history['train_f1']) + 1),\n",
    "                       training_history['train_f1'], linestyle='--', color='orange',\n",
    "                       label=\"Train F1\")\n",
    "            ax_f1.plot(range(1, len(training_history['val_f1']) + 1),\n",
    "                       training_history['val_f1'], linestyle='-', color='orange',\n",
    "                       label=\"Val F1\")\n",
    "            ax_f1.set_title(\"F1 Score\")\n",
    "            ax_f1.set_xlabel(\"Epoch\")\n",
    "            ax_f1.legend()\n",
    "            ax_f1.grid(True)\n",
    "\n",
    "            display(fig)\n",
    "\n",
    "            # Reprint accumulated logs so far\n",
    "            print(logs)\n",
    "\n",
    "            plt.pause(0.001)\n",
    "        # --------------------------------------------------------------\n",
    "\n",
    "        # Early stopping\n",
    "        if patience > 0:\n",
    "            current_metric = training_history[evaluation_metric][-1]\n",
    "            improved = (current_metric > best_metric) if mode == 'max' else (current_metric < best_metric)\n",
    "\n",
    "            if improved:\n",
    "                best_metric = current_metric\n",
    "                best_epoch = epoch\n",
    "                torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"\\nEarly stopping triggered after {epoch} epochs.\")\n",
    "                    break\n",
    "\n",
    "    # Restore best weights\n",
    "    if restore_best_weights and patience > 0:\n",
    "        model.load_state_dict(torch.load(\"models/\"+experiment_name+'_model.pt'))\n",
    "        print(f\"Best model restored from epoch {best_epoch} with {evaluation_metric} {best_metric:.4f}\")\n",
    "\n",
    "    # Save final weights if no ES\n",
    "    if patience == 0:\n",
    "        torch.save(model.state_dict(), \"models/\"+experiment_name+'_model.pt')\n",
    "\n",
    "    if plot_live:\n",
    "        plt.ioff()\n",
    "\n",
    "    return model, training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f5c71d",
   "metadata": {},
   "source": [
    "## **Model Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d59d94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:02.923827Z",
     "iopub.status.busy": "2025-11-17T14:14:02.923590Z",
     "iopub.status.idle": "2025-11-17T14:14:02.928646Z",
     "shell.execute_reply": "2025-11-17T14:14:02.927946Z",
     "shell.execute_reply.started": "2025-11-17T14:14:02.923811Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# ============================================================================\n",
    "# MODEL SETUP\n",
    "# ============================================================================\n",
    "import torch.nn as nn\n",
    "from model_definitions.cnn import CNN1DClassifier\n",
    "\n",
    "model = CNN1DClassifier(\n",
    "    input_size=input_shape[-1],\n",
    "    num_classes=num_classes,\n",
    "    num_filters=[128, 128, 256],\n",
    "    kernel_sizes=[7, 11, 3],\n",
    "    dropout_rate=0.5\n",
    ").to(device)\n",
    "\n",
    "\n",
    "print(f\"\\nðŸ”§ Model: {model.__class__.__name__}\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a19d5-036f-4145-b601-cde2868f92fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:02.929662Z",
     "iopub.status.busy": "2025-11-17T14:14:02.929443Z",
     "iopub.status.idle": "2025-11-17T14:14:02.969999Z",
     "shell.execute_reply": "2025-11-17T14:14:02.969452Z",
     "shell.execute_reply.started": "2025-11-17T14:14:02.929640Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MODEL SETUP - BEST HYPERPARAMETERS FROM OPTUNA\n",
    "# ============================================================================\n",
    "import torch.nn as nn\n",
    "from model_definitions.cnn import CNN1DClassifier\n",
    "\n",
    "# ðŸŽ¯ Best hyperparameters from Optuna optimization\n",
    "BEST_PARAMS = {\n",
    "    'num_filters': [256, 512, 128, 128],\n",
    "    'kernel_sizes': [11, 5, 7, 3],\n",
    "    'dropout_rate': 0.3,\n",
    "    'learning_rate': 3.85436576182968e-05,\n",
    "    'batch_size': 128,\n",
    "    'l1_lambda': 0,\n",
    "    'l2_lambda': 0.001\n",
    "}\n",
    "\n",
    "model = CNN1DClassifier(\n",
    "    input_size=input_shape[-1],\n",
    "    num_classes=num_classes,\n",
    "    num_filters=BEST_PARAMS['num_filters'],\n",
    "    kernel_sizes=BEST_PARAMS['kernel_sizes'],\n",
    "    dropout_rate=BEST_PARAMS['dropout_rate']\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\nðŸ”§ Model: {model.__class__.__name__}\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"\\nðŸ“‹ Using best hyperparameters:\")\n",
    "for key, value in BEST_PARAMS.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c1496",
   "metadata": {},
   "source": [
    "## Loss Function, Optimizer, Gradient Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f6181",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:02.970838Z",
     "iopub.status.busy": "2025-11-17T14:14:02.970637Z",
     "iopub.status.idle": "2025-11-17T14:14:02.976189Z",
     "shell.execute_reply": "2025-11-17T14:14:02.975624Z",
     "shell.execute_reply.started": "2025-11-17T14:14:02.970816Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "# Calculate class weights: inverse frequency with normalization\n",
    "train_class_counts = np.bincount(y_train.astype(int))\n",
    "class_weights_loss = len(y_train) / (len(train_class_counts) * train_class_counts)\n",
    "class_weights_loss = torch.tensor(class_weights_loss, dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"\\nâš–ï¸  Loss weights (amplifies gradients for minority classes):\")\n",
    "for cls, weight in enumerate(class_weights_loss):\n",
    "    print(f\"  Class {cls}: {weight:.4f}x\")\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss(weight=class_weights_loss, label_smoothing=0.1)\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        \"\"\"\n",
    "        Focal Loss for multi-class classification.\n",
    "\n",
    "        Parameters:\n",
    "        - alpha: Tensor of shape [num_classes] containing class weights. \n",
    "                 Use None if no weighting is needed (e.g., if using a WeightedRandomSampler).\n",
    "        - gamma: focusing parameter. Higher gamma â†’ focus more on hard examples.\n",
    "        - reduction: 'mean', 'sum', or 'none'\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.alpha = alpha  # should be a tensor or None\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        \"\"\"\n",
    "        inputs: [batch_size, num_classes] logits\n",
    "        targets: [batch_size] long tensor of class indices\n",
    "        \"\"\"\n",
    "        # Compute per-sample cross entropy\n",
    "        ce_loss = self.ce(inputs, targets)  # [batch_size]\n",
    "\n",
    "        # Compute probability of correct class\n",
    "        pt = torch.exp(-ce_loss)  # [batch_size]\n",
    "\n",
    "        # Apply class weights if provided\n",
    "        if self.alpha is not None:\n",
    "            # Ensure alpha is on the same device as inputs\n",
    "            alpha = self.alpha.to(inputs.device)\n",
    "            alpha_t = alpha[targets]  # pick weight per sample\n",
    "            focal_loss = alpha_t * ((1 - pt) ** self.gamma) * ce_loss\n",
    "        else:\n",
    "            focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:  # 'none'\n",
    "            return focal_loss\n",
    "\n",
    "criterion = FocalLoss(alpha=None, gamma=2.0)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-3,           # Learning rate\n",
    "    weight_decay=1e-4  # L2 regularization\n",
    ")\n",
    "\n",
    "scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec6a2d0-0a48-4ceb-9ea6-b3e716df917f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:02.977077Z",
     "iopub.status.busy": "2025-11-17T14:14:02.976837Z",
     "iopub.status.idle": "2025-11-17T14:14:05.521676Z",
     "shell.execute_reply": "2025-11-17T14:14:05.521034Z",
     "shell.execute_reply.started": "2025-11-17T14:14:02.977054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#NUOVA\n",
    "\n",
    "# ============================================================================\n",
    "# LOSS, OPTIMIZER - WITH BEST HYPERPARAMETERS\n",
    "# ============================================================================\n",
    "\n",
    "# ðŸŽ¯ Best hyperparameters\n",
    "BEST_PARAMS = {\n",
    "    'learning_rate': 3.85436576182968e-05,\n",
    "    'l2_lambda': 0.001\n",
    "}\n",
    "\n",
    "# Calculate class weights\n",
    "train_class_counts = np.bincount(y_train.astype(int))\n",
    "class_weights_loss = len(y_train) / (len(train_class_counts) * train_class_counts)\n",
    "class_weights_loss = torch.tensor(class_weights_loss, dtype=torch.float32).to(device)\n",
    "\n",
    "print(f\"\\nâš–ï¸  Loss weights:\")\n",
    "for cls, weight in enumerate(class_weights_loss):\n",
    "    print(f\"  Class {cls}: {weight:.4f}x\")\n",
    "\n",
    "# Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.ce = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = self.ce(inputs, targets)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            alpha = self.alpha.to(inputs.device)\n",
    "            alpha_t = alpha[targets]\n",
    "            focal_loss = alpha_t * ((1 - pt) ** self.gamma) * ce_loss\n",
    "        else:\n",
    "            focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return focal_loss.sum()\n",
    "        else:\n",
    "            return focal_loss\n",
    "\n",
    "criterion = FocalLoss(alpha=None, gamma=2.0)\n",
    "\n",
    "# Optimizer with best hyperparameters\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=BEST_PARAMS['learning_rate'],\n",
    "    weight_decay=BEST_PARAMS['l2_lambda']\n",
    ")\n",
    "\n",
    "scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "\n",
    "print(f\"\\nâœ… Optimizer configured:\")\n",
    "print(f\"   Learning rate: {BEST_PARAMS['learning_rate']:.2e}\")\n",
    "print(f\"   Weight decay (L2): {BEST_PARAMS['l2_lambda']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c5e5e",
   "metadata": {},
   "source": [
    "## Optuna Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2721502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:05.522832Z",
     "iopub.status.busy": "2025-11-17T14:14:05.522354Z",
     "iopub.status.idle": "2025-11-17T14:14:05.528132Z",
     "shell.execute_reply": "2025-11-17T14:14:05.527184Z",
     "shell.execute_reply.started": "2025-11-17T14:14:05.522806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š SETTING UP K-FOLD CROSS-VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "K_FOLDS = 5\n",
    "\n",
    "# Create K-Fold splits (fixed, will be reused for all Optuna trials)\n",
    "kfold = KFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n",
    "fold_indices = list(kfold.split(X_train))\n",
    "\n",
    "print(f\"   Fold splits created: {len(fold_indices)} folds ready\")\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251b78d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:05.529337Z",
     "iopub.status.busy": "2025-11-17T14:14:05.529070Z",
     "iopub.status.idle": "2025-11-17T14:14:05.547055Z",
     "shell.execute_reply": "2025-11-17T14:14:05.546297Z",
     "shell.execute_reply.started": "2025-11-17T14:14:05.529316Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "def optuna_objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function for CNN1DClassifier.\n",
    "    Trains model on K-Fold and returns average validation F1.\n",
    "    \"\"\"\n",
    "\n",
    "    # ========================================================================\n",
    "    # SUGGEST HYPERPARAMETERS FOR CNN\n",
    "    # ========================================================================\n",
    "    num_filters_1 = trial.suggest_categorical('num_filters_1', [64, 128, 256])\n",
    "    num_filters_2 = trial.suggest_categorical('num_filters_2', [128, 256, 512])\n",
    "    num_filters_3 = trial.suggest_categorical('num_filters_3', [128, 256, 512])\n",
    "    num_filters_4 = trial.suggest_categorical('num_filters_4', [128, 128, 256])\n",
    "    \n",
    "    kernel_size_1 = trial.suggest_categorical('kernel_size_1', [5, 7, 9, 11])\n",
    "    kernel_size_2 = trial.suggest_categorical('kernel_size_2', [5, 7, 9, 11, 13])\n",
    "    kernel_size_3 = trial.suggest_categorical('kernel_size_3', [3, 5, 7])\n",
    "    kernel_size_4 = trial.suggest_categorical('kernel_size_4', [7, 11, 3])\n",
    "    \n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.6, step=0.1)\n",
    "    learning_rate = trial.suggest_float('learning_rate',5e-6, 1e-4, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    l1_lambda = trial.suggest_categorical('l1_lambda', [0, 0.001, 0.01])\n",
    "    l2_lambda = trial.suggest_categorical('l2_lambda', [0, 1e-5, 1e-4, 1e-3])\n",
    "\n",
    "    # ========================================================================\n",
    "    # K-FOLD TRAINING\n",
    "    # ========================================================================\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(fold_indices):\n",
    "        # Split data for this fold\n",
    "        X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
    "\n",
    "        # Create datasets\n",
    "        train_ds = TensorDataset(torch.from_numpy(X_fold_train).float(), torch.from_numpy(y_fold_train).long())\n",
    "        val_ds = TensorDataset(torch.from_numpy(X_fold_val).float(), torch.from_numpy(y_fold_val).long())\n",
    "\n",
    "        # Weighted sampling for class imbalance\n",
    "        fold_class_counts = np.bincount(y_fold_train.astype(int))\n",
    "        class_weights_sampling = 1.0 / fold_class_counts\n",
    "        class_weights_sampling = class_weights_sampling / np.sum(class_weights_sampling)\n",
    "        sample_weights = class_weights_sampling[y_fold_train.astype(int)]\n",
    "        sample_weights = torch.from_numpy(sample_weights).float()\n",
    "\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "\n",
    "        # Create data loaders\n",
    "        train_loader = make_loader(train_ds, batch_size=batch_size, shuffle=False, drop_last=True, sampler=sampler)\n",
    "        val_loader = make_loader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "        # Create CNN model\n",
    "        model = CNN1DClassifier(\n",
    "            input_size=input_shape[-1],\n",
    "            num_classes=num_classes,\n",
    "            num_filters=[num_filters_1, num_filters_2, num_filters_3, num_filters_4],\n",
    "            kernel_sizes=[kernel_size_1, kernel_size_2, kernel_size_3, kernel_size_4],\n",
    "            dropout_rate=dropout_rate\n",
    "        ).to(device)\n",
    "\n",
    "        # Loss & Optimizer\n",
    "        fold_class_weights_loss = len(y_fold_train) / (len(fold_class_counts) * fold_class_counts)\n",
    "        fold_class_weights_loss = torch.tensor(fold_class_weights_loss, dtype=torch.float32).to(device)\n",
    "        \n",
    "        criterion = FocalLoss(alpha=None, gamma=2.0)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=l2_lambda\n",
    "        )\n",
    "\n",
    "        scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "\n",
    "        # Train\n",
    "        _, history = fit(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            epochs=30,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scaler=scaler,\n",
    "            device=device,\n",
    "            patience=50,\n",
    "            l1_lambda=l1_lambda,\n",
    "            verbose=0  # Silent during Optuna\n",
    "        )\n",
    "\n",
    "        # Get best F1 for this fold\n",
    "        best_f1 = max(history['val_f1'])\n",
    "        fold_scores.append(best_f1)\n",
    "\n",
    "        # Report intermediate value for pruning\n",
    "        trial.report(best_f1, fold_idx)\n",
    "\n",
    "        # Prune if performing poorly\n",
    "        if trial.should_prune():\n",
    "            raise optuna.TrialPruned()\n",
    "\n",
    "    # Return average F1 across all folds\n",
    "    avg_f1 = np.mean(fold_scores)\n",
    "    return avg_f1\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee9cda1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:05.547984Z",
     "iopub.status.busy": "2025-11-17T14:14:05.547769Z",
     "iopub.status.idle": "2025-11-17T14:14:05.559192Z",
     "shell.execute_reply": "2025-11-17T14:14:05.558386Z",
     "shell.execute_reply.started": "2025-11-17T14:14:05.547961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ” STARTING OPTUNA HYPERPARAMETER OPTIMIZATION FOR CNN1D\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Optuna configuration\n",
    "N_TRIALS = 5\n",
    "TIMEOUT = 6 * 3600  # 6 hours\n",
    "\n",
    "# Create pruner\n",
    "pruner = MedianPruner(\n",
    "    n_startup_trials=5,\n",
    "    n_warmup_steps=3,\n",
    "    interval_steps=10\n",
    ")\n",
    "\n",
    "# Create study\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    pruner=pruner,\n",
    "    study_name='cnn1d_kfold_optimization'\n",
    ")\n",
    "\n",
    "print(f\"\\nâš™  Configuration:\")\n",
    "print(f\"   Trials: {N_TRIALS}\")\n",
    "print(f\"   Timeout: {TIMEOUT/3600:.1f} hours\")\n",
    "print(f\"   K-Folds: {K_FOLDS}\")\n",
    "print(f\"   Epochs per trial: 50 (with patience=15)\")\n",
    "print(f\"   Pruning: Enabled (MedianPruner)\")\n",
    "\n",
    "print(f\"\\nðŸš€ Starting optimization...\")\n",
    "print(f\"   This will take approximately 4-6 hours\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Run optimization\n",
    "study.optimize(\n",
    "    optuna_objective,\n",
    "    n_trials=N_TRIALS,\n",
    "    timeout=TIMEOUT,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… OPTUNA OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Best trial\n",
    "best_trial = study.best_trial\n",
    "print(f\"\\nðŸ† Best Trial:\")\n",
    "print(f\"   Trial number: {best_trial.number}\")\n",
    "print(f\"   Best F1 score: {best_trial.value:.4f}\")\n",
    "print(f\"\\nðŸŽ¯ Best Hyperparameters:\")\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f\"   {key}: {value}\")\n",
    "\n",
    "# Save study\n",
    "import pickle\n",
    "with open('optuna_study_cnn1d.pkl', 'wb') as f:\n",
    "    pickle.dump(study, f)\n",
    "print(f\"\\nðŸ’¾ Study saved to 'optuna_study_cnn1d.pkl'\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f007ee",
   "metadata": {},
   "source": [
    "# **Fit Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11399fc",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:05.560255Z",
     "iopub.status.busy": "2025-11-17T14:14:05.560037Z",
     "iopub.status.idle": "2025-11-17T14:14:05.571275Z",
     "shell.execute_reply": "2025-11-17T14:14:05.570680Z",
     "shell.execute_reply.started": "2025-11-17T14:14:05.560231Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING\n",
    "# ============================================================================\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Training {model.__class__.__name__}...\")\n",
    "print(f\"{'='*70}\")\n",
    "\n",
    "_, history = fit(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=1000,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scaler=scaler,\n",
    "    device=device,\n",
    "    verbose=5,\n",
    "    experiment_name=\"model_training\",\n",
    "    patience=100,       # Set > 0 for early stopping\n",
    "    l1_lambda=0,      # L1 regularization\n",
    "    l2_lambda=0,       # L2 regularization (or use weight_decay in optimizer)\n",
    "    plot_live=True\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e687c3e0-41a6-4455-b9e8-4ca7fb721017",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:14:05.572231Z",
     "iopub.status.busy": "2025-11-17T14:14:05.571997Z",
     "iopub.status.idle": "2025-11-17T14:16:16.298311Z",
     "shell.execute_reply": "2025-11-17T14:16:16.297644Z",
     "shell.execute_reply.started": "2025-11-17T14:14:05.572216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# MULTI-SEED TRAINING EXPERIMENT\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"ðŸš€ STARTING MULTI-SEED EXPERIMENT\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"   Total seeds to test: {len(SEED_LIST)}\")\n",
    "print(f\"   Model: CNN1DClassifier\")\n",
    "print(f\"   Max epochs per seed: 500 (with early stopping patience=50)\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Store results for each seed\n",
    "seed_results = []\n",
    "best_f1_overall = 0\n",
    "best_seed = None\n",
    "best_model_state = None\n",
    "\n",
    "for seed_idx, current_seed in enumerate(SEED_LIST, 1):\n",
    "    print(f\"\\n\" + \"#\" * 80)\n",
    "    print(f\"# EXPERIMENT {seed_idx}/{len(SEED_LIST)} - SEED {current_seed}\")\n",
    "    print(\"#\" * 80)\n",
    "    \n",
    "    # Create train/val split with current seed\n",
    "    train_df, val_df, train_target, val_target = create_train_val_split(df, target, current_seed)\n",
    "    \n",
    "    # Prepare data and dataloaders\n",
    "    X_train, y_train, X_val, y_val, train_loader, val_loader = prepare_data_for_seed(\n",
    "        train_df, val_df, train_target, val_target, current_seed\n",
    "    )\n",
    "    \n",
    "    input_shape = X_train.shape\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    \n",
    "    # Create model with current seed\n",
    "    torch.manual_seed(current_seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(current_seed)\n",
    "    \n",
    "    model = CNN1DClassifier(\n",
    "        input_size=input_shape[-1],\n",
    "        num_classes=num_classes,\n",
    "        num_filters=[256, 512, 128, 128],\n",
    "        kernel_sizes=[11, 5, 7, 3],\n",
    "        dropout_rate=0.3\n",
    "    ).to(device)\n",
    "    \n",
    "    # Setup training components\n",
    "    train_class_counts = np.bincount(y_train.astype(int))\n",
    "    class_weights_loss = len(y_train) / (len(train_class_counts) * train_class_counts)\n",
    "    class_weights_loss = torch.tensor(class_weights_loss, dtype=torch.float32).to(device)\n",
    "    \n",
    "    criterion = FocalLoss(alpha=None, gamma=2.0)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=3.85436576182968e-05,\n",
    "        weight_decay=0.001\n",
    "    )\n",
    "    scaler = torch.amp.GradScaler(enabled=(device.type == 'cuda'))\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\nðŸ‹ï¸ Training with seed {current_seed}...\")\n",
    "    _, history = fit(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        epochs=500,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scaler=scaler,\n",
    "        device=device,\n",
    "        verbose=10,\n",
    "        experiment_name=f\"seed_{current_seed}\",\n",
    "        patience=50,\n",
    "        l1_lambda=0,\n",
    "        l2_lambda=0,\n",
    "        plot_live=False\n",
    "    )\n",
    "    \n",
    "    # Get results\n",
    "    best_val_f1 = max(history['val_f1'])\n",
    "    final_val_f1 = history['val_f1'][-1]\n",
    "    final_train_f1 = history['train_f1'][-1]\n",
    "    epochs_trained = len(history['val_f1'])\n",
    "    \n",
    "    # Store results\n",
    "    seed_results.append({\n",
    "        'seed': current_seed,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'final_val_f1': final_val_f1,\n",
    "        'final_train_f1': final_train_f1,\n",
    "        'epochs_trained': epochs_trained\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Results for seed {current_seed}:\")\n",
    "    print(f\"   Best Val F1: {best_val_f1:.4f}\")\n",
    "    print(f\"   Final Val F1: {final_val_f1:.4f}\")\n",
    "    print(f\"   Epochs trained: {epochs_trained}\")\n",
    "    \n",
    "    # Check if this is the best model so far\n",
    "    if best_val_f1 > best_f1_overall:\n",
    "        best_f1_overall = best_val_f1\n",
    "        best_seed = current_seed\n",
    "        # Save best model state\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"   ðŸ† NEW BEST MODEL! (F1: {best_val_f1:.4f})\")\n",
    "    \n",
    "    print(f\"\\n   Current best overall: seed={best_seed}, F1={best_f1_overall:.4f}\")\n",
    "\n",
    "print(f\"\\n\\n\" + \"=\" * 80)\n",
    "print(f\"âœ… MULTI-SEED EXPERIMENT COMPLETE!\")\n",
    "print(f\"=\" * 80)\n",
    "\n",
    "# Display results table\n",
    "results_df = pd.DataFrame(seed_results)\n",
    "results_df = results_df.sort_values('best_val_f1', ascending=False)\n",
    "\n",
    "print(f\"\\nðŸ“Š RESULTS SUMMARY (sorted by best val F1):\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nðŸ† BEST MODEL:\")\n",
    "print(f\"   Seed: {best_seed}\")\n",
    "print(f\"   Best Val F1: {best_f1_overall:.4f}\")\n",
    "print(f\"   Mean F1 across seeds: {results_df['best_val_f1'].mean():.4f}\")\n",
    "print(f\"   Std F1 across seeds: {results_df['best_val_f1'].std():.4f}\")\n",
    "\n",
    "# Load best model for inference\n",
    "print(f\"\\nðŸ’¾ Loading best model (seed {best_seed})...\")\n",
    "model.load_state_dict(best_model_state)\n",
    "torch.save(best_model_state, f\"models/best_model_seed_{best_seed}.pt\")\n",
    "print(f\"   Saved to: models/best_model_seed_{best_seed}.pt\")\n",
    "\n",
    "# For inference, reload the data split with the best seed\n",
    "print(f\"\\nðŸ”„ Recreating data split with best seed ({best_seed}) for inference...\")\n",
    "train_df, val_df, train_target, val_target = create_train_val_split(df, target, best_seed)\n",
    "X_train, y_train, X_val, y_val, train_loader, val_loader = prepare_data_for_seed(\n",
    "    train_df, val_df, train_target, val_target, best_seed\n",
    ")\n",
    "\n",
    "history = None  # Clear history from last seed iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb6996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:16:16.299620Z",
     "iopub.status.busy": "2025-11-17T14:16:16.299344Z",
     "iopub.status.idle": "2025-11-17T14:16:16.748639Z",
     "shell.execute_reply": "2025-11-17T14:16:16.747585Z",
     "shell.execute_reply.started": "2025-11-17T14:16:16.299597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL EVALUATION OF BEST MODEL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ“Š EVALUATING BEST MODEL:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"  Best seed: {best_seed}\")\n",
    "print(f\"  Best Val F1: {best_f1_overall:.4f}\")\n",
    "\n",
    "# Per-class predictions\n",
    "from sklearn.metrics import classification_report\n",
    "model.eval()\n",
    "val_preds = []\n",
    "val_true = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        val_preds.extend(preds.cpu().numpy())\n",
    "        val_true.extend(targets.cpu().numpy())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ“ˆ CLASSIFICATION REPORT:\")\n",
    "print(\"=\" * 70)\n",
    "print(classification_report(\n",
    "    val_true, val_preds,\n",
    "    target_names=['no_pain', 'low_pain', 'high_pain'],\n",
    "    digits=4\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c946f65a",
   "metadata": {},
   "source": [
    "## **Plot Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a741388",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:16:16.750648Z",
     "iopub.status.busy": "2025-11-17T14:16:16.750018Z",
     "iopub.status.idle": "2025-11-17T14:16:17.216827Z",
     "shell.execute_reply": "2025-11-17T14:16:17.215948Z",
     "shell.execute_reply.started": "2025-11-17T14:16:16.750621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Â @title Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Get predictions for the validation set\n",
    "model.eval()\n",
    "val_predictions = []\n",
    "val_targets = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        val_predictions.extend(predicted.cpu().numpy())\n",
    "        val_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(val_targets, val_predictions)\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['no_pain', 'low_pain', 'high_pain']\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix (Validation Set)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fbd6bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:16:17.218149Z",
     "iopub.status.busy": "2025-11-17T14:16:17.217852Z",
     "iopub.status.idle": "2025-11-17T14:16:17.736106Z",
     "shell.execute_reply": "2025-11-17T14:16:17.735537Z",
     "shell.execute_reply.started": "2025-11-17T14:16:17.218121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# @title Plot History\n",
    "\n",
    "# Create a figure with two side-by-side subplots (two columns)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(18, 5))\n",
    "\n",
    "# Plot of training and validation loss on the first axis\n",
    "ax1.plot(history['train_loss'], label='Training loss', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
    "ax1.plot(history['val_loss'], label='Validation loss', alpha=0.9, color='#ff7f0e')\n",
    "ax1.set_title('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# Plot of training and validation accuracy on the second axis\n",
    "ax2.plot(history['train_f1'], label='Training f1', alpha=0.3, color='#ff7f0e', linestyle='--')\n",
    "ax2.plot(history['val_f1'], label='Validation f1', alpha=0.9, color='#ff7f0e')\n",
    "ax2.set_title('F1 Score')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# Adjust the layout and display the plot\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3c284c",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957031d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:16:17.737040Z",
     "iopub.status.busy": "2025-11-17T14:16:17.736795Z",
     "iopub.status.idle": "2025-11-17T14:16:22.153800Z",
     "shell.execute_reply": "2025-11-17T14:16:22.152865Z",
     "shell.execute_reply.started": "2025-11-17T14:16:17.737014Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create test dataset and loader\n",
    "test_df = build_windows(df_test, None, WINDOW_SIZE, STRIDE, feature=\"3d\")[0]\n",
    "X_test = test_df.astype(np.float32)\n",
    "test_loader = make_loader(\n",
    "    TensorDataset(torch.from_numpy(X_test).float()), \n",
    "    batch_size=32, \n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# Generate predictions for all windows\n",
    "all_window_preds = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb in test_loader:\n",
    "        xb = xb[0].to(device)\n",
    "        outputs = model(xb)\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        all_window_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "print(f\"\\nðŸ“Š Generated {len(all_window_preds)} window predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76bf8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-17T14:16:22.155516Z",
     "iopub.status.busy": "2025-11-17T14:16:22.155002Z",
     "iopub.status.idle": "2025-11-17T14:16:24.567698Z",
     "shell.execute_reply": "2025-11-17T14:16:24.566836Z",
     "shell.execute_reply.started": "2025-11-17T14:16:22.155488Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# AGGREGATE PREDICTIONS PER PIRATE (sample_index)\n",
    "# ============================================================================\n",
    "# Calculate how many windows per sample_index\n",
    "num_test_samples = len(df_test['sample_index'].unique())\n",
    "windows_per_sample = len(all_window_preds) // num_test_samples\n",
    "\n",
    "print(f\"   Test samples: {num_test_samples}\")\n",
    "print(f\"   Windows per sample: {windows_per_sample}\")\n",
    "\n",
    "# Aggregate predictions using sum of logits (confidence-weighted voting)\n",
    "label_mapping = {0: 'no_pain', 1: 'low_pain', 2: 'high_pain'}\n",
    "final_predictions = []\n",
    "\n",
    "# Get probability scores for all windows\n",
    "all_window_probs = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb in test_loader:\n",
    "        xb = xb[0].to(device)\n",
    "        outputs = model(xb)\n",
    "        probs = torch.softmax(outputs, dim=1)  # Convert logits to probabilities\n",
    "        all_window_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "all_window_probs = np.array(all_window_probs)\n",
    "\n",
    "# Aggregate using sum of probabilities\n",
    "for sample_idx in range(num_test_samples):\n",
    "    # Get all window predictions for this sample_index\n",
    "    start_idx = sample_idx * windows_per_sample\n",
    "    end_idx = start_idx + windows_per_sample\n",
    "    window_probs = all_window_probs[start_idx:end_idx]\n",
    "    \n",
    "    # Sum probabilities across all windows for each class\n",
    "    class_scores = window_probs.sum(axis=0)  # Shape: (3,) for 3 classes\n",
    "    \n",
    "    # Winner: class with highest total confidence\n",
    "    predicted_class = class_scores.argmax()\n",
    "    final_predictions.append(label_mapping[predicted_class])\n",
    "\n",
    "print(f\"\\nAggregated to {len(final_predictions)} final predictions (one per pirate)\")\n",
    "\n",
    "# Create submission CSV\n",
    "from datetime import datetime\n",
    "predictions_df = pd.DataFrame({\n",
    "    'sample_index': np.arange(num_test_samples),\n",
    "    'label': final_predictions\n",
    "})\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "filename = f'predictions_seed_{best_seed}_{timestamp}.csv'\n",
    "predictions_df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"\\nâœ… Predictions saved to: {filename}\")\n",
    "print(f\"   Best seed used: {best_seed}\")\n",
    "print(f\"   Best Val F1: {best_f1_overall:.4f}\")\n",
    "print(f\"   Total predictions: {len(final_predictions)} (one per pirate)\")\n",
    "print(f\"\\nDistribution:\")\n",
    "for label in ['no_pain', 'low_pain', 'high_pain']:\n",
    "    count = final_predictions.count(label)\n",
    "    pct = (count / len(final_predictions)) * 100\n",
    "    print(f\"   {label:10s}: {count:5d} ({pct:5.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
